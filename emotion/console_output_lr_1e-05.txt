                                                text  label
0  “Worry is a down payment on a problem you may ...      2
1  My roommate: it's okay that we can't spell bec...      0
2  No but that's so cute. Atsu was probably shy a...      1
3  Rooneys fucking untouchable isn't he? Been fuc...      0
4  it's pretty depressing when u hit pan on ur fa...      3
                                                text
0  “Worry is a down payment on a problem you may ...
1  My roommate: it's okay that we can't spell bec...
2  No but that's so cute. Atsu was probably shy a...
3  Rooneys fucking untouchable isn't he? Been fuc...
4  it's pretty depressing when u hit pan on ur fa...
   label
0      2
1      0
2      1
3      0
4      3
                                                text  label
0  @user @user Oh, hidden revenge and anger...I r...      0
1  if not then #teamchristine bc all tana has don...      0
2  Hey @user #Fields in #skibbereen give your onl...      0
3  Why have #Emmerdale had to rob #robron of havi...      0
4  @user I would like to hear a podcast of you go...      0
                                                text
0  @user @user Oh, hidden revenge and anger...I r...
1  if not then #teamchristine bc all tana has don...
2  Hey @user #Fields in #skibbereen give your onl...
3  Why have #Emmerdale had to rob #robron of havi...
4  @user I would like to hear a podcast of you go...
   label
0      0
1      0
2      0
3      0
4      0
                                                text  label
0  #Deppression is real. Partners w/ #depressed p...      3
1  @user Interesting choice of words... Are you c...      0
2  My visit to hospital for care triggered #traum...      3
3  @user Welcome to #MPSVT! We are delighted to h...      1
4                       What makes you feel #joyful?      1
                                                text
0  #Deppression is real. Partners w/ #depressed p...
1  @user Interesting choice of words... Are you c...
2  My visit to hospital for care triggered #traum...
3  @user Welcome to #MPSVT! We are delighted to h...
4                       What makes you feel #joyful?
                                                text
0  #Deppression is real. Partners w/ #depressed p...
1  @user Interesting choice of words... Are you c...
2  My visit to hospital for care triggered #traum...
3  @user Welcome to #MPSVT! We are delighted to h...
4                       What makes you feel #joyful?



===================================================== 
flag 1.10  model: bert has started ==>   bert
===================================================== 
embeddings.word_embeddings.weight: requires_grad=True
embeddings.position_embeddings.weight: requires_grad=True
embeddings.token_type_embeddings.weight: requires_grad=True
embeddings.LayerNorm.weight: requires_grad=True
embeddings.LayerNorm.bias: requires_grad=True
encoder.layer.0.attention.self.query.weight: requires_grad=True
encoder.layer.0.attention.self.query.bias: requires_grad=True
encoder.layer.0.attention.self.key.weight: requires_grad=True
encoder.layer.0.attention.self.key.bias: requires_grad=True
encoder.layer.0.attention.self.value.weight: requires_grad=True
encoder.layer.0.attention.self.value.bias: requires_grad=True
encoder.layer.0.attention.output.dense.weight: requires_grad=True
encoder.layer.0.attention.output.dense.bias: requires_grad=True
encoder.layer.0.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.0.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.0.intermediate.dense.weight: requires_grad=True
encoder.layer.0.intermediate.dense.bias: requires_grad=True
encoder.layer.0.output.dense.weight: requires_grad=True
encoder.layer.0.output.dense.bias: requires_grad=True
encoder.layer.0.output.LayerNorm.weight: requires_grad=True
encoder.layer.0.output.LayerNorm.bias: requires_grad=True
encoder.layer.1.attention.self.query.weight: requires_grad=True
encoder.layer.1.attention.self.query.bias: requires_grad=True
encoder.layer.1.attention.self.key.weight: requires_grad=True
encoder.layer.1.attention.self.key.bias: requires_grad=True
encoder.layer.1.attention.self.value.weight: requires_grad=True
encoder.layer.1.attention.self.value.bias: requires_grad=True
encoder.layer.1.attention.output.dense.weight: requires_grad=True
encoder.layer.1.attention.output.dense.bias: requires_grad=True
encoder.layer.1.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.1.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.1.intermediate.dense.weight: requires_grad=True
encoder.layer.1.intermediate.dense.bias: requires_grad=True
encoder.layer.1.output.dense.weight: requires_grad=True
encoder.layer.1.output.dense.bias: requires_grad=True
encoder.layer.1.output.LayerNorm.weight: requires_grad=True
encoder.layer.1.output.LayerNorm.bias: requires_grad=True
encoder.layer.2.attention.self.query.weight: requires_grad=True
encoder.layer.2.attention.self.query.bias: requires_grad=True
encoder.layer.2.attention.self.key.weight: requires_grad=True
encoder.layer.2.attention.self.key.bias: requires_grad=True
encoder.layer.2.attention.self.value.weight: requires_grad=True
encoder.layer.2.attention.self.value.bias: requires_grad=True
encoder.layer.2.attention.output.dense.weight: requires_grad=True
encoder.layer.2.attention.output.dense.bias: requires_grad=True
encoder.layer.2.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.2.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.2.intermediate.dense.weight: requires_grad=True
encoder.layer.2.intermediate.dense.bias: requires_grad=True
encoder.layer.2.output.dense.weight: requires_grad=True
encoder.layer.2.output.dense.bias: requires_grad=True
encoder.layer.2.output.LayerNorm.weight: requires_grad=True
encoder.layer.2.output.LayerNorm.bias: requires_grad=True
encoder.layer.3.attention.self.query.weight: requires_grad=True
encoder.layer.3.attention.self.query.bias: requires_grad=True
encoder.layer.3.attention.self.key.weight: requires_grad=True
encoder.layer.3.attention.self.key.bias: requires_grad=True
encoder.layer.3.attention.self.value.weight: requires_grad=True
encoder.layer.3.attention.self.value.bias: requires_grad=True
encoder.layer.3.attention.output.dense.weight: requires_grad=True
encoder.layer.3.attention.output.dense.bias: requires_grad=True
encoder.layer.3.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.3.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.3.intermediate.dense.weight: requires_grad=True
encoder.layer.3.intermediate.dense.bias: requires_grad=True
encoder.layer.3.output.dense.weight: requires_grad=True
encoder.layer.3.output.dense.bias: requires_grad=True
encoder.layer.3.output.LayerNorm.weight: requires_grad=True
encoder.layer.3.output.LayerNorm.bias: requires_grad=True
encoder.layer.4.attention.self.query.weight: requires_grad=True
encoder.layer.4.attention.self.query.bias: requires_grad=True
encoder.layer.4.attention.self.key.weight: requires_grad=True
encoder.layer.4.attention.self.key.bias: requires_grad=True
encoder.layer.4.attention.self.value.weight: requires_grad=True
encoder.layer.4.attention.self.value.bias: requires_grad=True
encoder.layer.4.attention.output.dense.weight: requires_grad=True
encoder.layer.4.attention.output.dense.bias: requires_grad=True
encoder.layer.4.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.4.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.4.intermediate.dense.weight: requires_grad=True
encoder.layer.4.intermediate.dense.bias: requires_grad=True
encoder.layer.4.output.dense.weight: requires_grad=True
encoder.layer.4.output.dense.bias: requires_grad=True
encoder.layer.4.output.LayerNorm.weight: requires_grad=True
encoder.layer.4.output.LayerNorm.bias: requires_grad=True
encoder.layer.5.attention.self.query.weight: requires_grad=True
encoder.layer.5.attention.self.query.bias: requires_grad=True
encoder.layer.5.attention.self.key.weight: requires_grad=True
encoder.layer.5.attention.self.key.bias: requires_grad=True
encoder.layer.5.attention.self.value.weight: requires_grad=True
encoder.layer.5.attention.self.value.bias: requires_grad=True
encoder.layer.5.attention.output.dense.weight: requires_grad=True
encoder.layer.5.attention.output.dense.bias: requires_grad=True
encoder.layer.5.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.5.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.5.intermediate.dense.weight: requires_grad=True
encoder.layer.5.intermediate.dense.bias: requires_grad=True
encoder.layer.5.output.dense.weight: requires_grad=True
encoder.layer.5.output.dense.bias: requires_grad=True
encoder.layer.5.output.LayerNorm.weight: requires_grad=True
encoder.layer.5.output.LayerNorm.bias: requires_grad=True
encoder.layer.6.attention.self.query.weight: requires_grad=True
encoder.layer.6.attention.self.query.bias: requires_grad=True
encoder.layer.6.attention.self.key.weight: requires_grad=True
encoder.layer.6.attention.self.key.bias: requires_grad=True
encoder.layer.6.attention.self.value.weight: requires_grad=True
encoder.layer.6.attention.self.value.bias: requires_grad=True
encoder.layer.6.attention.output.dense.weight: requires_grad=True
encoder.layer.6.attention.output.dense.bias: requires_grad=True
encoder.layer.6.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.6.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.6.intermediate.dense.weight: requires_grad=True
encoder.layer.6.intermediate.dense.bias: requires_grad=True
encoder.layer.6.output.dense.weight: requires_grad=True
encoder.layer.6.output.dense.bias: requires_grad=True
encoder.layer.6.output.LayerNorm.weight: requires_grad=True
encoder.layer.6.output.LayerNorm.bias: requires_grad=True
encoder.layer.7.attention.self.query.weight: requires_grad=True
encoder.layer.7.attention.self.query.bias: requires_grad=True
encoder.layer.7.attention.self.key.weight: requires_grad=True
encoder.layer.7.attention.self.key.bias: requires_grad=True
encoder.layer.7.attention.self.value.weight: requires_grad=True
encoder.layer.7.attention.self.value.bias: requires_grad=True
encoder.layer.7.attention.output.dense.weight: requires_grad=True
encoder.layer.7.attention.output.dense.bias: requires_grad=True
encoder.layer.7.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.7.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.7.intermediate.dense.weight: requires_grad=True
encoder.layer.7.intermediate.dense.bias: requires_grad=True
encoder.layer.7.output.dense.weight: requires_grad=True
encoder.layer.7.output.dense.bias: requires_grad=True
encoder.layer.7.output.LayerNorm.weight: requires_grad=True
encoder.layer.7.output.LayerNorm.bias: requires_grad=True
encoder.layer.8.attention.self.query.weight: requires_grad=True
encoder.layer.8.attention.self.query.bias: requires_grad=True
encoder.layer.8.attention.self.key.weight: requires_grad=True
encoder.layer.8.attention.self.key.bias: requires_grad=True
encoder.layer.8.attention.self.value.weight: requires_grad=True
encoder.layer.8.attention.self.value.bias: requires_grad=True
encoder.layer.8.attention.output.dense.weight: requires_grad=True
encoder.layer.8.attention.output.dense.bias: requires_grad=True
encoder.layer.8.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.8.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.8.intermediate.dense.weight: requires_grad=True
encoder.layer.8.intermediate.dense.bias: requires_grad=True
encoder.layer.8.output.dense.weight: requires_grad=True
encoder.layer.8.output.dense.bias: requires_grad=True
encoder.layer.8.output.LayerNorm.weight: requires_grad=True
encoder.layer.8.output.LayerNorm.bias: requires_grad=True
encoder.layer.9.attention.self.query.weight: requires_grad=True
encoder.layer.9.attention.self.query.bias: requires_grad=True
encoder.layer.9.attention.self.key.weight: requires_grad=True
encoder.layer.9.attention.self.key.bias: requires_grad=True
encoder.layer.9.attention.self.value.weight: requires_grad=True
encoder.layer.9.attention.self.value.bias: requires_grad=True
encoder.layer.9.attention.output.dense.weight: requires_grad=True
encoder.layer.9.attention.output.dense.bias: requires_grad=True
encoder.layer.9.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.9.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.9.intermediate.dense.weight: requires_grad=True
encoder.layer.9.intermediate.dense.bias: requires_grad=True
encoder.layer.9.output.dense.weight: requires_grad=True
encoder.layer.9.output.dense.bias: requires_grad=True
encoder.layer.9.output.LayerNorm.weight: requires_grad=True
encoder.layer.9.output.LayerNorm.bias: requires_grad=True
encoder.layer.10.attention.self.query.weight: requires_grad=True
encoder.layer.10.attention.self.query.bias: requires_grad=True
encoder.layer.10.attention.self.key.weight: requires_grad=True
encoder.layer.10.attention.self.key.bias: requires_grad=True
encoder.layer.10.attention.self.value.weight: requires_grad=True
encoder.layer.10.attention.self.value.bias: requires_grad=True
encoder.layer.10.attention.output.dense.weight: requires_grad=True
encoder.layer.10.attention.output.dense.bias: requires_grad=True
encoder.layer.10.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.10.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.10.intermediate.dense.weight: requires_grad=True
encoder.layer.10.intermediate.dense.bias: requires_grad=True
encoder.layer.10.output.dense.weight: requires_grad=True
encoder.layer.10.output.dense.bias: requires_grad=True
encoder.layer.10.output.LayerNorm.weight: requires_grad=True
encoder.layer.10.output.LayerNorm.bias: requires_grad=True
encoder.layer.11.attention.self.query.weight: requires_grad=True
encoder.layer.11.attention.self.query.bias: requires_grad=True
encoder.layer.11.attention.self.key.weight: requires_grad=True
encoder.layer.11.attention.self.key.bias: requires_grad=True
encoder.layer.11.attention.self.value.weight: requires_grad=True
encoder.layer.11.attention.self.value.bias: requires_grad=True
encoder.layer.11.attention.output.dense.weight: requires_grad=True
encoder.layer.11.attention.output.dense.bias: requires_grad=True
encoder.layer.11.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.11.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.11.intermediate.dense.weight: requires_grad=True
encoder.layer.11.intermediate.dense.bias: requires_grad=True
encoder.layer.11.output.dense.weight: requires_grad=True
encoder.layer.11.output.dense.bias: requires_grad=True
encoder.layer.11.output.LayerNorm.weight: requires_grad=True
encoder.layer.11.output.LayerNorm.bias: requires_grad=True
pooler.dense.weight: requires_grad=True
pooler.dense.bias: requires_grad=True

 Epoch 1 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.177
Validation Loss: 0.941
Validation Accuracy: 0.604

 Epoch 2 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.796
Validation Loss: 0.673
Validation Accuracy: 0.786

 Epoch 3 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.542
Validation Loss: 0.652
Validation Accuracy: 0.791

 Epoch 4 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.403
Validation Loss: 0.641
Validation Accuracy: 0.789

 Epoch 5 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.299
Validation Loss: 0.668
Validation Accuracy: 0.783

 Epoch 6 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.224
Validation Loss: 0.693
Validation Accuracy: 0.799

 Epoch 7 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.162
Validation Loss: 0.761
Validation Accuracy: 0.789

 Epoch 8 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.116
Validation Loss: 0.783
Validation Accuracy: 0.805

 Epoch 9 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.091
Validation Loss: 0.860
Validation Accuracy: 0.797

 Epoch 10 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.066
Validation Loss: 0.929
Validation Accuracy: 0.786

Test Accuracy: 0.793
== flag 1.601 bert result On test data ==
Test Accuracy: 0.793%
Precision: 0.7986
Recall: 0.7931
F1 Score: 0.7942
Classification Report:
              precision    recall  f1-score   support

           0       0.89      0.82      0.85       558
           1       0.76      0.87      0.81       358
           2       0.58      0.65      0.61       123
           3       0.77      0.73      0.75       382

    accuracy                           0.79      1421
   macro avg       0.75      0.77      0.76      1421
weighted avg       0.80      0.79      0.79      1421

Confusion Matrix:
[[459  30  18  51]
 [ 12 311  17  18]
 [ 11  20  80  12]
 [ 36  46  23 277]]
flag 1.11  model: bert has finished  : bert



===================================================== 
flag 1.10  model: roberta has started ==>   roberta
===================================================== 
embeddings.word_embeddings.weight: requires_grad=True
embeddings.position_embeddings.weight: requires_grad=True
embeddings.token_type_embeddings.weight: requires_grad=True
embeddings.LayerNorm.weight: requires_grad=True
embeddings.LayerNorm.bias: requires_grad=True
encoder.layer.0.attention.self.query.weight: requires_grad=True
encoder.layer.0.attention.self.query.bias: requires_grad=True
encoder.layer.0.attention.self.key.weight: requires_grad=True
encoder.layer.0.attention.self.key.bias: requires_grad=True
encoder.layer.0.attention.self.value.weight: requires_grad=True
encoder.layer.0.attention.self.value.bias: requires_grad=True
encoder.layer.0.attention.output.dense.weight: requires_grad=True
encoder.layer.0.attention.output.dense.bias: requires_grad=True
encoder.layer.0.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.0.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.0.intermediate.dense.weight: requires_grad=True
encoder.layer.0.intermediate.dense.bias: requires_grad=True
encoder.layer.0.output.dense.weight: requires_grad=True
encoder.layer.0.output.dense.bias: requires_grad=True
encoder.layer.0.output.LayerNorm.weight: requires_grad=True
encoder.layer.0.output.LayerNorm.bias: requires_grad=True
encoder.layer.1.attention.self.query.weight: requires_grad=True
encoder.layer.1.attention.self.query.bias: requires_grad=True
encoder.layer.1.attention.self.key.weight: requires_grad=True
encoder.layer.1.attention.self.key.bias: requires_grad=True
encoder.layer.1.attention.self.value.weight: requires_grad=True
encoder.layer.1.attention.self.value.bias: requires_grad=True
encoder.layer.1.attention.output.dense.weight: requires_grad=True
encoder.layer.1.attention.output.dense.bias: requires_grad=True
encoder.layer.1.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.1.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.1.intermediate.dense.weight: requires_grad=True
encoder.layer.1.intermediate.dense.bias: requires_grad=True
encoder.layer.1.output.dense.weight: requires_grad=True
encoder.layer.1.output.dense.bias: requires_grad=True
encoder.layer.1.output.LayerNorm.weight: requires_grad=True
encoder.layer.1.output.LayerNorm.bias: requires_grad=True
encoder.layer.2.attention.self.query.weight: requires_grad=True
encoder.layer.2.attention.self.query.bias: requires_grad=True
encoder.layer.2.attention.self.key.weight: requires_grad=True
encoder.layer.2.attention.self.key.bias: requires_grad=True
encoder.layer.2.attention.self.value.weight: requires_grad=True
encoder.layer.2.attention.self.value.bias: requires_grad=True
encoder.layer.2.attention.output.dense.weight: requires_grad=True
encoder.layer.2.attention.output.dense.bias: requires_grad=True
encoder.layer.2.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.2.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.2.intermediate.dense.weight: requires_grad=True
encoder.layer.2.intermediate.dense.bias: requires_grad=True
encoder.layer.2.output.dense.weight: requires_grad=True
encoder.layer.2.output.dense.bias: requires_grad=True
encoder.layer.2.output.LayerNorm.weight: requires_grad=True
encoder.layer.2.output.LayerNorm.bias: requires_grad=True
encoder.layer.3.attention.self.query.weight: requires_grad=True
encoder.layer.3.attention.self.query.bias: requires_grad=True
encoder.layer.3.attention.self.key.weight: requires_grad=True
encoder.layer.3.attention.self.key.bias: requires_grad=True
encoder.layer.3.attention.self.value.weight: requires_grad=True
encoder.layer.3.attention.self.value.bias: requires_grad=True
encoder.layer.3.attention.output.dense.weight: requires_grad=True
encoder.layer.3.attention.output.dense.bias: requires_grad=True
encoder.layer.3.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.3.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.3.intermediate.dense.weight: requires_grad=True
encoder.layer.3.intermediate.dense.bias: requires_grad=True
encoder.layer.3.output.dense.weight: requires_grad=True
encoder.layer.3.output.dense.bias: requires_grad=True
encoder.layer.3.output.LayerNorm.weight: requires_grad=True
encoder.layer.3.output.LayerNorm.bias: requires_grad=True
encoder.layer.4.attention.self.query.weight: requires_grad=True
encoder.layer.4.attention.self.query.bias: requires_grad=True
encoder.layer.4.attention.self.key.weight: requires_grad=True
encoder.layer.4.attention.self.key.bias: requires_grad=True
encoder.layer.4.attention.self.value.weight: requires_grad=True
encoder.layer.4.attention.self.value.bias: requires_grad=True
encoder.layer.4.attention.output.dense.weight: requires_grad=True
encoder.layer.4.attention.output.dense.bias: requires_grad=True
encoder.layer.4.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.4.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.4.intermediate.dense.weight: requires_grad=True
encoder.layer.4.intermediate.dense.bias: requires_grad=True
encoder.layer.4.output.dense.weight: requires_grad=True
encoder.layer.4.output.dense.bias: requires_grad=True
encoder.layer.4.output.LayerNorm.weight: requires_grad=True
encoder.layer.4.output.LayerNorm.bias: requires_grad=True
encoder.layer.5.attention.self.query.weight: requires_grad=True
encoder.layer.5.attention.self.query.bias: requires_grad=True
encoder.layer.5.attention.self.key.weight: requires_grad=True
encoder.layer.5.attention.self.key.bias: requires_grad=True
encoder.layer.5.attention.self.value.weight: requires_grad=True
encoder.layer.5.attention.self.value.bias: requires_grad=True
encoder.layer.5.attention.output.dense.weight: requires_grad=True
encoder.layer.5.attention.output.dense.bias: requires_grad=True
encoder.layer.5.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.5.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.5.intermediate.dense.weight: requires_grad=True
encoder.layer.5.intermediate.dense.bias: requires_grad=True
encoder.layer.5.output.dense.weight: requires_grad=True
encoder.layer.5.output.dense.bias: requires_grad=True
encoder.layer.5.output.LayerNorm.weight: requires_grad=True
encoder.layer.5.output.LayerNorm.bias: requires_grad=True
encoder.layer.6.attention.self.query.weight: requires_grad=True
encoder.layer.6.attention.self.query.bias: requires_grad=True
encoder.layer.6.attention.self.key.weight: requires_grad=True
encoder.layer.6.attention.self.key.bias: requires_grad=True
encoder.layer.6.attention.self.value.weight: requires_grad=True
encoder.layer.6.attention.self.value.bias: requires_grad=True
encoder.layer.6.attention.output.dense.weight: requires_grad=True
encoder.layer.6.attention.output.dense.bias: requires_grad=True
encoder.layer.6.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.6.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.6.intermediate.dense.weight: requires_grad=True
encoder.layer.6.intermediate.dense.bias: requires_grad=True
encoder.layer.6.output.dense.weight: requires_grad=True
encoder.layer.6.output.dense.bias: requires_grad=True
encoder.layer.6.output.LayerNorm.weight: requires_grad=True
encoder.layer.6.output.LayerNorm.bias: requires_grad=True
encoder.layer.7.attention.self.query.weight: requires_grad=True
encoder.layer.7.attention.self.query.bias: requires_grad=True
encoder.layer.7.attention.self.key.weight: requires_grad=True
encoder.layer.7.attention.self.key.bias: requires_grad=True
encoder.layer.7.attention.self.value.weight: requires_grad=True
encoder.layer.7.attention.self.value.bias: requires_grad=True
encoder.layer.7.attention.output.dense.weight: requires_grad=True
encoder.layer.7.attention.output.dense.bias: requires_grad=True
encoder.layer.7.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.7.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.7.intermediate.dense.weight: requires_grad=True
encoder.layer.7.intermediate.dense.bias: requires_grad=True
encoder.layer.7.output.dense.weight: requires_grad=True
encoder.layer.7.output.dense.bias: requires_grad=True
encoder.layer.7.output.LayerNorm.weight: requires_grad=True
encoder.layer.7.output.LayerNorm.bias: requires_grad=True
encoder.layer.8.attention.self.query.weight: requires_grad=True
encoder.layer.8.attention.self.query.bias: requires_grad=True
encoder.layer.8.attention.self.key.weight: requires_grad=True
encoder.layer.8.attention.self.key.bias: requires_grad=True
encoder.layer.8.attention.self.value.weight: requires_grad=True
encoder.layer.8.attention.self.value.bias: requires_grad=True
encoder.layer.8.attention.output.dense.weight: requires_grad=True
encoder.layer.8.attention.output.dense.bias: requires_grad=True
encoder.layer.8.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.8.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.8.intermediate.dense.weight: requires_grad=True
encoder.layer.8.intermediate.dense.bias: requires_grad=True
encoder.layer.8.output.dense.weight: requires_grad=True
encoder.layer.8.output.dense.bias: requires_grad=True
encoder.layer.8.output.LayerNorm.weight: requires_grad=True
encoder.layer.8.output.LayerNorm.bias: requires_grad=True
encoder.layer.9.attention.self.query.weight: requires_grad=True
encoder.layer.9.attention.self.query.bias: requires_grad=True
encoder.layer.9.attention.self.key.weight: requires_grad=True
encoder.layer.9.attention.self.key.bias: requires_grad=True
encoder.layer.9.attention.self.value.weight: requires_grad=True
encoder.layer.9.attention.self.value.bias: requires_grad=True
encoder.layer.9.attention.output.dense.weight: requires_grad=True
encoder.layer.9.attention.output.dense.bias: requires_grad=True
encoder.layer.9.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.9.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.9.intermediate.dense.weight: requires_grad=True
encoder.layer.9.intermediate.dense.bias: requires_grad=True
encoder.layer.9.output.dense.weight: requires_grad=True
encoder.layer.9.output.dense.bias: requires_grad=True
encoder.layer.9.output.LayerNorm.weight: requires_grad=True
encoder.layer.9.output.LayerNorm.bias: requires_grad=True
encoder.layer.10.attention.self.query.weight: requires_grad=True
encoder.layer.10.attention.self.query.bias: requires_grad=True
encoder.layer.10.attention.self.key.weight: requires_grad=True
encoder.layer.10.attention.self.key.bias: requires_grad=True
encoder.layer.10.attention.self.value.weight: requires_grad=True
encoder.layer.10.attention.self.value.bias: requires_grad=True
encoder.layer.10.attention.output.dense.weight: requires_grad=True
encoder.layer.10.attention.output.dense.bias: requires_grad=True
encoder.layer.10.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.10.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.10.intermediate.dense.weight: requires_grad=True
encoder.layer.10.intermediate.dense.bias: requires_grad=True
encoder.layer.10.output.dense.weight: requires_grad=True
encoder.layer.10.output.dense.bias: requires_grad=True
encoder.layer.10.output.LayerNorm.weight: requires_grad=True
encoder.layer.10.output.LayerNorm.bias: requires_grad=True
encoder.layer.11.attention.self.query.weight: requires_grad=True
encoder.layer.11.attention.self.query.bias: requires_grad=True
encoder.layer.11.attention.self.key.weight: requires_grad=True
encoder.layer.11.attention.self.key.bias: requires_grad=True
encoder.layer.11.attention.self.value.weight: requires_grad=True
encoder.layer.11.attention.self.value.bias: requires_grad=True
encoder.layer.11.attention.output.dense.weight: requires_grad=True
encoder.layer.11.attention.output.dense.bias: requires_grad=True
encoder.layer.11.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.11.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.11.intermediate.dense.weight: requires_grad=True
encoder.layer.11.intermediate.dense.bias: requires_grad=True
encoder.layer.11.output.dense.weight: requires_grad=True
encoder.layer.11.output.dense.bias: requires_grad=True
encoder.layer.11.output.LayerNorm.weight: requires_grad=True
encoder.layer.11.output.LayerNorm.bias: requires_grad=True
pooler.dense.weight: requires_grad=True
pooler.dense.bias: requires_grad=True

 Epoch 1 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.169
Validation Loss: 0.849
Validation Accuracy: 0.727

 Epoch 2 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.727
Validation Loss: 0.734
Validation Accuracy: 0.751

 Epoch 3 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.565
Validation Loss: 0.694
Validation Accuracy: 0.770

 Epoch 4 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.461
Validation Loss: 0.709
Validation Accuracy: 0.767

 Epoch 5 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.384
Validation Loss: 0.669
Validation Accuracy: 0.791

 Epoch 6 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.304
Validation Loss: 0.667
Validation Accuracy: 0.794

 Epoch 7 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.267
Validation Loss: 0.748
Validation Accuracy: 0.781

 Epoch 8 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.206
Validation Loss: 0.783
Validation Accuracy: 0.781

 Epoch 9 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.186
Validation Loss: 0.811
Validation Accuracy: 0.791

 Epoch 10 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.158
Validation Loss: 0.954
Validation Accuracy: 0.765

Test Accuracy: 0.815
== flag 1.601 roberta result On test data ==
Test Accuracy: 0.815%
Precision: 0.8141
Recall: 0.8149
F1 Score: 0.8130
Classification Report:
              precision    recall  f1-score   support

           0       0.85      0.87      0.86       558
           1       0.79      0.87      0.83       358
           2       0.77      0.59      0.67       123
           3       0.79      0.76      0.78       382

    accuracy                           0.81      1421
   macro avg       0.80      0.77      0.78      1421
weighted avg       0.81      0.81      0.81      1421

Confusion Matrix:
[[483  30   6  39]
 [ 16 311   7  24]
 [ 18  18  73  14]
 [ 48  34   9 291]]
flag 1.11  model: roberta has finished  : roberta



===================================================== 
flag 1.10  model: distilbert has started ==>   distilbert
===================================================== 
embeddings.word_embeddings.weight: requires_grad=True
embeddings.position_embeddings.weight: requires_grad=True
embeddings.LayerNorm.weight: requires_grad=True
embeddings.LayerNorm.bias: requires_grad=True
transformer.layer.0.attention.q_lin.weight: requires_grad=True
transformer.layer.0.attention.q_lin.bias: requires_grad=True
transformer.layer.0.attention.k_lin.weight: requires_grad=True
transformer.layer.0.attention.k_lin.bias: requires_grad=True
transformer.layer.0.attention.v_lin.weight: requires_grad=True
transformer.layer.0.attention.v_lin.bias: requires_grad=True
transformer.layer.0.attention.out_lin.weight: requires_grad=True
transformer.layer.0.attention.out_lin.bias: requires_grad=True
transformer.layer.0.sa_layer_norm.weight: requires_grad=True
transformer.layer.0.sa_layer_norm.bias: requires_grad=True
transformer.layer.0.ffn.lin1.weight: requires_grad=True
transformer.layer.0.ffn.lin1.bias: requires_grad=True
transformer.layer.0.ffn.lin2.weight: requires_grad=True
transformer.layer.0.ffn.lin2.bias: requires_grad=True
transformer.layer.0.output_layer_norm.weight: requires_grad=True
transformer.layer.0.output_layer_norm.bias: requires_grad=True
transformer.layer.1.attention.q_lin.weight: requires_grad=True
transformer.layer.1.attention.q_lin.bias: requires_grad=True
transformer.layer.1.attention.k_lin.weight: requires_grad=True
transformer.layer.1.attention.k_lin.bias: requires_grad=True
transformer.layer.1.attention.v_lin.weight: requires_grad=True
transformer.layer.1.attention.v_lin.bias: requires_grad=True
transformer.layer.1.attention.out_lin.weight: requires_grad=True
transformer.layer.1.attention.out_lin.bias: requires_grad=True
transformer.layer.1.sa_layer_norm.weight: requires_grad=True
transformer.layer.1.sa_layer_norm.bias: requires_grad=True
transformer.layer.1.ffn.lin1.weight: requires_grad=True
transformer.layer.1.ffn.lin1.bias: requires_grad=True
transformer.layer.1.ffn.lin2.weight: requires_grad=True
transformer.layer.1.ffn.lin2.bias: requires_grad=True
transformer.layer.1.output_layer_norm.weight: requires_grad=True
transformer.layer.1.output_layer_norm.bias: requires_grad=True
transformer.layer.2.attention.q_lin.weight: requires_grad=True
transformer.layer.2.attention.q_lin.bias: requires_grad=True
transformer.layer.2.attention.k_lin.weight: requires_grad=True
transformer.layer.2.attention.k_lin.bias: requires_grad=True
transformer.layer.2.attention.v_lin.weight: requires_grad=True
transformer.layer.2.attention.v_lin.bias: requires_grad=True
transformer.layer.2.attention.out_lin.weight: requires_grad=True
transformer.layer.2.attention.out_lin.bias: requires_grad=True
transformer.layer.2.sa_layer_norm.weight: requires_grad=True
transformer.layer.2.sa_layer_norm.bias: requires_grad=True
transformer.layer.2.ffn.lin1.weight: requires_grad=True
transformer.layer.2.ffn.lin1.bias: requires_grad=True
transformer.layer.2.ffn.lin2.weight: requires_grad=True
transformer.layer.2.ffn.lin2.bias: requires_grad=True
transformer.layer.2.output_layer_norm.weight: requires_grad=True
transformer.layer.2.output_layer_norm.bias: requires_grad=True
transformer.layer.3.attention.q_lin.weight: requires_grad=True
transformer.layer.3.attention.q_lin.bias: requires_grad=True
transformer.layer.3.attention.k_lin.weight: requires_grad=True
transformer.layer.3.attention.k_lin.bias: requires_grad=True
transformer.layer.3.attention.v_lin.weight: requires_grad=True
transformer.layer.3.attention.v_lin.bias: requires_grad=True
transformer.layer.3.attention.out_lin.weight: requires_grad=True
transformer.layer.3.attention.out_lin.bias: requires_grad=True
transformer.layer.3.sa_layer_norm.weight: requires_grad=True
transformer.layer.3.sa_layer_norm.bias: requires_grad=True
transformer.layer.3.ffn.lin1.weight: requires_grad=True
transformer.layer.3.ffn.lin1.bias: requires_grad=True
transformer.layer.3.ffn.lin2.weight: requires_grad=True
transformer.layer.3.ffn.lin2.bias: requires_grad=True
transformer.layer.3.output_layer_norm.weight: requires_grad=True
transformer.layer.3.output_layer_norm.bias: requires_grad=True
transformer.layer.4.attention.q_lin.weight: requires_grad=True
transformer.layer.4.attention.q_lin.bias: requires_grad=True
transformer.layer.4.attention.k_lin.weight: requires_grad=True
transformer.layer.4.attention.k_lin.bias: requires_grad=True
transformer.layer.4.attention.v_lin.weight: requires_grad=True
transformer.layer.4.attention.v_lin.bias: requires_grad=True
transformer.layer.4.attention.out_lin.weight: requires_grad=True
transformer.layer.4.attention.out_lin.bias: requires_grad=True
transformer.layer.4.sa_layer_norm.weight: requires_grad=True
transformer.layer.4.sa_layer_norm.bias: requires_grad=True
transformer.layer.4.ffn.lin1.weight: requires_grad=True
transformer.layer.4.ffn.lin1.bias: requires_grad=True
transformer.layer.4.ffn.lin2.weight: requires_grad=True
transformer.layer.4.ffn.lin2.bias: requires_grad=True
transformer.layer.4.output_layer_norm.weight: requires_grad=True
transformer.layer.4.output_layer_norm.bias: requires_grad=True
transformer.layer.5.attention.q_lin.weight: requires_grad=True
transformer.layer.5.attention.q_lin.bias: requires_grad=True
transformer.layer.5.attention.k_lin.weight: requires_grad=True
transformer.layer.5.attention.k_lin.bias: requires_grad=True
transformer.layer.5.attention.v_lin.weight: requires_grad=True
transformer.layer.5.attention.v_lin.bias: requires_grad=True
transformer.layer.5.attention.out_lin.weight: requires_grad=True
transformer.layer.5.attention.out_lin.bias: requires_grad=True
transformer.layer.5.sa_layer_norm.weight: requires_grad=True
transformer.layer.5.sa_layer_norm.bias: requires_grad=True
transformer.layer.5.ffn.lin1.weight: requires_grad=True
transformer.layer.5.ffn.lin1.bias: requires_grad=True
transformer.layer.5.ffn.lin2.weight: requires_grad=True
transformer.layer.5.ffn.lin2.bias: requires_grad=True
transformer.layer.5.output_layer_norm.weight: requires_grad=True
transformer.layer.5.output_layer_norm.bias: requires_grad=True

 Epoch 1 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.132
Validation Loss: 0.849
Validation Accuracy: 0.714

 Epoch 2 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.701
Validation Loss: 0.676
Validation Accuracy: 0.767

 Epoch 3 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.507
Validation Loss: 0.624
Validation Accuracy: 0.765

 Epoch 4 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.396
Validation Loss: 0.657
Validation Accuracy: 0.770

 Epoch 5 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.307
Validation Loss: 0.722
Validation Accuracy: 0.749

 Epoch 6 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.236
Validation Loss: 0.707
Validation Accuracy: 0.767

 Epoch 7 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.179
Validation Loss: 0.713
Validation Accuracy: 0.781

 Epoch 8 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.132
Validation Loss: 0.745
Validation Accuracy: 0.783

 Epoch 9 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.099
Validation Loss: 0.850
Validation Accuracy: 0.773

 Epoch 10 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.074
Validation Loss: 0.894
Validation Accuracy: 0.775

Test Accuracy: 0.804
== flag 1.601 distilbert result On test data ==
Test Accuracy: 0.804%
Precision: 0.8027
Recall: 0.8037
F1 Score: 0.8017
Classification Report:
              precision    recall  f1-score   support

           0       0.87      0.84      0.86       558
           1       0.80      0.82      0.81       358
           2       0.67      0.50      0.57       123
           3       0.76      0.82      0.79       382

    accuracy                           0.80      1421
   macro avg       0.77      0.75      0.76      1421
weighted avg       0.80      0.80      0.80      1421

Confusion Matrix:
[[471  27  10  50]
 [ 22 295  10  31]
 [ 18  23  62  20]
 [ 31  26  11 314]]
flag 1.11  model: distilbert has finished  : distilbert



===================================================== 
flag 1.10  model: electra has started ==>   electra
===================================================== 
embeddings.word_embeddings.weight: requires_grad=True
embeddings.position_embeddings.weight: requires_grad=True
embeddings.token_type_embeddings.weight: requires_grad=True
embeddings.LayerNorm.weight: requires_grad=True
embeddings.LayerNorm.bias: requires_grad=True
encoder.layer.0.attention.self.query.weight: requires_grad=True
encoder.layer.0.attention.self.query.bias: requires_grad=True
encoder.layer.0.attention.self.key.weight: requires_grad=True
encoder.layer.0.attention.self.key.bias: requires_grad=True
encoder.layer.0.attention.self.value.weight: requires_grad=True
encoder.layer.0.attention.self.value.bias: requires_grad=True
encoder.layer.0.attention.output.dense.weight: requires_grad=True
encoder.layer.0.attention.output.dense.bias: requires_grad=True
encoder.layer.0.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.0.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.0.intermediate.dense.weight: requires_grad=True
encoder.layer.0.intermediate.dense.bias: requires_grad=True
encoder.layer.0.output.dense.weight: requires_grad=True
encoder.layer.0.output.dense.bias: requires_grad=True
encoder.layer.0.output.LayerNorm.weight: requires_grad=True
encoder.layer.0.output.LayerNorm.bias: requires_grad=True
encoder.layer.1.attention.self.query.weight: requires_grad=True
encoder.layer.1.attention.self.query.bias: requires_grad=True
encoder.layer.1.attention.self.key.weight: requires_grad=True
encoder.layer.1.attention.self.key.bias: requires_grad=True
encoder.layer.1.attention.self.value.weight: requires_grad=True
encoder.layer.1.attention.self.value.bias: requires_grad=True
encoder.layer.1.attention.output.dense.weight: requires_grad=True
encoder.layer.1.attention.output.dense.bias: requires_grad=True
encoder.layer.1.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.1.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.1.intermediate.dense.weight: requires_grad=True
encoder.layer.1.intermediate.dense.bias: requires_grad=True
encoder.layer.1.output.dense.weight: requires_grad=True
encoder.layer.1.output.dense.bias: requires_grad=True
encoder.layer.1.output.LayerNorm.weight: requires_grad=True
encoder.layer.1.output.LayerNorm.bias: requires_grad=True
encoder.layer.2.attention.self.query.weight: requires_grad=True
encoder.layer.2.attention.self.query.bias: requires_grad=True
encoder.layer.2.attention.self.key.weight: requires_grad=True
encoder.layer.2.attention.self.key.bias: requires_grad=True
encoder.layer.2.attention.self.value.weight: requires_grad=True
encoder.layer.2.attention.self.value.bias: requires_grad=True
encoder.layer.2.attention.output.dense.weight: requires_grad=True
encoder.layer.2.attention.output.dense.bias: requires_grad=True
encoder.layer.2.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.2.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.2.intermediate.dense.weight: requires_grad=True
encoder.layer.2.intermediate.dense.bias: requires_grad=True
encoder.layer.2.output.dense.weight: requires_grad=True
encoder.layer.2.output.dense.bias: requires_grad=True
encoder.layer.2.output.LayerNorm.weight: requires_grad=True
encoder.layer.2.output.LayerNorm.bias: requires_grad=True
encoder.layer.3.attention.self.query.weight: requires_grad=True
encoder.layer.3.attention.self.query.bias: requires_grad=True
encoder.layer.3.attention.self.key.weight: requires_grad=True
encoder.layer.3.attention.self.key.bias: requires_grad=True
encoder.layer.3.attention.self.value.weight: requires_grad=True
encoder.layer.3.attention.self.value.bias: requires_grad=True
encoder.layer.3.attention.output.dense.weight: requires_grad=True
encoder.layer.3.attention.output.dense.bias: requires_grad=True
encoder.layer.3.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.3.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.3.intermediate.dense.weight: requires_grad=True
encoder.layer.3.intermediate.dense.bias: requires_grad=True
encoder.layer.3.output.dense.weight: requires_grad=True
encoder.layer.3.output.dense.bias: requires_grad=True
encoder.layer.3.output.LayerNorm.weight: requires_grad=True
encoder.layer.3.output.LayerNorm.bias: requires_grad=True
encoder.layer.4.attention.self.query.weight: requires_grad=True
encoder.layer.4.attention.self.query.bias: requires_grad=True
encoder.layer.4.attention.self.key.weight: requires_grad=True
encoder.layer.4.attention.self.key.bias: requires_grad=True
encoder.layer.4.attention.self.value.weight: requires_grad=True
encoder.layer.4.attention.self.value.bias: requires_grad=True
encoder.layer.4.attention.output.dense.weight: requires_grad=True
encoder.layer.4.attention.output.dense.bias: requires_grad=True
encoder.layer.4.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.4.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.4.intermediate.dense.weight: requires_grad=True
encoder.layer.4.intermediate.dense.bias: requires_grad=True
encoder.layer.4.output.dense.weight: requires_grad=True
encoder.layer.4.output.dense.bias: requires_grad=True
encoder.layer.4.output.LayerNorm.weight: requires_grad=True
encoder.layer.4.output.LayerNorm.bias: requires_grad=True
encoder.layer.5.attention.self.query.weight: requires_grad=True
encoder.layer.5.attention.self.query.bias: requires_grad=True
encoder.layer.5.attention.self.key.weight: requires_grad=True
encoder.layer.5.attention.self.key.bias: requires_grad=True
encoder.layer.5.attention.self.value.weight: requires_grad=True
encoder.layer.5.attention.self.value.bias: requires_grad=True
encoder.layer.5.attention.output.dense.weight: requires_grad=True
encoder.layer.5.attention.output.dense.bias: requires_grad=True
encoder.layer.5.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.5.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.5.intermediate.dense.weight: requires_grad=True
encoder.layer.5.intermediate.dense.bias: requires_grad=True
encoder.layer.5.output.dense.weight: requires_grad=True
encoder.layer.5.output.dense.bias: requires_grad=True
encoder.layer.5.output.LayerNorm.weight: requires_grad=True
encoder.layer.5.output.LayerNorm.bias: requires_grad=True
encoder.layer.6.attention.self.query.weight: requires_grad=True
encoder.layer.6.attention.self.query.bias: requires_grad=True
encoder.layer.6.attention.self.key.weight: requires_grad=True
encoder.layer.6.attention.self.key.bias: requires_grad=True
encoder.layer.6.attention.self.value.weight: requires_grad=True
encoder.layer.6.attention.self.value.bias: requires_grad=True
encoder.layer.6.attention.output.dense.weight: requires_grad=True
encoder.layer.6.attention.output.dense.bias: requires_grad=True
encoder.layer.6.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.6.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.6.intermediate.dense.weight: requires_grad=True
encoder.layer.6.intermediate.dense.bias: requires_grad=True
encoder.layer.6.output.dense.weight: requires_grad=True
encoder.layer.6.output.dense.bias: requires_grad=True
encoder.layer.6.output.LayerNorm.weight: requires_grad=True
encoder.layer.6.output.LayerNorm.bias: requires_grad=True
encoder.layer.7.attention.self.query.weight: requires_grad=True
encoder.layer.7.attention.self.query.bias: requires_grad=True
encoder.layer.7.attention.self.key.weight: requires_grad=True
encoder.layer.7.attention.self.key.bias: requires_grad=True
encoder.layer.7.attention.self.value.weight: requires_grad=True
encoder.layer.7.attention.self.value.bias: requires_grad=True
encoder.layer.7.attention.output.dense.weight: requires_grad=True
encoder.layer.7.attention.output.dense.bias: requires_grad=True
encoder.layer.7.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.7.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.7.intermediate.dense.weight: requires_grad=True
encoder.layer.7.intermediate.dense.bias: requires_grad=True
encoder.layer.7.output.dense.weight: requires_grad=True
encoder.layer.7.output.dense.bias: requires_grad=True
encoder.layer.7.output.LayerNorm.weight: requires_grad=True
encoder.layer.7.output.LayerNorm.bias: requires_grad=True
encoder.layer.8.attention.self.query.weight: requires_grad=True
encoder.layer.8.attention.self.query.bias: requires_grad=True
encoder.layer.8.attention.self.key.weight: requires_grad=True
encoder.layer.8.attention.self.key.bias: requires_grad=True
encoder.layer.8.attention.self.value.weight: requires_grad=True
encoder.layer.8.attention.self.value.bias: requires_grad=True
encoder.layer.8.attention.output.dense.weight: requires_grad=True
encoder.layer.8.attention.output.dense.bias: requires_grad=True
encoder.layer.8.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.8.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.8.intermediate.dense.weight: requires_grad=True
encoder.layer.8.intermediate.dense.bias: requires_grad=True
encoder.layer.8.output.dense.weight: requires_grad=True
encoder.layer.8.output.dense.bias: requires_grad=True
encoder.layer.8.output.LayerNorm.weight: requires_grad=True
encoder.layer.8.output.LayerNorm.bias: requires_grad=True
encoder.layer.9.attention.self.query.weight: requires_grad=True
encoder.layer.9.attention.self.query.bias: requires_grad=True
encoder.layer.9.attention.self.key.weight: requires_grad=True
encoder.layer.9.attention.self.key.bias: requires_grad=True
encoder.layer.9.attention.self.value.weight: requires_grad=True
encoder.layer.9.attention.self.value.bias: requires_grad=True
encoder.layer.9.attention.output.dense.weight: requires_grad=True
encoder.layer.9.attention.output.dense.bias: requires_grad=True
encoder.layer.9.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.9.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.9.intermediate.dense.weight: requires_grad=True
encoder.layer.9.intermediate.dense.bias: requires_grad=True
encoder.layer.9.output.dense.weight: requires_grad=True
encoder.layer.9.output.dense.bias: requires_grad=True
encoder.layer.9.output.LayerNorm.weight: requires_grad=True
encoder.layer.9.output.LayerNorm.bias: requires_grad=True
encoder.layer.10.attention.self.query.weight: requires_grad=True
encoder.layer.10.attention.self.query.bias: requires_grad=True
encoder.layer.10.attention.self.key.weight: requires_grad=True
encoder.layer.10.attention.self.key.bias: requires_grad=True
encoder.layer.10.attention.self.value.weight: requires_grad=True
encoder.layer.10.attention.self.value.bias: requires_grad=True
encoder.layer.10.attention.output.dense.weight: requires_grad=True
encoder.layer.10.attention.output.dense.bias: requires_grad=True
encoder.layer.10.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.10.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.10.intermediate.dense.weight: requires_grad=True
encoder.layer.10.intermediate.dense.bias: requires_grad=True
encoder.layer.10.output.dense.weight: requires_grad=True
encoder.layer.10.output.dense.bias: requires_grad=True
encoder.layer.10.output.LayerNorm.weight: requires_grad=True
encoder.layer.10.output.LayerNorm.bias: requires_grad=True
encoder.layer.11.attention.self.query.weight: requires_grad=True
encoder.layer.11.attention.self.query.bias: requires_grad=True
encoder.layer.11.attention.self.key.weight: requires_grad=True
encoder.layer.11.attention.self.key.bias: requires_grad=True
encoder.layer.11.attention.self.value.weight: requires_grad=True
encoder.layer.11.attention.self.value.bias: requires_grad=True
encoder.layer.11.attention.output.dense.weight: requires_grad=True
encoder.layer.11.attention.output.dense.bias: requires_grad=True
encoder.layer.11.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.11.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.11.intermediate.dense.weight: requires_grad=True
encoder.layer.11.intermediate.dense.bias: requires_grad=True
encoder.layer.11.output.dense.weight: requires_grad=True
encoder.layer.11.output.dense.bias: requires_grad=True
encoder.layer.11.output.LayerNorm.weight: requires_grad=True
encoder.layer.11.output.LayerNorm.bias: requires_grad=True

 Epoch 1 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.231
Validation Loss: 1.042
Validation Accuracy: 0.628

 Epoch 2 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.910
Validation Loss: 0.695
Validation Accuracy: 0.759

 Epoch 3 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.661
Validation Loss: 0.589
Validation Accuracy: 0.821

 Epoch 4 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.489
Validation Loss: 0.565
Validation Accuracy: 0.824

 Epoch 5 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.394
Validation Loss: 0.606
Validation Accuracy: 0.799

 Epoch 6 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.319
Validation Loss: 0.552
Validation Accuracy: 0.826

 Epoch 7 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.244
Validation Loss: 0.634
Validation Accuracy: 0.818

 Epoch 8 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.201
Validation Loss: 0.678
Validation Accuracy: 0.799

 Epoch 9 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.154
Validation Loss: 0.703
Validation Accuracy: 0.816

 Epoch 10 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.132
Validation Loss: 0.787
Validation Accuracy: 0.807

Test Accuracy: 0.808
== flag 1.601 electra result On test data ==
Test Accuracy: 0.808%
Precision: 0.8075
Recall: 0.8079
F1 Score: 0.8072
Classification Report:
              precision    recall  f1-score   support

           0       0.87      0.85      0.86       558
           1       0.79      0.86      0.82       358
           2       0.62      0.57      0.59       123
           3       0.79      0.78      0.78       382

    accuracy                           0.81      1421
   macro avg       0.77      0.76      0.77      1421
weighted avg       0.81      0.81      0.81      1421

Confusion Matrix:
[[474  28  11  45]
 [ 20 307  13  18]
 [ 18  20  70  15]
 [ 32  34  19 297]]
flag 1.11  model: electra has finished  : electra



===================================================== 
flag 1.10  model: gpt2 has started ==>   gpt2
===================================================== 
wte.weight: requires_grad=True
wpe.weight: requires_grad=True
h.0.ln_1.weight: requires_grad=True
h.0.ln_1.bias: requires_grad=True
h.0.attn.c_attn.weight: requires_grad=True
h.0.attn.c_attn.bias: requires_grad=True
h.0.attn.c_proj.weight: requires_grad=True
h.0.attn.c_proj.bias: requires_grad=True
h.0.ln_2.weight: requires_grad=True
h.0.ln_2.bias: requires_grad=True
h.0.mlp.c_fc.weight: requires_grad=True
h.0.mlp.c_fc.bias: requires_grad=True
h.0.mlp.c_proj.weight: requires_grad=True
h.0.mlp.c_proj.bias: requires_grad=True
h.1.ln_1.weight: requires_grad=True
h.1.ln_1.bias: requires_grad=True
h.1.attn.c_attn.weight: requires_grad=True
h.1.attn.c_attn.bias: requires_grad=True
h.1.attn.c_proj.weight: requires_grad=True
h.1.attn.c_proj.bias: requires_grad=True
h.1.ln_2.weight: requires_grad=True
h.1.ln_2.bias: requires_grad=True
h.1.mlp.c_fc.weight: requires_grad=True
h.1.mlp.c_fc.bias: requires_grad=True
h.1.mlp.c_proj.weight: requires_grad=True
h.1.mlp.c_proj.bias: requires_grad=True
h.2.ln_1.weight: requires_grad=True
h.2.ln_1.bias: requires_grad=True
h.2.attn.c_attn.weight: requires_grad=True
h.2.attn.c_attn.bias: requires_grad=True
h.2.attn.c_proj.weight: requires_grad=True
h.2.attn.c_proj.bias: requires_grad=True
h.2.ln_2.weight: requires_grad=True
h.2.ln_2.bias: requires_grad=True
h.2.mlp.c_fc.weight: requires_grad=True
h.2.mlp.c_fc.bias: requires_grad=True
h.2.mlp.c_proj.weight: requires_grad=True
h.2.mlp.c_proj.bias: requires_grad=True
h.3.ln_1.weight: requires_grad=True
h.3.ln_1.bias: requires_grad=True
h.3.attn.c_attn.weight: requires_grad=True
h.3.attn.c_attn.bias: requires_grad=True
h.3.attn.c_proj.weight: requires_grad=True
h.3.attn.c_proj.bias: requires_grad=True
h.3.ln_2.weight: requires_grad=True
h.3.ln_2.bias: requires_grad=True
h.3.mlp.c_fc.weight: requires_grad=True
h.3.mlp.c_fc.bias: requires_grad=True
h.3.mlp.c_proj.weight: requires_grad=True
h.3.mlp.c_proj.bias: requires_grad=True
h.4.ln_1.weight: requires_grad=True
h.4.ln_1.bias: requires_grad=True
h.4.attn.c_attn.weight: requires_grad=True
h.4.attn.c_attn.bias: requires_grad=True
h.4.attn.c_proj.weight: requires_grad=True
h.4.attn.c_proj.bias: requires_grad=True
h.4.ln_2.weight: requires_grad=True
h.4.ln_2.bias: requires_grad=True
h.4.mlp.c_fc.weight: requires_grad=True
h.4.mlp.c_fc.bias: requires_grad=True
h.4.mlp.c_proj.weight: requires_grad=True
h.4.mlp.c_proj.bias: requires_grad=True
h.5.ln_1.weight: requires_grad=True
h.5.ln_1.bias: requires_grad=True
h.5.attn.c_attn.weight: requires_grad=True
h.5.attn.c_attn.bias: requires_grad=True
h.5.attn.c_proj.weight: requires_grad=True
h.5.attn.c_proj.bias: requires_grad=True
h.5.ln_2.weight: requires_grad=True
h.5.ln_2.bias: requires_grad=True
h.5.mlp.c_fc.weight: requires_grad=True
h.5.mlp.c_fc.bias: requires_grad=True
h.5.mlp.c_proj.weight: requires_grad=True
h.5.mlp.c_proj.bias: requires_grad=True
h.6.ln_1.weight: requires_grad=True
h.6.ln_1.bias: requires_grad=True
h.6.attn.c_attn.weight: requires_grad=True
h.6.attn.c_attn.bias: requires_grad=True
h.6.attn.c_proj.weight: requires_grad=True
h.6.attn.c_proj.bias: requires_grad=True
h.6.ln_2.weight: requires_grad=True
h.6.ln_2.bias: requires_grad=True
h.6.mlp.c_fc.weight: requires_grad=True
h.6.mlp.c_fc.bias: requires_grad=True
h.6.mlp.c_proj.weight: requires_grad=True
h.6.mlp.c_proj.bias: requires_grad=True
h.7.ln_1.weight: requires_grad=True
h.7.ln_1.bias: requires_grad=True
h.7.attn.c_attn.weight: requires_grad=True
h.7.attn.c_attn.bias: requires_grad=True
h.7.attn.c_proj.weight: requires_grad=True
h.7.attn.c_proj.bias: requires_grad=True
h.7.ln_2.weight: requires_grad=True
h.7.ln_2.bias: requires_grad=True
h.7.mlp.c_fc.weight: requires_grad=True
h.7.mlp.c_fc.bias: requires_grad=True
h.7.mlp.c_proj.weight: requires_grad=True
h.7.mlp.c_proj.bias: requires_grad=True
h.8.ln_1.weight: requires_grad=True
h.8.ln_1.bias: requires_grad=True
h.8.attn.c_attn.weight: requires_grad=True
h.8.attn.c_attn.bias: requires_grad=True
h.8.attn.c_proj.weight: requires_grad=True
h.8.attn.c_proj.bias: requires_grad=True
h.8.ln_2.weight: requires_grad=True
h.8.ln_2.bias: requires_grad=True
h.8.mlp.c_fc.weight: requires_grad=True
h.8.mlp.c_fc.bias: requires_grad=True
h.8.mlp.c_proj.weight: requires_grad=True
h.8.mlp.c_proj.bias: requires_grad=True
h.9.ln_1.weight: requires_grad=True
h.9.ln_1.bias: requires_grad=True
h.9.attn.c_attn.weight: requires_grad=True
h.9.attn.c_attn.bias: requires_grad=True
h.9.attn.c_proj.weight: requires_grad=True
h.9.attn.c_proj.bias: requires_grad=True
h.9.ln_2.weight: requires_grad=True
h.9.ln_2.bias: requires_grad=True
h.9.mlp.c_fc.weight: requires_grad=True
h.9.mlp.c_fc.bias: requires_grad=True
h.9.mlp.c_proj.weight: requires_grad=True
h.9.mlp.c_proj.bias: requires_grad=True
h.10.ln_1.weight: requires_grad=True
h.10.ln_1.bias: requires_grad=True
h.10.attn.c_attn.weight: requires_grad=True
h.10.attn.c_attn.bias: requires_grad=True
h.10.attn.c_proj.weight: requires_grad=True
h.10.attn.c_proj.bias: requires_grad=True
h.10.ln_2.weight: requires_grad=True
h.10.ln_2.bias: requires_grad=True
h.10.mlp.c_fc.weight: requires_grad=True
h.10.mlp.c_fc.bias: requires_grad=True
h.10.mlp.c_proj.weight: requires_grad=True
h.10.mlp.c_proj.bias: requires_grad=True
h.11.ln_1.weight: requires_grad=True
h.11.ln_1.bias: requires_grad=True
h.11.attn.c_attn.weight: requires_grad=True
h.11.attn.c_attn.bias: requires_grad=True
h.11.attn.c_proj.weight: requires_grad=True
h.11.attn.c_proj.bias: requires_grad=True
h.11.ln_2.weight: requires_grad=True
h.11.ln_2.bias: requires_grad=True
h.11.mlp.c_fc.weight: requires_grad=True
h.11.mlp.c_fc.bias: requires_grad=True
h.11.mlp.c_proj.weight: requires_grad=True
h.11.mlp.c_proj.bias: requires_grad=True
ln_f.weight: requires_grad=True
ln_f.bias: requires_grad=True

 Epoch 1 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.443
Validation Loss: 1.184
Validation Accuracy: 0.430

 Epoch 2 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.131
Validation Loss: 0.916
Validation Accuracy: 0.679

 Epoch 3 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.826
Validation Loss: 0.710
Validation Accuracy: 0.738

 Epoch 4 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.652
Validation Loss: 0.670
Validation Accuracy: 0.754

 Epoch 5 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.553
Validation Loss: 0.626
Validation Accuracy: 0.773

 Epoch 6 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.494
Validation Loss: 0.622
Validation Accuracy: 0.773

 Epoch 7 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.415
Validation Loss: 0.640
Validation Accuracy: 0.762

 Epoch 8 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.373
Validation Loss: 0.688
Validation Accuracy: 0.759

 Epoch 9 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.321
Validation Loss: 0.688
Validation Accuracy: 0.767

 Epoch 10 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.295
Validation Loss: 0.705
Validation Accuracy: 0.767

Test Accuracy: 0.798
== flag 1.601 gpt2 result On test data ==
Test Accuracy: 0.798%
Precision: 0.7975
Recall: 0.7980
F1 Score: 0.7969
Classification Report:
              precision    recall  f1-score   support

           0       0.85      0.84      0.84       558
           1       0.78      0.83      0.81       358
           2       0.71      0.58      0.64       123
           3       0.76      0.78      0.77       382

    accuracy                           0.80      1421
   macro avg       0.78      0.76      0.76      1421
weighted avg       0.80      0.80      0.80      1421

Confusion Matrix:
[[466  33  11  48]
 [ 21 298  11  28]
 [ 19  17  71  16]
 [ 42  34   7 299]]
flag 1.11  model: gpt2 has finished  : gpt2



===================================================== 
flag 1.10  model: longformer has started ==>   longformer
===================================================== 
embeddings.word_embeddings.weight: requires_grad=True
embeddings.token_type_embeddings.weight: requires_grad=True
embeddings.LayerNorm.weight: requires_grad=True
embeddings.LayerNorm.bias: requires_grad=True
embeddings.position_embeddings.weight: requires_grad=True
encoder.layer.0.attention.self.query.weight: requires_grad=True
encoder.layer.0.attention.self.query.bias: requires_grad=True
encoder.layer.0.attention.self.key.weight: requires_grad=True
encoder.layer.0.attention.self.key.bias: requires_grad=True
encoder.layer.0.attention.self.value.weight: requires_grad=True
encoder.layer.0.attention.self.value.bias: requires_grad=True
encoder.layer.0.attention.self.query_global.weight: requires_grad=True
encoder.layer.0.attention.self.query_global.bias: requires_grad=True
encoder.layer.0.attention.self.key_global.weight: requires_grad=True
encoder.layer.0.attention.self.key_global.bias: requires_grad=True
encoder.layer.0.attention.self.value_global.weight: requires_grad=True
encoder.layer.0.attention.self.value_global.bias: requires_grad=True
encoder.layer.0.attention.output.dense.weight: requires_grad=True
encoder.layer.0.attention.output.dense.bias: requires_grad=True
encoder.layer.0.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.0.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.0.intermediate.dense.weight: requires_grad=True
encoder.layer.0.intermediate.dense.bias: requires_grad=True
encoder.layer.0.output.dense.weight: requires_grad=True
encoder.layer.0.output.dense.bias: requires_grad=True
encoder.layer.0.output.LayerNorm.weight: requires_grad=True
encoder.layer.0.output.LayerNorm.bias: requires_grad=True
encoder.layer.1.attention.self.query.weight: requires_grad=True
encoder.layer.1.attention.self.query.bias: requires_grad=True
encoder.layer.1.attention.self.key.weight: requires_grad=True
encoder.layer.1.attention.self.key.bias: requires_grad=True
encoder.layer.1.attention.self.value.weight: requires_grad=True
encoder.layer.1.attention.self.value.bias: requires_grad=True
encoder.layer.1.attention.self.query_global.weight: requires_grad=True
encoder.layer.1.attention.self.query_global.bias: requires_grad=True
encoder.layer.1.attention.self.key_global.weight: requires_grad=True
encoder.layer.1.attention.self.key_global.bias: requires_grad=True
encoder.layer.1.attention.self.value_global.weight: requires_grad=True
encoder.layer.1.attention.self.value_global.bias: requires_grad=True
encoder.layer.1.attention.output.dense.weight: requires_grad=True
encoder.layer.1.attention.output.dense.bias: requires_grad=True
encoder.layer.1.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.1.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.1.intermediate.dense.weight: requires_grad=True
encoder.layer.1.intermediate.dense.bias: requires_grad=True
encoder.layer.1.output.dense.weight: requires_grad=True
encoder.layer.1.output.dense.bias: requires_grad=True
encoder.layer.1.output.LayerNorm.weight: requires_grad=True
encoder.layer.1.output.LayerNorm.bias: requires_grad=True
encoder.layer.2.attention.self.query.weight: requires_grad=True
encoder.layer.2.attention.self.query.bias: requires_grad=True
encoder.layer.2.attention.self.key.weight: requires_grad=True
encoder.layer.2.attention.self.key.bias: requires_grad=True
encoder.layer.2.attention.self.value.weight: requires_grad=True
encoder.layer.2.attention.self.value.bias: requires_grad=True
encoder.layer.2.attention.self.query_global.weight: requires_grad=True
encoder.layer.2.attention.self.query_global.bias: requires_grad=True
encoder.layer.2.attention.self.key_global.weight: requires_grad=True
encoder.layer.2.attention.self.key_global.bias: requires_grad=True
encoder.layer.2.attention.self.value_global.weight: requires_grad=True
encoder.layer.2.attention.self.value_global.bias: requires_grad=True
encoder.layer.2.attention.output.dense.weight: requires_grad=True
encoder.layer.2.attention.output.dense.bias: requires_grad=True
encoder.layer.2.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.2.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.2.intermediate.dense.weight: requires_grad=True
encoder.layer.2.intermediate.dense.bias: requires_grad=True
encoder.layer.2.output.dense.weight: requires_grad=True
encoder.layer.2.output.dense.bias: requires_grad=True
encoder.layer.2.output.LayerNorm.weight: requires_grad=True
encoder.layer.2.output.LayerNorm.bias: requires_grad=True
encoder.layer.3.attention.self.query.weight: requires_grad=True
encoder.layer.3.attention.self.query.bias: requires_grad=True
encoder.layer.3.attention.self.key.weight: requires_grad=True
encoder.layer.3.attention.self.key.bias: requires_grad=True
encoder.layer.3.attention.self.value.weight: requires_grad=True
encoder.layer.3.attention.self.value.bias: requires_grad=True
encoder.layer.3.attention.self.query_global.weight: requires_grad=True
encoder.layer.3.attention.self.query_global.bias: requires_grad=True
encoder.layer.3.attention.self.key_global.weight: requires_grad=True
encoder.layer.3.attention.self.key_global.bias: requires_grad=True
encoder.layer.3.attention.self.value_global.weight: requires_grad=True
encoder.layer.3.attention.self.value_global.bias: requires_grad=True
encoder.layer.3.attention.output.dense.weight: requires_grad=True
encoder.layer.3.attention.output.dense.bias: requires_grad=True
encoder.layer.3.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.3.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.3.intermediate.dense.weight: requires_grad=True
encoder.layer.3.intermediate.dense.bias: requires_grad=True
encoder.layer.3.output.dense.weight: requires_grad=True
encoder.layer.3.output.dense.bias: requires_grad=True
encoder.layer.3.output.LayerNorm.weight: requires_grad=True
encoder.layer.3.output.LayerNorm.bias: requires_grad=True
encoder.layer.4.attention.self.query.weight: requires_grad=True
encoder.layer.4.attention.self.query.bias: requires_grad=True
encoder.layer.4.attention.self.key.weight: requires_grad=True
encoder.layer.4.attention.self.key.bias: requires_grad=True
encoder.layer.4.attention.self.value.weight: requires_grad=True
encoder.layer.4.attention.self.value.bias: requires_grad=True
encoder.layer.4.attention.self.query_global.weight: requires_grad=True
encoder.layer.4.attention.self.query_global.bias: requires_grad=True
encoder.layer.4.attention.self.key_global.weight: requires_grad=True
encoder.layer.4.attention.self.key_global.bias: requires_grad=True
encoder.layer.4.attention.self.value_global.weight: requires_grad=True
encoder.layer.4.attention.self.value_global.bias: requires_grad=True
encoder.layer.4.attention.output.dense.weight: requires_grad=True
encoder.layer.4.attention.output.dense.bias: requires_grad=True
encoder.layer.4.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.4.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.4.intermediate.dense.weight: requires_grad=True
encoder.layer.4.intermediate.dense.bias: requires_grad=True
encoder.layer.4.output.dense.weight: requires_grad=True
encoder.layer.4.output.dense.bias: requires_grad=True
encoder.layer.4.output.LayerNorm.weight: requires_grad=True
encoder.layer.4.output.LayerNorm.bias: requires_grad=True
encoder.layer.5.attention.self.query.weight: requires_grad=True
encoder.layer.5.attention.self.query.bias: requires_grad=True
encoder.layer.5.attention.self.key.weight: requires_grad=True
encoder.layer.5.attention.self.key.bias: requires_grad=True
encoder.layer.5.attention.self.value.weight: requires_grad=True
encoder.layer.5.attention.self.value.bias: requires_grad=True
encoder.layer.5.attention.self.query_global.weight: requires_grad=True
encoder.layer.5.attention.self.query_global.bias: requires_grad=True
encoder.layer.5.attention.self.key_global.weight: requires_grad=True
encoder.layer.5.attention.self.key_global.bias: requires_grad=True
encoder.layer.5.attention.self.value_global.weight: requires_grad=True
encoder.layer.5.attention.self.value_global.bias: requires_grad=True
encoder.layer.5.attention.output.dense.weight: requires_grad=True
encoder.layer.5.attention.output.dense.bias: requires_grad=True
encoder.layer.5.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.5.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.5.intermediate.dense.weight: requires_grad=True
encoder.layer.5.intermediate.dense.bias: requires_grad=True
encoder.layer.5.output.dense.weight: requires_grad=True
encoder.layer.5.output.dense.bias: requires_grad=True
encoder.layer.5.output.LayerNorm.weight: requires_grad=True
encoder.layer.5.output.LayerNorm.bias: requires_grad=True
encoder.layer.6.attention.self.query.weight: requires_grad=True
encoder.layer.6.attention.self.query.bias: requires_grad=True
encoder.layer.6.attention.self.key.weight: requires_grad=True
encoder.layer.6.attention.self.key.bias: requires_grad=True
encoder.layer.6.attention.self.value.weight: requires_grad=True
encoder.layer.6.attention.self.value.bias: requires_grad=True
encoder.layer.6.attention.self.query_global.weight: requires_grad=True
encoder.layer.6.attention.self.query_global.bias: requires_grad=True
encoder.layer.6.attention.self.key_global.weight: requires_grad=True
encoder.layer.6.attention.self.key_global.bias: requires_grad=True
encoder.layer.6.attention.self.value_global.weight: requires_grad=True
encoder.layer.6.attention.self.value_global.bias: requires_grad=True
encoder.layer.6.attention.output.dense.weight: requires_grad=True
encoder.layer.6.attention.output.dense.bias: requires_grad=True
encoder.layer.6.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.6.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.6.intermediate.dense.weight: requires_grad=True
encoder.layer.6.intermediate.dense.bias: requires_grad=True
encoder.layer.6.output.dense.weight: requires_grad=True
encoder.layer.6.output.dense.bias: requires_grad=True
encoder.layer.6.output.LayerNorm.weight: requires_grad=True
encoder.layer.6.output.LayerNorm.bias: requires_grad=True
encoder.layer.7.attention.self.query.weight: requires_grad=True
encoder.layer.7.attention.self.query.bias: requires_grad=True
encoder.layer.7.attention.self.key.weight: requires_grad=True
encoder.layer.7.attention.self.key.bias: requires_grad=True
encoder.layer.7.attention.self.value.weight: requires_grad=True
encoder.layer.7.attention.self.value.bias: requires_grad=True
encoder.layer.7.attention.self.query_global.weight: requires_grad=True
encoder.layer.7.attention.self.query_global.bias: requires_grad=True
encoder.layer.7.attention.self.key_global.weight: requires_grad=True
encoder.layer.7.attention.self.key_global.bias: requires_grad=True
encoder.layer.7.attention.self.value_global.weight: requires_grad=True
encoder.layer.7.attention.self.value_global.bias: requires_grad=True
encoder.layer.7.attention.output.dense.weight: requires_grad=True
encoder.layer.7.attention.output.dense.bias: requires_grad=True
encoder.layer.7.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.7.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.7.intermediate.dense.weight: requires_grad=True
encoder.layer.7.intermediate.dense.bias: requires_grad=True
encoder.layer.7.output.dense.weight: requires_grad=True
encoder.layer.7.output.dense.bias: requires_grad=True
encoder.layer.7.output.LayerNorm.weight: requires_grad=True
encoder.layer.7.output.LayerNorm.bias: requires_grad=True
encoder.layer.8.attention.self.query.weight: requires_grad=True
encoder.layer.8.attention.self.query.bias: requires_grad=True
encoder.layer.8.attention.self.key.weight: requires_grad=True
encoder.layer.8.attention.self.key.bias: requires_grad=True
encoder.layer.8.attention.self.value.weight: requires_grad=True
encoder.layer.8.attention.self.value.bias: requires_grad=True
encoder.layer.8.attention.self.query_global.weight: requires_grad=True
encoder.layer.8.attention.self.query_global.bias: requires_grad=True
encoder.layer.8.attention.self.key_global.weight: requires_grad=True
encoder.layer.8.attention.self.key_global.bias: requires_grad=True
encoder.layer.8.attention.self.value_global.weight: requires_grad=True
encoder.layer.8.attention.self.value_global.bias: requires_grad=True
encoder.layer.8.attention.output.dense.weight: requires_grad=True
encoder.layer.8.attention.output.dense.bias: requires_grad=True
encoder.layer.8.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.8.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.8.intermediate.dense.weight: requires_grad=True
encoder.layer.8.intermediate.dense.bias: requires_grad=True
encoder.layer.8.output.dense.weight: requires_grad=True
encoder.layer.8.output.dense.bias: requires_grad=True
encoder.layer.8.output.LayerNorm.weight: requires_grad=True
encoder.layer.8.output.LayerNorm.bias: requires_grad=True
encoder.layer.9.attention.self.query.weight: requires_grad=True
encoder.layer.9.attention.self.query.bias: requires_grad=True
encoder.layer.9.attention.self.key.weight: requires_grad=True
encoder.layer.9.attention.self.key.bias: requires_grad=True
encoder.layer.9.attention.self.value.weight: requires_grad=True
encoder.layer.9.attention.self.value.bias: requires_grad=True
encoder.layer.9.attention.self.query_global.weight: requires_grad=True
encoder.layer.9.attention.self.query_global.bias: requires_grad=True
encoder.layer.9.attention.self.key_global.weight: requires_grad=True
encoder.layer.9.attention.self.key_global.bias: requires_grad=True
encoder.layer.9.attention.self.value_global.weight: requires_grad=True
encoder.layer.9.attention.self.value_global.bias: requires_grad=True
encoder.layer.9.attention.output.dense.weight: requires_grad=True
encoder.layer.9.attention.output.dense.bias: requires_grad=True
encoder.layer.9.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.9.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.9.intermediate.dense.weight: requires_grad=True
encoder.layer.9.intermediate.dense.bias: requires_grad=True
encoder.layer.9.output.dense.weight: requires_grad=True
encoder.layer.9.output.dense.bias: requires_grad=True
encoder.layer.9.output.LayerNorm.weight: requires_grad=True
encoder.layer.9.output.LayerNorm.bias: requires_grad=True
encoder.layer.10.attention.self.query.weight: requires_grad=True
encoder.layer.10.attention.self.query.bias: requires_grad=True
encoder.layer.10.attention.self.key.weight: requires_grad=True
encoder.layer.10.attention.self.key.bias: requires_grad=True
encoder.layer.10.attention.self.value.weight: requires_grad=True
encoder.layer.10.attention.self.value.bias: requires_grad=True
encoder.layer.10.attention.self.query_global.weight: requires_grad=True
encoder.layer.10.attention.self.query_global.bias: requires_grad=True
encoder.layer.10.attention.self.key_global.weight: requires_grad=True
encoder.layer.10.attention.self.key_global.bias: requires_grad=True
encoder.layer.10.attention.self.value_global.weight: requires_grad=True
encoder.layer.10.attention.self.value_global.bias: requires_grad=True
encoder.layer.10.attention.output.dense.weight: requires_grad=True
encoder.layer.10.attention.output.dense.bias: requires_grad=True
encoder.layer.10.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.10.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.10.intermediate.dense.weight: requires_grad=True
encoder.layer.10.intermediate.dense.bias: requires_grad=True
encoder.layer.10.output.dense.weight: requires_grad=True
encoder.layer.10.output.dense.bias: requires_grad=True
encoder.layer.10.output.LayerNorm.weight: requires_grad=True
encoder.layer.10.output.LayerNorm.bias: requires_grad=True
encoder.layer.11.attention.self.query.weight: requires_grad=True
encoder.layer.11.attention.self.query.bias: requires_grad=True
encoder.layer.11.attention.self.key.weight: requires_grad=True
encoder.layer.11.attention.self.key.bias: requires_grad=True
encoder.layer.11.attention.self.value.weight: requires_grad=True
encoder.layer.11.attention.self.value.bias: requires_grad=True
encoder.layer.11.attention.self.query_global.weight: requires_grad=True
encoder.layer.11.attention.self.query_global.bias: requires_grad=True
encoder.layer.11.attention.self.key_global.weight: requires_grad=True
encoder.layer.11.attention.self.key_global.bias: requires_grad=True
encoder.layer.11.attention.self.value_global.weight: requires_grad=True
encoder.layer.11.attention.self.value_global.bias: requires_grad=True
encoder.layer.11.attention.output.dense.weight: requires_grad=True
encoder.layer.11.attention.output.dense.bias: requires_grad=True
encoder.layer.11.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.11.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.11.intermediate.dense.weight: requires_grad=True
encoder.layer.11.intermediate.dense.bias: requires_grad=True
encoder.layer.11.output.dense.weight: requires_grad=True
encoder.layer.11.output.dense.bias: requires_grad=True
encoder.layer.11.output.LayerNorm.weight: requires_grad=True
encoder.layer.11.output.LayerNorm.bias: requires_grad=True
pooler.dense.weight: requires_grad=True
pooler.dense.bias: requires_grad=True

 Epoch 1 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.097
Validation Loss: 0.727
Validation Accuracy: 0.759

 Epoch 2 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.654
Validation Loss: 0.614
Validation Accuracy: 0.799

 Epoch 3 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.490
Validation Loss: 0.633
Validation Accuracy: 0.797

 Epoch 4 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.404
Validation Loss: 0.619
Validation Accuracy: 0.807

 Epoch 5 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.314
Validation Loss: 0.674
Validation Accuracy: 0.794

 Epoch 6 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.264
Validation Loss: 0.712
Validation Accuracy: 0.789

 Epoch 7 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.220
Validation Loss: 0.693
Validation Accuracy: 0.802

 Epoch 8 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.176
Validation Loss: 0.763
Validation Accuracy: 0.794

 Epoch 9 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.126
Validation Loss: 0.979
Validation Accuracy: 0.775

 Epoch 10 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.101
Validation Loss: 0.960
Validation Accuracy: 0.781

Test Accuracy: 0.799
== flag 1.601 longformer result On test data ==
Test Accuracy: 0.799%
Precision: 0.7965
Recall: 0.7987
F1 Score: 0.7956
Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.90      0.85       558
           1       0.82      0.82      0.82       358
           2       0.66      0.54      0.60       123
           3       0.80      0.72      0.76       382

    accuracy                           0.80      1421
   macro avg       0.77      0.74      0.76      1421
weighted avg       0.80      0.80      0.80      1421

Confusion Matrix:
[[500  19   9  30]
 [ 26 292  17  23]
 [ 29  13  67  14]
 [ 65  32   9 276]]
flag 1.11  model: longformer has finished  : longformer



===================================================== 
flag 1.10  model: luke has started ==>   luke
===================================================== 
embeddings.word_embeddings.weight: requires_grad=True
embeddings.position_embeddings.weight: requires_grad=True
embeddings.token_type_embeddings.weight: requires_grad=True
embeddings.LayerNorm.weight: requires_grad=True
embeddings.LayerNorm.bias: requires_grad=True
entity_embeddings.entity_embeddings.weight: requires_grad=True
entity_embeddings.entity_embedding_dense.weight: requires_grad=True
entity_embeddings.position_embeddings.weight: requires_grad=True
entity_embeddings.token_type_embeddings.weight: requires_grad=True
entity_embeddings.LayerNorm.weight: requires_grad=True
entity_embeddings.LayerNorm.bias: requires_grad=True
encoder.layer.0.attention.self.query.weight: requires_grad=True
encoder.layer.0.attention.self.query.bias: requires_grad=True
encoder.layer.0.attention.self.key.weight: requires_grad=True
encoder.layer.0.attention.self.key.bias: requires_grad=True
encoder.layer.0.attention.self.value.weight: requires_grad=True
encoder.layer.0.attention.self.value.bias: requires_grad=True
encoder.layer.0.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.0.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.0.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.0.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.0.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.0.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.0.attention.output.dense.weight: requires_grad=True
encoder.layer.0.attention.output.dense.bias: requires_grad=True
encoder.layer.0.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.0.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.0.intermediate.dense.weight: requires_grad=True
encoder.layer.0.intermediate.dense.bias: requires_grad=True
encoder.layer.0.output.dense.weight: requires_grad=True
encoder.layer.0.output.dense.bias: requires_grad=True
encoder.layer.0.output.LayerNorm.weight: requires_grad=True
encoder.layer.0.output.LayerNorm.bias: requires_grad=True
encoder.layer.1.attention.self.query.weight: requires_grad=True
encoder.layer.1.attention.self.query.bias: requires_grad=True
encoder.layer.1.attention.self.key.weight: requires_grad=True
encoder.layer.1.attention.self.key.bias: requires_grad=True
encoder.layer.1.attention.self.value.weight: requires_grad=True
encoder.layer.1.attention.self.value.bias: requires_grad=True
encoder.layer.1.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.1.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.1.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.1.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.1.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.1.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.1.attention.output.dense.weight: requires_grad=True
encoder.layer.1.attention.output.dense.bias: requires_grad=True
encoder.layer.1.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.1.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.1.intermediate.dense.weight: requires_grad=True
encoder.layer.1.intermediate.dense.bias: requires_grad=True
encoder.layer.1.output.dense.weight: requires_grad=True
encoder.layer.1.output.dense.bias: requires_grad=True
encoder.layer.1.output.LayerNorm.weight: requires_grad=True
encoder.layer.1.output.LayerNorm.bias: requires_grad=True
encoder.layer.2.attention.self.query.weight: requires_grad=True
encoder.layer.2.attention.self.query.bias: requires_grad=True
encoder.layer.2.attention.self.key.weight: requires_grad=True
encoder.layer.2.attention.self.key.bias: requires_grad=True
encoder.layer.2.attention.self.value.weight: requires_grad=True
encoder.layer.2.attention.self.value.bias: requires_grad=True
encoder.layer.2.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.2.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.2.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.2.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.2.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.2.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.2.attention.output.dense.weight: requires_grad=True
encoder.layer.2.attention.output.dense.bias: requires_grad=True
encoder.layer.2.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.2.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.2.intermediate.dense.weight: requires_grad=True
encoder.layer.2.intermediate.dense.bias: requires_grad=True
encoder.layer.2.output.dense.weight: requires_grad=True
encoder.layer.2.output.dense.bias: requires_grad=True
encoder.layer.2.output.LayerNorm.weight: requires_grad=True
encoder.layer.2.output.LayerNorm.bias: requires_grad=True
encoder.layer.3.attention.self.query.weight: requires_grad=True
encoder.layer.3.attention.self.query.bias: requires_grad=True
encoder.layer.3.attention.self.key.weight: requires_grad=True
encoder.layer.3.attention.self.key.bias: requires_grad=True
encoder.layer.3.attention.self.value.weight: requires_grad=True
encoder.layer.3.attention.self.value.bias: requires_grad=True
encoder.layer.3.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.3.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.3.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.3.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.3.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.3.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.3.attention.output.dense.weight: requires_grad=True
encoder.layer.3.attention.output.dense.bias: requires_grad=True
encoder.layer.3.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.3.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.3.intermediate.dense.weight: requires_grad=True
encoder.layer.3.intermediate.dense.bias: requires_grad=True
encoder.layer.3.output.dense.weight: requires_grad=True
encoder.layer.3.output.dense.bias: requires_grad=True
encoder.layer.3.output.LayerNorm.weight: requires_grad=True
encoder.layer.3.output.LayerNorm.bias: requires_grad=True
encoder.layer.4.attention.self.query.weight: requires_grad=True
encoder.layer.4.attention.self.query.bias: requires_grad=True
encoder.layer.4.attention.self.key.weight: requires_grad=True
encoder.layer.4.attention.self.key.bias: requires_grad=True
encoder.layer.4.attention.self.value.weight: requires_grad=True
encoder.layer.4.attention.self.value.bias: requires_grad=True
encoder.layer.4.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.4.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.4.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.4.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.4.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.4.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.4.attention.output.dense.weight: requires_grad=True
encoder.layer.4.attention.output.dense.bias: requires_grad=True
encoder.layer.4.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.4.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.4.intermediate.dense.weight: requires_grad=True
encoder.layer.4.intermediate.dense.bias: requires_grad=True
encoder.layer.4.output.dense.weight: requires_grad=True
encoder.layer.4.output.dense.bias: requires_grad=True
encoder.layer.4.output.LayerNorm.weight: requires_grad=True
encoder.layer.4.output.LayerNorm.bias: requires_grad=True
encoder.layer.5.attention.self.query.weight: requires_grad=True
encoder.layer.5.attention.self.query.bias: requires_grad=True
encoder.layer.5.attention.self.key.weight: requires_grad=True
encoder.layer.5.attention.self.key.bias: requires_grad=True
encoder.layer.5.attention.self.value.weight: requires_grad=True
encoder.layer.5.attention.self.value.bias: requires_grad=True
encoder.layer.5.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.5.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.5.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.5.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.5.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.5.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.5.attention.output.dense.weight: requires_grad=True
encoder.layer.5.attention.output.dense.bias: requires_grad=True
encoder.layer.5.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.5.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.5.intermediate.dense.weight: requires_grad=True
encoder.layer.5.intermediate.dense.bias: requires_grad=True
encoder.layer.5.output.dense.weight: requires_grad=True
encoder.layer.5.output.dense.bias: requires_grad=True
encoder.layer.5.output.LayerNorm.weight: requires_grad=True
encoder.layer.5.output.LayerNorm.bias: requires_grad=True
encoder.layer.6.attention.self.query.weight: requires_grad=True
encoder.layer.6.attention.self.query.bias: requires_grad=True
encoder.layer.6.attention.self.key.weight: requires_grad=True
encoder.layer.6.attention.self.key.bias: requires_grad=True
encoder.layer.6.attention.self.value.weight: requires_grad=True
encoder.layer.6.attention.self.value.bias: requires_grad=True
encoder.layer.6.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.6.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.6.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.6.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.6.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.6.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.6.attention.output.dense.weight: requires_grad=True
encoder.layer.6.attention.output.dense.bias: requires_grad=True
encoder.layer.6.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.6.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.6.intermediate.dense.weight: requires_grad=True
encoder.layer.6.intermediate.dense.bias: requires_grad=True
encoder.layer.6.output.dense.weight: requires_grad=True
encoder.layer.6.output.dense.bias: requires_grad=True
encoder.layer.6.output.LayerNorm.weight: requires_grad=True
encoder.layer.6.output.LayerNorm.bias: requires_grad=True
encoder.layer.7.attention.self.query.weight: requires_grad=True
encoder.layer.7.attention.self.query.bias: requires_grad=True
encoder.layer.7.attention.self.key.weight: requires_grad=True
encoder.layer.7.attention.self.key.bias: requires_grad=True
encoder.layer.7.attention.self.value.weight: requires_grad=True
encoder.layer.7.attention.self.value.bias: requires_grad=True
encoder.layer.7.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.7.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.7.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.7.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.7.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.7.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.7.attention.output.dense.weight: requires_grad=True
encoder.layer.7.attention.output.dense.bias: requires_grad=True
encoder.layer.7.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.7.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.7.intermediate.dense.weight: requires_grad=True
encoder.layer.7.intermediate.dense.bias: requires_grad=True
encoder.layer.7.output.dense.weight: requires_grad=True
encoder.layer.7.output.dense.bias: requires_grad=True
encoder.layer.7.output.LayerNorm.weight: requires_grad=True
encoder.layer.7.output.LayerNorm.bias: requires_grad=True
encoder.layer.8.attention.self.query.weight: requires_grad=True
encoder.layer.8.attention.self.query.bias: requires_grad=True
encoder.layer.8.attention.self.key.weight: requires_grad=True
encoder.layer.8.attention.self.key.bias: requires_grad=True
encoder.layer.8.attention.self.value.weight: requires_grad=True
encoder.layer.8.attention.self.value.bias: requires_grad=True
encoder.layer.8.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.8.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.8.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.8.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.8.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.8.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.8.attention.output.dense.weight: requires_grad=True
encoder.layer.8.attention.output.dense.bias: requires_grad=True
encoder.layer.8.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.8.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.8.intermediate.dense.weight: requires_grad=True
encoder.layer.8.intermediate.dense.bias: requires_grad=True
encoder.layer.8.output.dense.weight: requires_grad=True
encoder.layer.8.output.dense.bias: requires_grad=True
encoder.layer.8.output.LayerNorm.weight: requires_grad=True
encoder.layer.8.output.LayerNorm.bias: requires_grad=True
encoder.layer.9.attention.self.query.weight: requires_grad=True
encoder.layer.9.attention.self.query.bias: requires_grad=True
encoder.layer.9.attention.self.key.weight: requires_grad=True
encoder.layer.9.attention.self.key.bias: requires_grad=True
encoder.layer.9.attention.self.value.weight: requires_grad=True
encoder.layer.9.attention.self.value.bias: requires_grad=True
encoder.layer.9.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.9.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.9.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.9.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.9.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.9.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.9.attention.output.dense.weight: requires_grad=True
encoder.layer.9.attention.output.dense.bias: requires_grad=True
encoder.layer.9.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.9.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.9.intermediate.dense.weight: requires_grad=True
encoder.layer.9.intermediate.dense.bias: requires_grad=True
encoder.layer.9.output.dense.weight: requires_grad=True
encoder.layer.9.output.dense.bias: requires_grad=True
encoder.layer.9.output.LayerNorm.weight: requires_grad=True
encoder.layer.9.output.LayerNorm.bias: requires_grad=True
encoder.layer.10.attention.self.query.weight: requires_grad=True
encoder.layer.10.attention.self.query.bias: requires_grad=True
encoder.layer.10.attention.self.key.weight: requires_grad=True
encoder.layer.10.attention.self.key.bias: requires_grad=True
encoder.layer.10.attention.self.value.weight: requires_grad=True
encoder.layer.10.attention.self.value.bias: requires_grad=True
encoder.layer.10.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.10.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.10.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.10.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.10.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.10.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.10.attention.output.dense.weight: requires_grad=True
encoder.layer.10.attention.output.dense.bias: requires_grad=True
encoder.layer.10.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.10.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.10.intermediate.dense.weight: requires_grad=True
encoder.layer.10.intermediate.dense.bias: requires_grad=True
encoder.layer.10.output.dense.weight: requires_grad=True
encoder.layer.10.output.dense.bias: requires_grad=True
encoder.layer.10.output.LayerNorm.weight: requires_grad=True
encoder.layer.10.output.LayerNorm.bias: requires_grad=True
encoder.layer.11.attention.self.query.weight: requires_grad=True
encoder.layer.11.attention.self.query.bias: requires_grad=True
encoder.layer.11.attention.self.key.weight: requires_grad=True
encoder.layer.11.attention.self.key.bias: requires_grad=True
encoder.layer.11.attention.self.value.weight: requires_grad=True
encoder.layer.11.attention.self.value.bias: requires_grad=True
encoder.layer.11.attention.self.w2e_query.weight: requires_grad=True
encoder.layer.11.attention.self.w2e_query.bias: requires_grad=True
encoder.layer.11.attention.self.e2w_query.weight: requires_grad=True
encoder.layer.11.attention.self.e2w_query.bias: requires_grad=True
encoder.layer.11.attention.self.e2e_query.weight: requires_grad=True
encoder.layer.11.attention.self.e2e_query.bias: requires_grad=True
encoder.layer.11.attention.output.dense.weight: requires_grad=True
encoder.layer.11.attention.output.dense.bias: requires_grad=True
encoder.layer.11.attention.output.LayerNorm.weight: requires_grad=True
encoder.layer.11.attention.output.LayerNorm.bias: requires_grad=True
encoder.layer.11.intermediate.dense.weight: requires_grad=True
encoder.layer.11.intermediate.dense.bias: requires_grad=True
encoder.layer.11.output.dense.weight: requires_grad=True
encoder.layer.11.output.dense.bias: requires_grad=True
encoder.layer.11.output.LayerNorm.weight: requires_grad=True
encoder.layer.11.output.LayerNorm.bias: requires_grad=True
pooler.dense.weight: requires_grad=True
pooler.dense.bias: requires_grad=True

 Epoch 1 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.131
Validation Loss: 0.788
Validation Accuracy: 0.725

 Epoch 2 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.647
Validation Loss: 0.692
Validation Accuracy: 0.759

 Epoch 3 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.496
Validation Loss: 0.637
Validation Accuracy: 0.778

 Epoch 4 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.385
Validation Loss: 0.653
Validation Accuracy: 0.791

 Epoch 5 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.297
Validation Loss: 0.639
Validation Accuracy: 0.781

 Epoch 6 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.242
Validation Loss: 0.725
Validation Accuracy: 0.789

 Epoch 7 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.193
Validation Loss: 0.915
Validation Accuracy: 0.765

 Epoch 8 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.166
Validation Loss: 0.751
Validation Accuracy: 0.783

 Epoch 9 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.115
Validation Loss: 0.887
Validation Accuracy: 0.789

 Epoch 10 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.106
Validation Loss: 1.076
Validation Accuracy: 0.775

Test Accuracy: 0.816
== flag 1.601 luke result On test data ==
Test Accuracy: 0.816%
Precision: 0.8183
Recall: 0.8163
F1 Score: 0.8168
Classification Report:
              precision    recall  f1-score   support

           0       0.87      0.84      0.85       558
           1       0.85      0.83      0.84       358
           2       0.70      0.68      0.69       123
           3       0.76      0.82      0.78       382

    accuracy                           0.82      1421
   macro avg       0.79      0.79      0.79      1421
weighted avg       0.82      0.82      0.82      1421

Confusion Matrix:
[[468  20  16  54]
 [ 20 296  12  30]
 [ 12  10  84  17]
 [ 41  21   8 312]]
flag 1.11  model: luke has finished  : luke



===================================================== 
flag 1.10  model: t5 has started ==>   t5
===================================================== 
shared.weight: requires_grad=True
encoder.block.0.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.0.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.0.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.0.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: requires_grad=True
encoder.block.0.layer.0.layer_norm.weight: requires_grad=True
encoder.block.0.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.0.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.0.layer.1.layer_norm.weight: requires_grad=True
encoder.block.1.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.1.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.1.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.1.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.1.layer.0.layer_norm.weight: requires_grad=True
encoder.block.1.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.1.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.1.layer.1.layer_norm.weight: requires_grad=True
encoder.block.2.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.2.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.2.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.2.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.2.layer.0.layer_norm.weight: requires_grad=True
encoder.block.2.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.2.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.2.layer.1.layer_norm.weight: requires_grad=True
encoder.block.3.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.3.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.3.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.3.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.3.layer.0.layer_norm.weight: requires_grad=True
encoder.block.3.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.3.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.3.layer.1.layer_norm.weight: requires_grad=True
encoder.block.4.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.4.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.4.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.4.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.4.layer.0.layer_norm.weight: requires_grad=True
encoder.block.4.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.4.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.4.layer.1.layer_norm.weight: requires_grad=True
encoder.block.5.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.5.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.5.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.5.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.5.layer.0.layer_norm.weight: requires_grad=True
encoder.block.5.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.5.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.5.layer.1.layer_norm.weight: requires_grad=True
encoder.block.6.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.6.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.6.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.6.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.6.layer.0.layer_norm.weight: requires_grad=True
encoder.block.6.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.6.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.6.layer.1.layer_norm.weight: requires_grad=True
encoder.block.7.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.7.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.7.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.7.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.7.layer.0.layer_norm.weight: requires_grad=True
encoder.block.7.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.7.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.7.layer.1.layer_norm.weight: requires_grad=True
encoder.block.8.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.8.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.8.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.8.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.8.layer.0.layer_norm.weight: requires_grad=True
encoder.block.8.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.8.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.8.layer.1.layer_norm.weight: requires_grad=True
encoder.block.9.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.9.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.9.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.9.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.9.layer.0.layer_norm.weight: requires_grad=True
encoder.block.9.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.9.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.9.layer.1.layer_norm.weight: requires_grad=True
encoder.block.10.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.10.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.10.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.10.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.10.layer.0.layer_norm.weight: requires_grad=True
encoder.block.10.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.10.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.10.layer.1.layer_norm.weight: requires_grad=True
encoder.block.11.layer.0.SelfAttention.q.weight: requires_grad=True
encoder.block.11.layer.0.SelfAttention.k.weight: requires_grad=True
encoder.block.11.layer.0.SelfAttention.v.weight: requires_grad=True
encoder.block.11.layer.0.SelfAttention.o.weight: requires_grad=True
encoder.block.11.layer.0.layer_norm.weight: requires_grad=True
encoder.block.11.layer.1.DenseReluDense.wi.weight: requires_grad=True
encoder.block.11.layer.1.DenseReluDense.wo.weight: requires_grad=True
encoder.block.11.layer.1.layer_norm.weight: requires_grad=True
encoder.final_layer_norm.weight: requires_grad=True
decoder.block.0.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.0.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.0.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.0.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight: requires_grad=True
decoder.block.0.layer.0.layer_norm.weight: requires_grad=True
decoder.block.0.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.0.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.0.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.0.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.0.layer.1.layer_norm.weight: requires_grad=True
decoder.block.0.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.0.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.0.layer.2.layer_norm.weight: requires_grad=True
decoder.block.1.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.1.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.1.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.1.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.1.layer.0.layer_norm.weight: requires_grad=True
decoder.block.1.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.1.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.1.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.1.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.1.layer.1.layer_norm.weight: requires_grad=True
decoder.block.1.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.1.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.1.layer.2.layer_norm.weight: requires_grad=True
decoder.block.2.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.2.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.2.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.2.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.2.layer.0.layer_norm.weight: requires_grad=True
decoder.block.2.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.2.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.2.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.2.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.2.layer.1.layer_norm.weight: requires_grad=True
decoder.block.2.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.2.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.2.layer.2.layer_norm.weight: requires_grad=True
decoder.block.3.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.3.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.3.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.3.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.3.layer.0.layer_norm.weight: requires_grad=True
decoder.block.3.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.3.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.3.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.3.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.3.layer.1.layer_norm.weight: requires_grad=True
decoder.block.3.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.3.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.3.layer.2.layer_norm.weight: requires_grad=True
decoder.block.4.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.4.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.4.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.4.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.4.layer.0.layer_norm.weight: requires_grad=True
decoder.block.4.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.4.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.4.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.4.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.4.layer.1.layer_norm.weight: requires_grad=True
decoder.block.4.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.4.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.4.layer.2.layer_norm.weight: requires_grad=True
decoder.block.5.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.5.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.5.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.5.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.5.layer.0.layer_norm.weight: requires_grad=True
decoder.block.5.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.5.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.5.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.5.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.5.layer.1.layer_norm.weight: requires_grad=True
decoder.block.5.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.5.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.5.layer.2.layer_norm.weight: requires_grad=True
decoder.block.6.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.6.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.6.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.6.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.6.layer.0.layer_norm.weight: requires_grad=True
decoder.block.6.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.6.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.6.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.6.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.6.layer.1.layer_norm.weight: requires_grad=True
decoder.block.6.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.6.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.6.layer.2.layer_norm.weight: requires_grad=True
decoder.block.7.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.7.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.7.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.7.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.7.layer.0.layer_norm.weight: requires_grad=True
decoder.block.7.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.7.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.7.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.7.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.7.layer.1.layer_norm.weight: requires_grad=True
decoder.block.7.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.7.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.7.layer.2.layer_norm.weight: requires_grad=True
decoder.block.8.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.8.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.8.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.8.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.8.layer.0.layer_norm.weight: requires_grad=True
decoder.block.8.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.8.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.8.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.8.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.8.layer.1.layer_norm.weight: requires_grad=True
decoder.block.8.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.8.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.8.layer.2.layer_norm.weight: requires_grad=True
decoder.block.9.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.9.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.9.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.9.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.9.layer.0.layer_norm.weight: requires_grad=True
decoder.block.9.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.9.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.9.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.9.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.9.layer.1.layer_norm.weight: requires_grad=True
decoder.block.9.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.9.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.9.layer.2.layer_norm.weight: requires_grad=True
decoder.block.10.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.10.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.10.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.10.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.10.layer.0.layer_norm.weight: requires_grad=True
decoder.block.10.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.10.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.10.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.10.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.10.layer.1.layer_norm.weight: requires_grad=True
decoder.block.10.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.10.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.10.layer.2.layer_norm.weight: requires_grad=True
decoder.block.11.layer.0.SelfAttention.q.weight: requires_grad=True
decoder.block.11.layer.0.SelfAttention.k.weight: requires_grad=True
decoder.block.11.layer.0.SelfAttention.v.weight: requires_grad=True
decoder.block.11.layer.0.SelfAttention.o.weight: requires_grad=True
decoder.block.11.layer.0.layer_norm.weight: requires_grad=True
decoder.block.11.layer.1.EncDecAttention.q.weight: requires_grad=True
decoder.block.11.layer.1.EncDecAttention.k.weight: requires_grad=True
decoder.block.11.layer.1.EncDecAttention.v.weight: requires_grad=True
decoder.block.11.layer.1.EncDecAttention.o.weight: requires_grad=True
decoder.block.11.layer.1.layer_norm.weight: requires_grad=True
decoder.block.11.layer.2.DenseReluDense.wi.weight: requires_grad=True
decoder.block.11.layer.2.DenseReluDense.wo.weight: requires_grad=True
decoder.block.11.layer.2.layer_norm.weight: requires_grad=True
decoder.final_layer_norm.weight: requires_grad=True

 Epoch 1 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.361
Validation Loss: 1.302
Validation Accuracy: 0.428

 Epoch 2 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.287
Validation Loss: 1.250
Validation Accuracy: 0.428

 Epoch 3 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.251
Validation Loss: 1.214
Validation Accuracy: 0.428

 Epoch 4 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.214
Validation Loss: 1.143
Validation Accuracy: 0.439

 Epoch 5 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.138
Validation Loss: 1.024
Validation Accuracy: 0.564

 Epoch 6 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.026
Validation Loss: 0.918
Validation Accuracy: 0.668

 Epoch 7 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.923
Validation Loss: 0.854
Validation Accuracy: 0.693

 Epoch 8 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.832
Validation Loss: 0.772
Validation Accuracy: 0.717

 Epoch 9 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.749
Validation Loss: 0.726
Validation Accuracy: 0.727

 Epoch 10 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.677
Validation Loss: 0.706
Validation Accuracy: 0.738

Test Accuracy: 0.762
== flag 1.601 t5 result On test data ==
Test Accuracy: 0.762%
Precision: 0.6982
Recall: 0.7621
F1 Score: 0.7282
Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.88      0.86       558
           1       0.71      0.85      0.77       358
           2       0.00      0.00      0.00       123
           3       0.71      0.76      0.73       382

    accuracy                           0.76      1421
   macro avg       0.56      0.62      0.59      1421
weighted avg       0.70      0.76      0.73      1421

Confusion Matrix:
[[490  18   0  50]
 [ 24 304   0  30]
 [ 17  69   0  37]
 [ 55  38   0 289]]
flag 1.11  model: t5 has finished  : t5



===================================================== 
flag 1.10  model: xlnet has started ==>   xlnet
===================================================== 
mask_emb: requires_grad=True
word_embedding.weight: requires_grad=True
layer.0.rel_attn.q: requires_grad=True
layer.0.rel_attn.k: requires_grad=True
layer.0.rel_attn.v: requires_grad=True
layer.0.rel_attn.o: requires_grad=True
layer.0.rel_attn.r: requires_grad=True
layer.0.rel_attn.r_r_bias: requires_grad=True
layer.0.rel_attn.r_s_bias: requires_grad=True
layer.0.rel_attn.r_w_bias: requires_grad=True
layer.0.rel_attn.seg_embed: requires_grad=True
layer.0.rel_attn.layer_norm.weight: requires_grad=True
layer.0.rel_attn.layer_norm.bias: requires_grad=True
layer.0.ff.layer_norm.weight: requires_grad=True
layer.0.ff.layer_norm.bias: requires_grad=True
layer.0.ff.layer_1.weight: requires_grad=True
layer.0.ff.layer_1.bias: requires_grad=True
layer.0.ff.layer_2.weight: requires_grad=True
layer.0.ff.layer_2.bias: requires_grad=True
layer.1.rel_attn.q: requires_grad=True
layer.1.rel_attn.k: requires_grad=True
layer.1.rel_attn.v: requires_grad=True
layer.1.rel_attn.o: requires_grad=True
layer.1.rel_attn.r: requires_grad=True
layer.1.rel_attn.r_r_bias: requires_grad=True
layer.1.rel_attn.r_s_bias: requires_grad=True
layer.1.rel_attn.r_w_bias: requires_grad=True
layer.1.rel_attn.seg_embed: requires_grad=True
layer.1.rel_attn.layer_norm.weight: requires_grad=True
layer.1.rel_attn.layer_norm.bias: requires_grad=True
layer.1.ff.layer_norm.weight: requires_grad=True
layer.1.ff.layer_norm.bias: requires_grad=True
layer.1.ff.layer_1.weight: requires_grad=True
layer.1.ff.layer_1.bias: requires_grad=True
layer.1.ff.layer_2.weight: requires_grad=True
layer.1.ff.layer_2.bias: requires_grad=True
layer.2.rel_attn.q: requires_grad=True
layer.2.rel_attn.k: requires_grad=True
layer.2.rel_attn.v: requires_grad=True
layer.2.rel_attn.o: requires_grad=True
layer.2.rel_attn.r: requires_grad=True
layer.2.rel_attn.r_r_bias: requires_grad=True
layer.2.rel_attn.r_s_bias: requires_grad=True
layer.2.rel_attn.r_w_bias: requires_grad=True
layer.2.rel_attn.seg_embed: requires_grad=True
layer.2.rel_attn.layer_norm.weight: requires_grad=True
layer.2.rel_attn.layer_norm.bias: requires_grad=True
layer.2.ff.layer_norm.weight: requires_grad=True
layer.2.ff.layer_norm.bias: requires_grad=True
layer.2.ff.layer_1.weight: requires_grad=True
layer.2.ff.layer_1.bias: requires_grad=True
layer.2.ff.layer_2.weight: requires_grad=True
layer.2.ff.layer_2.bias: requires_grad=True
layer.3.rel_attn.q: requires_grad=True
layer.3.rel_attn.k: requires_grad=True
layer.3.rel_attn.v: requires_grad=True
layer.3.rel_attn.o: requires_grad=True
layer.3.rel_attn.r: requires_grad=True
layer.3.rel_attn.r_r_bias: requires_grad=True
layer.3.rel_attn.r_s_bias: requires_grad=True
layer.3.rel_attn.r_w_bias: requires_grad=True
layer.3.rel_attn.seg_embed: requires_grad=True
layer.3.rel_attn.layer_norm.weight: requires_grad=True
layer.3.rel_attn.layer_norm.bias: requires_grad=True
layer.3.ff.layer_norm.weight: requires_grad=True
layer.3.ff.layer_norm.bias: requires_grad=True
layer.3.ff.layer_1.weight: requires_grad=True
layer.3.ff.layer_1.bias: requires_grad=True
layer.3.ff.layer_2.weight: requires_grad=True
layer.3.ff.layer_2.bias: requires_grad=True
layer.4.rel_attn.q: requires_grad=True
layer.4.rel_attn.k: requires_grad=True
layer.4.rel_attn.v: requires_grad=True
layer.4.rel_attn.o: requires_grad=True
layer.4.rel_attn.r: requires_grad=True
layer.4.rel_attn.r_r_bias: requires_grad=True
layer.4.rel_attn.r_s_bias: requires_grad=True
layer.4.rel_attn.r_w_bias: requires_grad=True
layer.4.rel_attn.seg_embed: requires_grad=True
layer.4.rel_attn.layer_norm.weight: requires_grad=True
layer.4.rel_attn.layer_norm.bias: requires_grad=True
layer.4.ff.layer_norm.weight: requires_grad=True
layer.4.ff.layer_norm.bias: requires_grad=True
layer.4.ff.layer_1.weight: requires_grad=True
layer.4.ff.layer_1.bias: requires_grad=True
layer.4.ff.layer_2.weight: requires_grad=True
layer.4.ff.layer_2.bias: requires_grad=True
layer.5.rel_attn.q: requires_grad=True
layer.5.rel_attn.k: requires_grad=True
layer.5.rel_attn.v: requires_grad=True
layer.5.rel_attn.o: requires_grad=True
layer.5.rel_attn.r: requires_grad=True
layer.5.rel_attn.r_r_bias: requires_grad=True
layer.5.rel_attn.r_s_bias: requires_grad=True
layer.5.rel_attn.r_w_bias: requires_grad=True
layer.5.rel_attn.seg_embed: requires_grad=True
layer.5.rel_attn.layer_norm.weight: requires_grad=True
layer.5.rel_attn.layer_norm.bias: requires_grad=True
layer.5.ff.layer_norm.weight: requires_grad=True
layer.5.ff.layer_norm.bias: requires_grad=True
layer.5.ff.layer_1.weight: requires_grad=True
layer.5.ff.layer_1.bias: requires_grad=True
layer.5.ff.layer_2.weight: requires_grad=True
layer.5.ff.layer_2.bias: requires_grad=True
layer.6.rel_attn.q: requires_grad=True
layer.6.rel_attn.k: requires_grad=True
layer.6.rel_attn.v: requires_grad=True
layer.6.rel_attn.o: requires_grad=True
layer.6.rel_attn.r: requires_grad=True
layer.6.rel_attn.r_r_bias: requires_grad=True
layer.6.rel_attn.r_s_bias: requires_grad=True
layer.6.rel_attn.r_w_bias: requires_grad=True
layer.6.rel_attn.seg_embed: requires_grad=True
layer.6.rel_attn.layer_norm.weight: requires_grad=True
layer.6.rel_attn.layer_norm.bias: requires_grad=True
layer.6.ff.layer_norm.weight: requires_grad=True
layer.6.ff.layer_norm.bias: requires_grad=True
layer.6.ff.layer_1.weight: requires_grad=True
layer.6.ff.layer_1.bias: requires_grad=True
layer.6.ff.layer_2.weight: requires_grad=True
layer.6.ff.layer_2.bias: requires_grad=True
layer.7.rel_attn.q: requires_grad=True
layer.7.rel_attn.k: requires_grad=True
layer.7.rel_attn.v: requires_grad=True
layer.7.rel_attn.o: requires_grad=True
layer.7.rel_attn.r: requires_grad=True
layer.7.rel_attn.r_r_bias: requires_grad=True
layer.7.rel_attn.r_s_bias: requires_grad=True
layer.7.rel_attn.r_w_bias: requires_grad=True
layer.7.rel_attn.seg_embed: requires_grad=True
layer.7.rel_attn.layer_norm.weight: requires_grad=True
layer.7.rel_attn.layer_norm.bias: requires_grad=True
layer.7.ff.layer_norm.weight: requires_grad=True
layer.7.ff.layer_norm.bias: requires_grad=True
layer.7.ff.layer_1.weight: requires_grad=True
layer.7.ff.layer_1.bias: requires_grad=True
layer.7.ff.layer_2.weight: requires_grad=True
layer.7.ff.layer_2.bias: requires_grad=True
layer.8.rel_attn.q: requires_grad=True
layer.8.rel_attn.k: requires_grad=True
layer.8.rel_attn.v: requires_grad=True
layer.8.rel_attn.o: requires_grad=True
layer.8.rel_attn.r: requires_grad=True
layer.8.rel_attn.r_r_bias: requires_grad=True
layer.8.rel_attn.r_s_bias: requires_grad=True
layer.8.rel_attn.r_w_bias: requires_grad=True
layer.8.rel_attn.seg_embed: requires_grad=True
layer.8.rel_attn.layer_norm.weight: requires_grad=True
layer.8.rel_attn.layer_norm.bias: requires_grad=True
layer.8.ff.layer_norm.weight: requires_grad=True
layer.8.ff.layer_norm.bias: requires_grad=True
layer.8.ff.layer_1.weight: requires_grad=True
layer.8.ff.layer_1.bias: requires_grad=True
layer.8.ff.layer_2.weight: requires_grad=True
layer.8.ff.layer_2.bias: requires_grad=True
layer.9.rel_attn.q: requires_grad=True
layer.9.rel_attn.k: requires_grad=True
layer.9.rel_attn.v: requires_grad=True
layer.9.rel_attn.o: requires_grad=True
layer.9.rel_attn.r: requires_grad=True
layer.9.rel_attn.r_r_bias: requires_grad=True
layer.9.rel_attn.r_s_bias: requires_grad=True
layer.9.rel_attn.r_w_bias: requires_grad=True
layer.9.rel_attn.seg_embed: requires_grad=True
layer.9.rel_attn.layer_norm.weight: requires_grad=True
layer.9.rel_attn.layer_norm.bias: requires_grad=True
layer.9.ff.layer_norm.weight: requires_grad=True
layer.9.ff.layer_norm.bias: requires_grad=True
layer.9.ff.layer_1.weight: requires_grad=True
layer.9.ff.layer_1.bias: requires_grad=True
layer.9.ff.layer_2.weight: requires_grad=True
layer.9.ff.layer_2.bias: requires_grad=True
layer.10.rel_attn.q: requires_grad=True
layer.10.rel_attn.k: requires_grad=True
layer.10.rel_attn.v: requires_grad=True
layer.10.rel_attn.o: requires_grad=True
layer.10.rel_attn.r: requires_grad=True
layer.10.rel_attn.r_r_bias: requires_grad=True
layer.10.rel_attn.r_s_bias: requires_grad=True
layer.10.rel_attn.r_w_bias: requires_grad=True
layer.10.rel_attn.seg_embed: requires_grad=True
layer.10.rel_attn.layer_norm.weight: requires_grad=True
layer.10.rel_attn.layer_norm.bias: requires_grad=True
layer.10.ff.layer_norm.weight: requires_grad=True
layer.10.ff.layer_norm.bias: requires_grad=True
layer.10.ff.layer_1.weight: requires_grad=True
layer.10.ff.layer_1.bias: requires_grad=True
layer.10.ff.layer_2.weight: requires_grad=True
layer.10.ff.layer_2.bias: requires_grad=True
layer.11.rel_attn.q: requires_grad=True
layer.11.rel_attn.k: requires_grad=True
layer.11.rel_attn.v: requires_grad=True
layer.11.rel_attn.o: requires_grad=True
layer.11.rel_attn.r: requires_grad=True
layer.11.rel_attn.r_r_bias: requires_grad=True
layer.11.rel_attn.r_s_bias: requires_grad=True
layer.11.rel_attn.r_w_bias: requires_grad=True
layer.11.rel_attn.seg_embed: requires_grad=True
layer.11.rel_attn.layer_norm.weight: requires_grad=True
layer.11.rel_attn.layer_norm.bias: requires_grad=True
layer.11.ff.layer_norm.weight: requires_grad=True
layer.11.ff.layer_norm.bias: requires_grad=True
layer.11.ff.layer_1.weight: requires_grad=True
layer.11.ff.layer_1.bias: requires_grad=True
layer.11.ff.layer_2.weight: requires_grad=True
layer.11.ff.layer_2.bias: requires_grad=True

 Epoch 1 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 1.172
Validation Loss: 0.918
Validation Accuracy: 0.655

 Epoch 2 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.825
Validation Loss: 0.741
Validation Accuracy: 0.714

 Epoch 3 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.624
Validation Loss: 0.728
Validation Accuracy: 0.733

 Epoch 4 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.494
Validation Loss: 0.691
Validation Accuracy: 0.754

 Epoch 5 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.394
Validation Loss: 0.707
Validation Accuracy: 0.767

 Epoch 6 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.298
Validation Loss: 0.817
Validation Accuracy: 0.770

 Epoch 7 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.240
Validation Loss: 0.944
Validation Accuracy: 0.735

 Epoch 8 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.189
Validation Loss: 0.945
Validation Accuracy: 0.743

 Epoch 9 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.149
Validation Loss: 0.953
Validation Accuracy: 0.767

 Epoch 10 / 10
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...

Training Loss: 0.123
Validation Loss: 1.045
Validation Accuracy: 0.773

Test Accuracy: 0.784
== flag 1.601 xlnet result On test data ==
Test Accuracy: 0.784%
Precision: 0.7915
Recall: 0.7840
F1 Score: 0.7847
Classification Report:
              precision    recall  f1-score   support

           0       0.81      0.84      0.83       558
           1       0.78      0.83      0.80       358
           2       0.56      0.69      0.62       123
           3       0.85      0.69      0.76       382

    accuracy                           0.78      1421
   macro avg       0.75      0.76      0.75      1421
weighted avg       0.79      0.78      0.78      1421

Confusion Matrix:
[[469  36  26  27]
 [ 29 296  16  17]
 [ 17  17  85   4]
 [ 61  31  26 264]]
flag 1.11  model: xlnet has finished  : xlnet
