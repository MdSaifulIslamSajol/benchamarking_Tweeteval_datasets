learning rate  : 1e-05
epochs : 20
                                                text  label
0  “Worry is a down payment on a problem you may ...      2
1  My roommate: it's okay that we can't spell bec...      0
2  No but that's so cute. Atsu was probably shy a...      1
3  Rooneys fucking untouchable isn't he? Been fuc...      0
4  it's pretty depressing when u hit pan on ur fa...      3
                                                text
0  “Worry is a down payment on a problem you may ...
1  My roommate: it's okay that we can't spell bec...
2  No but that's so cute. Atsu was probably shy a...
3  Rooneys fucking untouchable isn't he? Been fuc...
4  it's pretty depressing when u hit pan on ur fa...
   label
0      2
1      0
2      1
3      0
4      3
                                                text  label
0  @user @user Oh, hidden revenge and anger...I r...      0
1  if not then #teamchristine bc all tana has don...      0
2  Hey @user #Fields in #skibbereen give your onl...      0
3  Why have #Emmerdale had to rob #robron of havi...      0
4  @user I would like to hear a podcast of you go...      0
                                                text
0  @user @user Oh, hidden revenge and anger...I r...
1  if not then #teamchristine bc all tana has don...
2  Hey @user #Fields in #skibbereen give your onl...
3  Why have #Emmerdale had to rob #robron of havi...
4  @user I would like to hear a podcast of you go...
   label
0      0
1      0
2      0
3      0
4      0
                                                text  label
0  #Deppression is real. Partners w/ #depressed p...      3
1  @user Interesting choice of words... Are you c...      0
2  My visit to hospital for care triggered #traum...      3
3  @user Welcome to #MPSVT! We are delighted to h...      1
4                       What makes you feel #joyful?      1
                                                text
0  #Deppression is real. Partners w/ #depressed p...
1  @user Interesting choice of words... Are you c...
2  My visit to hospital for care triggered #traum...
3  @user Welcome to #MPSVT! We are delighted to h...
4                       What makes you feel #joyful?
                                                text
0  #Deppression is real. Partners w/ #depressed p...
1  @user Interesting choice of words... Are you c...
2  My visit to hospital for care triggered #traum...
3  @user Welcome to #MPSVT! We are delighted to h...
4                       What makes you feel #joyful?
len(train_labels) 3257
len(test_labels) 1421
len(val_labels) 374

Unique values count in train_labels:
label
0    1400
3     855
1     708
2     294
Name: count, dtype: int64

Unique values count in val_labels:
label
0    160
1     97
3     89
2     28
Name: count, dtype: int64

Unique values count in test_labels:
label
0    558
3    382
1    358
2    123
Name: count, dtype: int64





===================================================== 
flag 1.10  model:  started with ==>   bert
===================================================== 

 Epoch 1 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7031

Evaluating...

Training Loss: 1.1851
Validation Loss: 0.9389
Validation Accuracy: 0.6872

 Epoch 2 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8545

Evaluating...

Training Loss: 0.7831
Validation Loss: 0.6886
Validation Accuracy: 0.7941

 Epoch 3 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9100

Evaluating...

Training Loss: 0.5195
Validation Loss: 0.6287
Validation Accuracy: 0.7914

 Epoch 4 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9414

Evaluating...

Training Loss: 0.3730
Validation Loss: 0.6497
Validation Accuracy: 0.7888

 Epoch 5 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9625

Evaluating...

Training Loss: 0.2744
Validation Loss: 0.7053
Validation Accuracy: 0.7861

 Epoch 6 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9757

Evaluating...

Training Loss: 0.1924
Validation Loss: 0.7636
Validation Accuracy: 0.7781

 Epoch 7 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9810

Evaluating...

Training Loss: 0.1551
Validation Loss: 0.8104
Validation Accuracy: 0.7834

 Epoch 8 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9837

Evaluating...

Training Loss: 0.1138
Validation Loss: 0.8897
Validation Accuracy: 0.7807

 Epoch 9 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9883

Evaluating...

Training Loss: 0.0855
Validation Loss: 0.9342
Validation Accuracy: 0.7888

 Epoch 10 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9926

Evaluating...

Training Loss: 0.0704
Validation Loss: 0.9842
Validation Accuracy: 0.7914

 Epoch 11 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9951

Evaluating...

Training Loss: 0.0552
Validation Loss: 1.1131
Validation Accuracy: 0.7781

 Epoch 12 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9960

Evaluating...

Training Loss: 0.0376
Validation Loss: 1.1667
Validation Accuracy: 0.7727

 Epoch 13 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9975

Evaluating...

Training Loss: 0.0320
Validation Loss: 1.2733
Validation Accuracy: 0.7834

 Epoch 14 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9969

Evaluating...

Training Loss: 0.0222
Validation Loss: 1.2322
Validation Accuracy: 0.7781

 Epoch 15 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9979

Evaluating...

Training Loss: 0.0281
Validation Loss: 1.2524
Validation Accuracy: 0.7834

 Epoch 16 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9985

Evaluating...

Training Loss: 0.0153
Validation Loss: 1.3024
Validation Accuracy: 0.7834

 Epoch 17 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9985

Evaluating...

Training Loss: 0.0125
Validation Loss: 1.3522
Validation Accuracy: 0.7781

 Epoch 18 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9988

Evaluating...

Training Loss: 0.0168
Validation Loss: 1.3919
Validation Accuracy: 0.7888

 Epoch 19 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9994

Evaluating...

Training Loss: 0.0071
Validation Loss: 1.4605
Validation Accuracy: 0.7941

 Epoch 20 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9991

Evaluating...

Training Loss: 0.0151
Validation Loss: 1.4854
Validation Accuracy: 0.7834


         == flag 1.601 bert result On test data ==
# called_model : bert
# Test Accuracy: 0.8023%
Precision: 0.8003
Recall: 0.8023
F1 Score: 0.8005
Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.89      0.86       558
           1       0.84      0.81      0.82       358
           2       0.57      0.53      0.55       123
           3       0.80      0.76      0.78       382

    accuracy                           0.80      1421
   macro avg       0.76      0.75      0.75      1421
weighted avg       0.80      0.80      0.80      1421

Confusion Matrix:
[[497  20  11  30]
 [ 22 289  21  26]
 [ 25  17  65  16]
 [ 57  19  17 289]]

flag 1.11  model:  finished  with:   bert





===================================================== 
flag 1.10  model:  started with ==>   roberta
===================================================== 

 Epoch 1 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7581

Evaluating...

Training Loss: 1.1770
Validation Loss: 0.8565
Validation Accuracy: 0.7326

 Epoch 2 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8253

Evaluating...

Training Loss: 0.7604
Validation Loss: 0.7094
Validation Accuracy: 0.7727

 Epoch 3 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8499

Evaluating...

Training Loss: 0.5750
Validation Loss: 0.7161
Validation Accuracy: 0.7433

 Epoch 4 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9088

Evaluating...

Training Loss: 0.4591
Validation Loss: 0.6200
Validation Accuracy: 0.7914

 Epoch 5 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9340

Evaluating...

Training Loss: 0.3709
Validation Loss: 0.6463
Validation Accuracy: 0.7968

 Epoch 6 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9536

Evaluating...

Training Loss: 0.3058
Validation Loss: 0.6971
Validation Accuracy: 0.7888

 Epoch 7 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9619

Evaluating...

Training Loss: 0.2458
Validation Loss: 0.8284
Validation Accuracy: 0.7674

 Epoch 8 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9702

Evaluating...

Training Loss: 0.2252
Validation Loss: 0.7538
Validation Accuracy: 0.7861

 Epoch 9 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9797

Evaluating...

Training Loss: 0.1778
Validation Loss: 0.8520
Validation Accuracy: 0.7861

 Epoch 10 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9822

Evaluating...

Training Loss: 0.1507
Validation Loss: 1.0439
Validation Accuracy: 0.7567

 Epoch 11 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9837

Evaluating...

Training Loss: 0.1330
Validation Loss: 0.9081
Validation Accuracy: 0.7807

 Epoch 12 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9886

Evaluating...

Training Loss: 0.1104
Validation Loss: 1.0842
Validation Accuracy: 0.7781

 Epoch 13 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9889

Evaluating...

Training Loss: 0.0886
Validation Loss: 1.1631
Validation Accuracy: 0.7727

 Epoch 14 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9917

Evaluating...

Training Loss: 0.0923
Validation Loss: 1.1799
Validation Accuracy: 0.7701

 Epoch 15 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9917

Evaluating...

Training Loss: 0.0727
Validation Loss: 1.3456
Validation Accuracy: 0.7834

 Epoch 16 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9939

Evaluating...

Training Loss: 0.0751
Validation Loss: 1.3867
Validation Accuracy: 0.7781

 Epoch 17 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9963

Evaluating...

Training Loss: 0.0712
Validation Loss: 1.3975
Validation Accuracy: 0.7781

 Epoch 18 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9945

Evaluating...

Training Loss: 0.0560
Validation Loss: 1.3769
Validation Accuracy: 0.7807

 Epoch 19 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9972

Evaluating...

Training Loss: 0.0432
Validation Loss: 1.4688
Validation Accuracy: 0.7701

 Epoch 20 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9957

Evaluating...

Training Loss: 0.0424
Validation Loss: 1.4846
Validation Accuracy: 0.7647


         == flag 1.601 roberta result On test data ==
# called_model : roberta
# Test Accuracy: 0.8093%
Precision: 0.8129
Recall: 0.8093
F1 Score: 0.8100
Classification Report:
              precision    recall  f1-score   support

           0       0.89      0.82      0.85       558
           1       0.78      0.85      0.81       358
           2       0.67      0.68      0.67       123
           3       0.78      0.80      0.79       382

    accuracy                           0.81      1421
   macro avg       0.78      0.79      0.78      1421
weighted avg       0.81      0.81      0.81      1421

Confusion Matrix:
[[455  42  15  46]
 [ 13 306  12  27]
 [ 13  15  84  11]
 [ 32  30  15 305]]

flag 1.11  model:  finished  with:   roberta





===================================================== 
flag 1.10  model:  started with ==>   distilbert
===================================================== 

 Epoch 1 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7209

Evaluating...

Training Loss: 1.1428
Validation Loss: 0.8592
Validation Accuracy: 0.7112

 Epoch 2 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8351

Evaluating...

Training Loss: 0.7172
Validation Loss: 0.6506
Validation Accuracy: 0.7781

 Epoch 3 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8873

Evaluating...

Training Loss: 0.5165
Validation Loss: 0.6203
Validation Accuracy: 0.7781

 Epoch 4 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9048

Evaluating...

Training Loss: 0.4086
Validation Loss: 0.6536
Validation Accuracy: 0.7727

 Epoch 5 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9487

Evaluating...

Training Loss: 0.3118
Validation Loss: 0.6556
Validation Accuracy: 0.7727

 Epoch 6 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9656

Evaluating...

Training Loss: 0.2447
Validation Loss: 0.6719
Validation Accuracy: 0.7861

 Epoch 7 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9776

Evaluating...

Training Loss: 0.1822
Validation Loss: 0.7263
Validation Accuracy: 0.7674

 Epoch 8 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9840

Evaluating...

Training Loss: 0.1307
Validation Loss: 0.8287
Validation Accuracy: 0.7674

 Epoch 9 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9874

Evaluating...

Training Loss: 0.1051
Validation Loss: 0.8584
Validation Accuracy: 0.7701

 Epoch 10 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9905

Evaluating...

Training Loss: 0.0807
Validation Loss: 0.9156
Validation Accuracy: 0.7594

 Epoch 11 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9932

Evaluating...

Training Loss: 0.0610
Validation Loss: 0.9827
Validation Accuracy: 0.7701

 Epoch 12 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9942

Evaluating...

Training Loss: 0.0468
Validation Loss: 1.0648
Validation Accuracy: 0.7701

 Epoch 13 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9954

Evaluating...

Training Loss: 0.0352
Validation Loss: 1.0527
Validation Accuracy: 0.7727

 Epoch 14 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9966

Evaluating...

Training Loss: 0.0376
Validation Loss: 1.0609
Validation Accuracy: 0.7754

 Epoch 15 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9991

Evaluating...

Training Loss: 0.0210
Validation Loss: 1.1762
Validation Accuracy: 0.7701

 Epoch 16 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9991

Evaluating...

Training Loss: 0.0182
Validation Loss: 1.1983
Validation Accuracy: 0.7567

 Epoch 17 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9988

Evaluating...

Training Loss: 0.0133
Validation Loss: 1.3912
Validation Accuracy: 0.7647

 Epoch 18 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9991

Evaluating...

Training Loss: 0.0113
Validation Loss: 1.1972
Validation Accuracy: 0.7968

 Epoch 19 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9997

Evaluating...

Training Loss: 0.0099
Validation Loss: 1.3396
Validation Accuracy: 0.7674

 Epoch 20 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 1.0000

Evaluating...

Training Loss: 0.0083
Validation Loss: 1.2465
Validation Accuracy: 0.7888


         == flag 1.601 distilbert result On test data ==
# called_model : distilbert
# Test Accuracy: 0.7994%
Precision: 0.7977
Recall: 0.7994
F1 Score: 0.7979
Classification Report:
              precision    recall  f1-score   support

           0       0.83      0.87      0.85       558
           1       0.81      0.83      0.82       358
           2       0.59      0.55      0.57       123
           3       0.81      0.74      0.77       382

    accuracy                           0.80      1421
   macro avg       0.76      0.75      0.75      1421
weighted avg       0.80      0.80      0.80      1421

Confusion Matrix:
[[488  22  11  37]
 [ 24 296  17  21]
 [ 26  19  68  10]
 [ 49  30  19 284]]

flag 1.11  model:  finished  with:   distilbert





===================================================== 
flag 1.10  model:  started with ==>   electra
===================================================== 

 Epoch 1 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.6534

Evaluating...

Training Loss: 1.2280
Validation Loss: 1.0325
Validation Accuracy: 0.6230

 Epoch 2 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7774

Evaluating...

Training Loss: 0.9138
Validation Loss: 0.7431
Validation Accuracy: 0.7513

 Epoch 3 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8628

Evaluating...

Training Loss: 0.6586
Validation Loss: 0.6048
Validation Accuracy: 0.7995

 Epoch 4 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8809

Evaluating...

Training Loss: 0.5038
Validation Loss: 0.6247
Validation Accuracy: 0.7914

 Epoch 5 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9186

Evaluating...

Training Loss: 0.4304
Validation Loss: 0.5791
Validation Accuracy: 0.8021

 Epoch 6 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9395

Evaluating...

Training Loss: 0.3475
Validation Loss: 0.5746
Validation Accuracy: 0.8075

 Epoch 7 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9619

Evaluating...

Training Loss: 0.2695
Validation Loss: 0.6067
Validation Accuracy: 0.8182

 Epoch 8 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9705

Evaluating...

Training Loss: 0.2402
Validation Loss: 0.6646
Validation Accuracy: 0.7995

 Epoch 9 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9696

Evaluating...

Training Loss: 0.1731
Validation Loss: 0.8308
Validation Accuracy: 0.7781

 Epoch 10 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9791

Evaluating...

Training Loss: 0.1442
Validation Loss: 0.8437
Validation Accuracy: 0.7888

 Epoch 11 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9810

Evaluating...

Training Loss: 0.1287
Validation Loss: 0.8379
Validation Accuracy: 0.8075

 Epoch 12 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9883

Evaluating...

Training Loss: 0.1097
Validation Loss: 0.8543
Validation Accuracy: 0.7995

 Epoch 13 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9871

Evaluating...

Training Loss: 0.0931
Validation Loss: 1.0689
Validation Accuracy: 0.7754

 Epoch 14 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9923

Evaluating...

Training Loss: 0.0829
Validation Loss: 0.9865
Validation Accuracy: 0.7995

 Epoch 15 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9932

Evaluating...

Training Loss: 0.0689
Validation Loss: 1.0393
Validation Accuracy: 0.8075

 Epoch 16 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9951

Evaluating...

Training Loss: 0.0512
Validation Loss: 1.1166
Validation Accuracy: 0.8075

 Epoch 17 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9963

Evaluating...

Training Loss: 0.0401
Validation Loss: 1.1188
Validation Accuracy: 0.8021

 Epoch 18 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9963

Evaluating...

Training Loss: 0.0503
Validation Loss: 1.1329
Validation Accuracy: 0.8048

 Epoch 19 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9979

Evaluating...

Training Loss: 0.0310
Validation Loss: 1.1469
Validation Accuracy: 0.7995

 Epoch 20 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9975

Evaluating...

Training Loss: 0.0291
Validation Loss: 1.1814
Validation Accuracy: 0.8075


         == flag 1.601 electra result On test data ==
# called_model : electra
# Test Accuracy: 0.8220%
Precision: 0.8226
Recall: 0.8220
F1 Score: 0.8197
Classification Report:
              precision    recall  f1-score   support

           0       0.88      0.86      0.87       558
           1       0.79      0.86      0.82       358
           2       0.79      0.54      0.64       123
           3       0.79      0.83      0.81       382

    accuracy                           0.82      1421
   macro avg       0.81      0.77      0.78      1421
weighted avg       0.82      0.82      0.82      1421

Confusion Matrix:
[[478  31   5  44]
 [ 19 308   6  25]
 [ 18  23  66  16]
 [ 31  28   7 316]]

flag 1.11  model:  finished  with:   electra





===================================================== 
flag 1.10  model:  started with ==>   gpt2
===================================================== 

 Epoch 1 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.4449

Evaluating...

Training Loss: 1.6177
Validation Loss: 1.2147
Validation Accuracy: 0.4358

 Epoch 2 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.6411

Evaluating...

Training Loss: 1.1034
Validation Loss: 0.9602
Validation Accuracy: 0.5936

 Epoch 3 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7307

Evaluating...

Training Loss: 0.8883
Validation Loss: 0.7762
Validation Accuracy: 0.6898

 Epoch 4 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8121

Evaluating...

Training Loss: 0.7163
Validation Loss: 0.6816
Validation Accuracy: 0.7674

 Epoch 5 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8284

Evaluating...

Training Loss: 0.6024
Validation Loss: 0.6719
Validation Accuracy: 0.7540

 Epoch 6 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8542

Evaluating...

Training Loss: 0.5320
Validation Loss: 0.6378
Validation Accuracy: 0.7754

 Epoch 7 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8818

Evaluating...

Training Loss: 0.4820
Validation Loss: 0.6458
Validation Accuracy: 0.7807

 Epoch 8 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8821

Evaluating...

Training Loss: 0.4186
Validation Loss: 0.7048
Validation Accuracy: 0.7513

 Epoch 9 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9226

Evaluating...

Training Loss: 0.3691
Validation Loss: 0.6680
Validation Accuracy: 0.7674

 Epoch 10 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9374

Evaluating...

Training Loss: 0.3344
Validation Loss: 0.6512
Validation Accuracy: 0.7941

 Epoch 11 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9423

Evaluating...

Training Loss: 0.2876
Validation Loss: 0.6916
Validation Accuracy: 0.7727

 Epoch 12 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9610

Evaluating...

Training Loss: 0.2570
Validation Loss: 0.7097
Validation Accuracy: 0.7807

 Epoch 13 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9668

Evaluating...

Training Loss: 0.2228
Validation Loss: 0.7965
Validation Accuracy: 0.7807

 Epoch 14 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9711

Evaluating...

Training Loss: 0.1889
Validation Loss: 0.8193
Validation Accuracy: 0.7594

 Epoch 15 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9819

Evaluating...

Training Loss: 0.1684
Validation Loss: 0.8370
Validation Accuracy: 0.7754

 Epoch 16 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9880

Evaluating...

Training Loss: 0.1389
Validation Loss: 0.8921
Validation Accuracy: 0.7647

 Epoch 17 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9929

Evaluating...

Training Loss: 0.1127
Validation Loss: 0.9438
Validation Accuracy: 0.7701

 Epoch 18 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9936

Evaluating...

Training Loss: 0.1043
Validation Loss: 0.9349
Validation Accuracy: 0.7674

 Epoch 19 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9951

Evaluating...

Training Loss: 0.0858
Validation Loss: 1.0095
Validation Accuracy: 0.7834

 Epoch 20 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9951

Evaluating...

Training Loss: 0.0711
Validation Loss: 1.1382
Validation Accuracy: 0.7727


         == flag 1.601 gpt2 result On test data ==
# called_model : gpt2
# Test Accuracy: 0.7868%
Precision: 0.7884
Recall: 0.7868
F1 Score: 0.7817
Classification Report:
              precision    recall  f1-score   support

           0       0.77      0.91      0.83       558
           1       0.81      0.77      0.79       358
           2       0.78      0.49      0.60       123
           3       0.80      0.72      0.76       382

    accuracy                           0.79      1421
   macro avg       0.79      0.72      0.75      1421
weighted avg       0.79      0.79      0.78      1421

Confusion Matrix:
[[507  22   4  25]
 [ 43 277   5  33]
 [ 41  11  60  11]
 [ 68  32   8 274]]

flag 1.11  model:  finished  with:   gpt2





===================================================== 
flag 1.10  model:  started with ==>   longformer
===================================================== 

 Epoch 1 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7694

Evaluating...

Training Loss: 1.0526
Validation Loss: 0.7166
Validation Accuracy: 0.7433

 Epoch 2 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8492

Evaluating...

Training Loss: 0.6507
Validation Loss: 0.6274
Validation Accuracy: 0.7861

 Epoch 3 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8971

Evaluating...

Training Loss: 0.4882
Validation Loss: 0.6067
Validation Accuracy: 0.7888

 Epoch 4 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9199

Evaluating...

Training Loss: 0.4015
Validation Loss: 0.6453
Validation Accuracy: 0.8021

 Epoch 5 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9444

Evaluating...

Training Loss: 0.3217
Validation Loss: 0.6620
Validation Accuracy: 0.7968

 Epoch 6 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9610

Evaluating...

Training Loss: 0.2635
Validation Loss: 0.6978
Validation Accuracy: 0.7995

 Epoch 7 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9401

Evaluating...

Training Loss: 0.2104
Validation Loss: 0.9823
Validation Accuracy: 0.7273

 Epoch 8 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9800

Evaluating...

Training Loss: 0.1863
Validation Loss: 0.8301
Validation Accuracy: 0.7807

 Epoch 9 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9850

Evaluating...

Training Loss: 0.1424
Validation Loss: 0.8818
Validation Accuracy: 0.7968

 Epoch 10 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9807

Evaluating...

Training Loss: 0.1287
Validation Loss: 0.9888
Validation Accuracy: 0.7861

 Epoch 11 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9914

Evaluating...

Training Loss: 0.0911
Validation Loss: 0.9268
Validation Accuracy: 0.8102

 Epoch 12 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9908

Evaluating...

Training Loss: 0.0864
Validation Loss: 1.2326
Validation Accuracy: 0.7754

 Epoch 13 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9951

Evaluating...

Training Loss: 0.0820
Validation Loss: 1.1186
Validation Accuracy: 0.7914

 Epoch 14 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9960

Evaluating...

Training Loss: 0.0591
Validation Loss: 1.1883
Validation Accuracy: 0.7968

 Epoch 15 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9954

Evaluating...

Training Loss: 0.0555
Validation Loss: 1.3761
Validation Accuracy: 0.7674

 Epoch 16 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9969

Evaluating...

Training Loss: 0.0445
Validation Loss: 1.4238
Validation Accuracy: 0.7674

 Epoch 17 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9979

Evaluating...

Training Loss: 0.0525
Validation Loss: 1.4133
Validation Accuracy: 0.7807

 Epoch 18 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9982

Evaluating...

Training Loss: 0.0506
Validation Loss: 1.5534
Validation Accuracy: 0.7620

 Epoch 19 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9979

Evaluating...

Training Loss: 0.0292
Validation Loss: 1.4125
Validation Accuracy: 0.8021

 Epoch 20 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9988

Evaluating...

Training Loss: 0.0302
Validation Loss: 1.4666
Validation Accuracy: 0.7834


         == flag 1.601 longformer result On test data ==
# called_model : longformer
# Test Accuracy: 0.8205%
Precision: 0.8204
Recall: 0.8205
F1 Score: 0.8200
Classification Report:
              precision    recall  f1-score   support

           0       0.85      0.88      0.87       558
           1       0.86      0.80      0.83       358
           2       0.68      0.65      0.67       123
           3       0.79      0.80      0.80       382

    accuracy                           0.82      1421
   macro avg       0.79      0.78      0.79      1421
weighted avg       0.82      0.82      0.82      1421

Confusion Matrix:
[[493  17   7  41]
 [ 24 286  19  29]
 [ 19  11  80  13]
 [ 45  19  11 307]]

flag 1.11  model:  finished  with:   longformer





===================================================== 
flag 1.10  model:  started with ==>   luke
===================================================== 

 Epoch 1 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7872

Evaluating...

Training Loss: 1.0805
Validation Loss: 0.6889
Validation Accuracy: 0.7620

 Epoch 2 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8502

Evaluating...

Training Loss: 0.6344
Validation Loss: 0.6413
Validation Accuracy: 0.7941

 Epoch 3 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8849

Evaluating...

Training Loss: 0.5092
Validation Loss: 0.5658
Validation Accuracy: 0.7941

 Epoch 4 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9325

Evaluating...

Training Loss: 0.3958
Validation Loss: 0.6067
Validation Accuracy: 0.8102

 Epoch 5 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9429

Evaluating...

Training Loss: 0.3092
Validation Loss: 0.6733
Validation Accuracy: 0.8021

 Epoch 6 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9656

Evaluating...

Training Loss: 0.2568
Validation Loss: 0.7234
Validation Accuracy: 0.7888

 Epoch 7 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9727

Evaluating...

Training Loss: 0.1990
Validation Loss: 0.8418
Validation Accuracy: 0.7834

 Epoch 8 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9840

Evaluating...

Training Loss: 0.1519
Validation Loss: 0.9455
Validation Accuracy: 0.7674

 Epoch 9 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9865

Evaluating...

Training Loss: 0.1182
Validation Loss: 0.9971
Validation Accuracy: 0.7727

 Epoch 10 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9883

Evaluating...

Training Loss: 0.1178
Validation Loss: 1.0957
Validation Accuracy: 0.7620

 Epoch 11 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9902

Evaluating...

Training Loss: 0.0939
Validation Loss: 1.1063
Validation Accuracy: 0.7674

 Epoch 12 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9908

Evaluating...

Training Loss: 0.0783
Validation Loss: 1.2264
Validation Accuracy: 0.7540

 Epoch 13 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9963

Evaluating...

Training Loss: 0.0668
Validation Loss: 1.1690
Validation Accuracy: 0.7781

 Epoch 14 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9963

Evaluating...

Training Loss: 0.0673
Validation Loss: 1.2909
Validation Accuracy: 0.7781

 Epoch 15 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9969

Evaluating...

Training Loss: 0.0485
Validation Loss: 1.4243
Validation Accuracy: 0.7807

 Epoch 16 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9963

Evaluating...

Training Loss: 0.0526
Validation Loss: 1.4555
Validation Accuracy: 0.7674

 Epoch 17 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9982

Evaluating...

Training Loss: 0.0412
Validation Loss: 1.4807
Validation Accuracy: 0.7781

 Epoch 18 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9972

Evaluating...

Training Loss: 0.0396
Validation Loss: 1.5594
Validation Accuracy: 0.7620

 Epoch 19 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9991

Evaluating...

Training Loss: 0.0381
Validation Loss: 1.4607
Validation Accuracy: 0.7727

 Epoch 20 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9982

Evaluating...

Training Loss: 0.0244
Validation Loss: 1.4447
Validation Accuracy: 0.7941


         == flag 1.601 luke result On test data ==
# called_model : luke
# Test Accuracy: 0.8100%
Precision: 0.8122
Recall: 0.8100
F1 Score: 0.8061
Classification Report:
              precision    recall  f1-score   support

           0       0.84      0.88      0.86       558
           1       0.76      0.90      0.82       358
           2       0.75      0.54      0.63       123
           3       0.85      0.71      0.77       382

    accuracy                           0.81      1421
   macro avg       0.80      0.76      0.77      1421
weighted avg       0.81      0.81      0.81      1421

Confusion Matrix:
[[491  31   8  28]
 [ 15 323   8  12]
 [ 25  23  66   9]
 [ 55  50   6 271]]

flag 1.11  model:  finished  with:   luke





===================================================== 
flag 1.10  model:  started with ==>   t5
===================================================== 

 Epoch 1 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.4302

Evaluating...

Training Loss: 1.3532
Validation Loss: 1.2910
Validation Accuracy: 0.4278

 Epoch 2 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.4298

Evaluating...

Training Loss: 1.2793
Validation Loss: 1.2526
Validation Accuracy: 0.4278

 Epoch 3 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.4298

Evaluating...

Training Loss: 1.2520
Validation Loss: 1.2303
Validation Accuracy: 0.4278

 Epoch 4 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.4421

Evaluating...

Training Loss: 1.2274
Validation Loss: 1.1670
Validation Accuracy: 0.4278

 Epoch 5 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.5533

Evaluating...

Training Loss: 1.1507
Validation Loss: 1.0599
Validation Accuracy: 0.5508

 Epoch 6 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.6543

Evaluating...

Training Loss: 1.0486
Validation Loss: 0.9541
Validation Accuracy: 0.6524

 Epoch 7 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7218

Evaluating...

Training Loss: 0.9477
Validation Loss: 0.8782
Validation Accuracy: 0.6765

 Epoch 8 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7639

Evaluating...

Training Loss: 0.8455
Validation Loss: 0.8244
Validation Accuracy: 0.7005

 Epoch 9 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7878

Evaluating...

Training Loss: 0.7641
Validation Loss: 0.7635
Validation Accuracy: 0.7112

 Epoch 10 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7989

Evaluating...

Training Loss: 0.6915
Validation Loss: 0.7482
Validation Accuracy: 0.7139

 Epoch 11 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8130

Evaluating...

Training Loss: 0.6176
Validation Loss: 0.7250
Validation Accuracy: 0.7299

 Epoch 12 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8324

Evaluating...

Training Loss: 0.5894
Validation Loss: 0.7295
Validation Accuracy: 0.7460

 Epoch 13 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8532

Evaluating...

Training Loss: 0.5518
Validation Loss: 0.7172
Validation Accuracy: 0.7513

 Epoch 14 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8683

Evaluating...

Training Loss: 0.5115
Validation Loss: 0.7072
Validation Accuracy: 0.7620

 Epoch 15 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8855

Evaluating...

Training Loss: 0.4766
Validation Loss: 0.7067
Validation Accuracy: 0.7647

 Epoch 16 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8938

Evaluating...

Training Loss: 0.4507
Validation Loss: 0.7174
Validation Accuracy: 0.7567

 Epoch 17 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9051

Evaluating...

Training Loss: 0.4260
Validation Loss: 0.7086
Validation Accuracy: 0.7674

 Epoch 18 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9122

Evaluating...

Training Loss: 0.4011
Validation Loss: 0.7319
Validation Accuracy: 0.7727

 Epoch 19 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9183

Evaluating...

Training Loss: 0.3906
Validation Loss: 0.7387
Validation Accuracy: 0.7647

 Epoch 20 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9272

Evaluating...

Training Loss: 0.3557
Validation Loss: 0.7603
Validation Accuracy: 0.7701


         == flag 1.601 t5 result On test data ==
# called_model : t5
# Test Accuracy: 0.8023%
Precision: 0.8074
Recall: 0.8023
F1 Score: 0.7977
Classification Report:
              precision    recall  f1-score   support

           0       0.87      0.87      0.87       558
           1       0.78      0.85      0.81       358
           2       0.87      0.43      0.58       123
           3       0.73      0.79      0.75       382

    accuracy                           0.80      1421
   macro avg       0.81      0.73      0.75      1421
weighted avg       0.81      0.80      0.80      1421

Confusion Matrix:
[[483  16   3  56]
 [ 19 304   2  33]
 [ 10  36  53  24]
 [ 45  34   3 300]]

flag 1.11  model:  finished  with:   t5





===================================================== 
flag 1.10  model:  started with ==>   xlnet
===================================================== 

 Epoch 1 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.7013

Evaluating...

Training Loss: 1.2004
Validation Loss: 0.9200
Validation Accuracy: 0.6310

 Epoch 2 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8201

Evaluating...

Training Loss: 0.7987
Validation Loss: 0.7096
Validation Accuracy: 0.7166

 Epoch 3 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.8520

Evaluating...

Training Loss: 0.5821
Validation Loss: 0.7700
Validation Accuracy: 0.7380

 Epoch 4 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9002

Evaluating...

Training Loss: 0.4900
Validation Loss: 0.7201
Validation Accuracy: 0.7594

 Epoch 5 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9398

Evaluating...

Training Loss: 0.3966
Validation Loss: 0.6603
Validation Accuracy: 0.7861

 Epoch 6 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9543

Evaluating...

Training Loss: 0.3021
Validation Loss: 0.7778
Validation Accuracy: 0.7513

 Epoch 7 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9742

Evaluating...

Training Loss: 0.2492
Validation Loss: 0.8282
Validation Accuracy: 0.7594

 Epoch 8 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9736

Evaluating...

Training Loss: 0.2057
Validation Loss: 0.9336
Validation Accuracy: 0.7567

 Epoch 9 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9834

Evaluating...

Training Loss: 0.1591
Validation Loss: 0.8904
Validation Accuracy: 0.7647

 Epoch 10 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9920

Evaluating...

Training Loss: 0.1295
Validation Loss: 1.0662
Validation Accuracy: 0.7594

 Epoch 11 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9899

Evaluating...

Training Loss: 0.1114
Validation Loss: 1.0883
Validation Accuracy: 0.7540

 Epoch 12 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9929

Evaluating...

Training Loss: 0.0861
Validation Loss: 1.1428
Validation Accuracy: 0.7781

 Epoch 13 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9902

Evaluating...

Training Loss: 0.0649
Validation Loss: 1.5159
Validation Accuracy: 0.7460

 Epoch 14 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9979

Evaluating...

Training Loss: 0.0627
Validation Loss: 1.5041
Validation Accuracy: 0.7433

 Epoch 15 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9960

Evaluating...

Training Loss: 0.0470
Validation Loss: 1.4784
Validation Accuracy: 0.7647

 Epoch 16 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9975

Evaluating...

Training Loss: 0.0599
Validation Loss: 1.5360
Validation Accuracy: 0.7487

 Epoch 17 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9926

Evaluating...

Training Loss: 0.0566
Validation Loss: 1.9067
Validation Accuracy: 0.7219

 Epoch 18 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9975

Evaluating...

Training Loss: 0.0467
Validation Loss: 1.5807
Validation Accuracy: 0.7594

 Epoch 19 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9988

Evaluating...

Training Loss: 0.0289
Validation Loss: 1.6984
Validation Accuracy: 0.7674

 Epoch 20 / 20
  Batch    50  of    102.
  Batch   100  of    102.

Evaluating...
  Batch    50  of    102.
  Batch   100  of    102.
Training Accuracy: 0.9982

Evaluating...

Training Loss: 0.0473
Validation Loss: 1.8834
Validation Accuracy: 0.7487


         == flag 1.601 xlnet result On test data ==
# called_model : xlnet
# Test Accuracy: 0.8023%
Precision: 0.8013
Recall: 0.8023
F1 Score: 0.8009
Classification Report:
              precision    recall  f1-score   support

           0       0.85      0.82      0.83       558
           1       0.81      0.85      0.83       358
           2       0.68      0.56      0.62       123
           3       0.77      0.80      0.78       382

    accuracy                           0.80      1421
   macro avg       0.78      0.76      0.77      1421
weighted avg       0.80      0.80      0.80      1421

Confusion Matrix:
[[459  29  14  56]
 [ 22 306   7  23]
 [ 22  17  69  15]
 [ 39  26  11 306]]

flag 1.11  model:  finished  with:   xlnet

Execution Finished
