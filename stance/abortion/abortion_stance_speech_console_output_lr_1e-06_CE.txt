learning rate  : 1e-06
epochs : 20
                                                text  label
0  we remind ourselves that love means to be will...      1
1  @user @user and most Islanders have different ...      0
2  Life is #precious & so are babies, mothers, & ...      1
3  @user too many people are taking this to serio...      0
4  Dude i won a #freeshirt from @user ! I never w...      0
                                                text
0  we remind ourselves that love means to be will...
1  @user @user and most Islanders have different ...
2  Life is #precious & so are babies, mothers, & ...
3  @user too many people are taking this to serio...
4  Dude i won a #freeshirt from @user ! I never w...
   label
0      1
1      0
2      1
3      0
4      0
                                                text  label
0  Today, AB 775 passed out of Committee on Judic...      0
1  There's a gray area when it comes to abortion....      1
2  If you aren't responsible enough to take care ...      1
3  Follow #Patriot --> @user  Thanks for followin...      0
4  One day I'm gonna set an abortion clinic on fi...      1
                                                text
0  Today, AB 775 passed out of Committee on Judic...
1  There's a gray area when it comes to abortion....
2  If you aren't responsible enough to take care ...
3  Follow #Patriot --> @user  Thanks for followin...
4  One day I'm gonna set an abortion clinic on fi...
   label
0      0
1      1
2      1
3      0
4      1
                                                text  label
0  Need a ProLife R.E. Agent? - Support a ProLife...      1
1  Where is the childcare program @user which you...      1
2  I get several requests with petitions to save ...      1
3  we must always see others as Christ sees us,we...      1
4  PRAYERS FOR BABIES Urgent prayer one in Lexing...      1
                                                text
0  Need a ProLife R.E. Agent? - Support a ProLife...
1  Where is the childcare program @user which you...
2  I get several requests with petitions to save ...
3  we must always see others as Christ sees us,we...
4  PRAYERS FOR BABIES Urgent prayer one in Lexing...
                                                text
0  Need a ProLife R.E. Agent? - Support a ProLife...
1  Where is the childcare program @user which you...
2  I get several requests with petitions to save ...
3  we must always see others as Christ sees us,we...
4  PRAYERS FOR BABIES Urgent prayer one in Lexing...
len(train_labels) 587
len(test_labels) 280
len(val_labels) 66

Unique values count in train_labels:
label
1    319
0    159
2    109
Name: count, dtype: int64

Unique values count in val_labels:
label
1    36
0    18
2    12
Name: count, dtype: int64

Unique values count in test_labels:
label
1    189
2     46
0     45
Name: count, dtype: int64





===================================================== 
flag 1.10  model:  started with ==>   bert
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.1704

Training Loss: 1.420
Validation Loss: 1.383
Validation Accuracy: 0.1667

 Epoch 2 / 20
Training Accuracy: 0.2283

Training Loss: 1.382
Validation Loss: 1.358
Validation Accuracy: 0.2576

 Epoch 3 / 20
Training Accuracy: 0.4753

Training Loss: 1.350
Validation Loss: 1.339
Validation Accuracy: 0.5000

 Epoch 4 / 20
Training Accuracy: 0.5281

Training Loss: 1.320
Validation Loss: 1.320
Validation Accuracy: 0.5455

 Epoch 5 / 20
Training Accuracy: 0.5451

Training Loss: 1.289
Validation Loss: 1.302
Validation Accuracy: 0.5455

 Epoch 6 / 20
Training Accuracy: 0.5434

Training Loss: 1.260
Validation Loss: 1.285
Validation Accuracy: 0.5606

 Epoch 7 / 20
Training Accuracy: 0.5434

Training Loss: 1.228
Validation Loss: 1.273
Validation Accuracy: 0.5606

 Epoch 8 / 20
Training Accuracy: 0.5434

Training Loss: 1.203
Validation Loss: 1.261
Validation Accuracy: 0.5455

 Epoch 9 / 20
Training Accuracy: 0.5434

Training Loss: 1.179
Validation Loss: 1.249
Validation Accuracy: 0.5455

 Epoch 10 / 20
Training Accuracy: 0.5434

Training Loss: 1.158
Validation Loss: 1.240
Validation Accuracy: 0.5455

 Epoch 11 / 20
Training Accuracy: 0.5434

Training Loss: 1.139
Validation Loss: 1.233
Validation Accuracy: 0.5455

 Epoch 12 / 20
Training Accuracy: 0.5434

Training Loss: 1.122
Validation Loss: 1.228
Validation Accuracy: 0.5455

 Epoch 13 / 20
Training Accuracy: 0.5434

Training Loss: 1.113
Validation Loss: 1.218
Validation Accuracy: 0.5455

 Epoch 14 / 20
Training Accuracy: 0.5434

Training Loss: 1.096
Validation Loss: 1.210
Validation Accuracy: 0.5455

 Epoch 15 / 20
Training Accuracy: 0.5434

Training Loss: 1.079
Validation Loss: 1.203
Validation Accuracy: 0.5455

 Epoch 16 / 20
Training Accuracy: 0.5434

Training Loss: 1.074
Validation Loss: 1.196
Validation Accuracy: 0.5455

 Epoch 17 / 20
Training Accuracy: 0.5434

Training Loss: 1.056
Validation Loss: 1.193
Validation Accuracy: 0.5455

 Epoch 18 / 20
Training Accuracy: 0.5434

Training Loss: 1.045
Validation Loss: 1.185
Validation Accuracy: 0.5455

 Epoch 19 / 20
Training Accuracy: 0.5434

Training Loss: 1.038
Validation Loss: 1.177
Validation Accuracy: 0.5455

 Epoch 20 / 20
Training Accuracy: 0.5451

Training Loss: 1.031
Validation Loss: 1.173
Validation Accuracy: 0.5455


         == flag 1.601 bert result On test data ==
# called_model : bert
# Test Accuracy: 0.6750%
Precision: 0.4556
Recall: 0.6750
F1 Score: 0.5440
Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        45
           1       0.68      1.00      0.81       189
           2       0.00      0.00      0.00        46

    accuracy                           0.68       280
   macro avg       0.23      0.33      0.27       280
weighted avg       0.46      0.68      0.54       280

Confusion Matrix:
[[  0  45   0]
 [  0 189   0]
 [  0  46   0]]

flag 1.11  model:  finished  with:   bert





===================================================== 
flag 1.10  model:  started with ==>   roberta
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.0000

Training Loss: 1.403
Validation Loss: 1.400
Validation Accuracy: 0.0000

 Epoch 2 / 20
Training Accuracy: 0.5213

Training Loss: 1.387
Validation Loss: 1.390
Validation Accuracy: 0.5303

 Epoch 3 / 20
Training Accuracy: 0.5434

Training Loss: 1.371
Validation Loss: 1.380
Validation Accuracy: 0.5455

 Epoch 4 / 20
Training Accuracy: 0.5434

Training Loss: 1.354
Validation Loss: 1.367
Validation Accuracy: 0.5455

 Epoch 5 / 20
Training Accuracy: 0.5434

Training Loss: 1.333
Validation Loss: 1.349
Validation Accuracy: 0.5455

 Epoch 6 / 20
Training Accuracy: 0.5434

Training Loss: 1.304
Validation Loss: 1.325
Validation Accuracy: 0.5455

 Epoch 7 / 20
Training Accuracy: 0.5434

Training Loss: 1.261
Validation Loss: 1.291
Validation Accuracy: 0.5455

 Epoch 8 / 20
Training Accuracy: 0.5434

Training Loss: 1.208
Validation Loss: 1.260
Validation Accuracy: 0.5455

 Epoch 9 / 20
Training Accuracy: 0.5434

Training Loss: 1.167
Validation Loss: 1.242
Validation Accuracy: 0.5455

 Epoch 10 / 20
Training Accuracy: 0.5434

Training Loss: 1.133
Validation Loss: 1.233
Validation Accuracy: 0.5455

 Epoch 11 / 20
Training Accuracy: 0.5434

Training Loss: 1.107
Validation Loss: 1.222
Validation Accuracy: 0.5455

 Epoch 12 / 20
Training Accuracy: 0.5434

Training Loss: 1.091
Validation Loss: 1.211
Validation Accuracy: 0.5455

 Epoch 13 / 20
Training Accuracy: 0.5434

Training Loss: 1.067
Validation Loss: 1.203
Validation Accuracy: 0.5455

 Epoch 14 / 20
Training Accuracy: 0.5434

Training Loss: 1.062
Validation Loss: 1.193
Validation Accuracy: 0.5455

 Epoch 15 / 20
Training Accuracy: 0.5434

Training Loss: 1.044
Validation Loss: 1.177
Validation Accuracy: 0.5455

 Epoch 16 / 20
Training Accuracy: 0.5434

Training Loss: 1.035
Validation Loss: 1.160
Validation Accuracy: 0.5455

 Epoch 17 / 20
Training Accuracy: 0.5434

Training Loss: 1.015
Validation Loss: 1.137
Validation Accuracy: 0.5455

 Epoch 18 / 20
Training Accuracy: 0.5434

Training Loss: 1.002
Validation Loss: 1.113
Validation Accuracy: 0.5455

 Epoch 19 / 20
Training Accuracy: 0.5486

Training Loss: 0.977
Validation Loss: 1.087
Validation Accuracy: 0.5455

 Epoch 20 / 20
Training Accuracy: 0.5826

Training Loss: 0.958
Validation Loss: 1.065
Validation Accuracy: 0.5606


         == flag 1.601 roberta result On test data ==
# called_model : roberta
# Test Accuracy: 0.6607%
Precision: 0.5094
Recall: 0.6607
F1 Score: 0.5572
Classification Report:
              precision    recall  f1-score   support

           0       0.33      0.09      0.14        45
           1       0.68      0.96      0.79       189
           2       0.00      0.00      0.00        46

    accuracy                           0.66       280
   macro avg       0.34      0.35      0.31       280
weighted avg       0.51      0.66      0.56       280

Confusion Matrix:
[[  4  41   0]
 [  8 181   0]
 [  0  46   0]]

flag 1.11  model:  finished  with:   roberta





===================================================== 
flag 1.10  model:  started with ==>   distilbert
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.5434

Training Loss: 1.324
Validation Loss: 1.359
Validation Accuracy: 0.5455

 Epoch 2 / 20
Training Accuracy: 0.5434

Training Loss: 1.291
Validation Loss: 1.339
Validation Accuracy: 0.5455

 Epoch 3 / 20
Training Accuracy: 0.5434

Training Loss: 1.264
Validation Loss: 1.320
Validation Accuracy: 0.5455

 Epoch 4 / 20
Training Accuracy: 0.5434

Training Loss: 1.239
Validation Loss: 1.303
Validation Accuracy: 0.5455

 Epoch 5 / 20
Training Accuracy: 0.5434

Training Loss: 1.207
Validation Loss: 1.284
Validation Accuracy: 0.5455

 Epoch 6 / 20
Training Accuracy: 0.5434

Training Loss: 1.176
Validation Loss: 1.267
Validation Accuracy: 0.5455

 Epoch 7 / 20
Training Accuracy: 0.5434

Training Loss: 1.130
Validation Loss: 1.252
Validation Accuracy: 0.5455

 Epoch 8 / 20
Training Accuracy: 0.5434

Training Loss: 1.103
Validation Loss: 1.233
Validation Accuracy: 0.5455

 Epoch 9 / 20
Training Accuracy: 0.5434

Training Loss: 1.092
Validation Loss: 1.217
Validation Accuracy: 0.5455

 Epoch 10 / 20
Training Accuracy: 0.5434

Training Loss: 1.063
Validation Loss: 1.189
Validation Accuracy: 0.5455

 Epoch 11 / 20
Training Accuracy: 0.5434

Training Loss: 1.047
Validation Loss: 1.180
Validation Accuracy: 0.5455

 Epoch 12 / 20
Training Accuracy: 0.5434

Training Loss: 1.045
Validation Loss: 1.163
Validation Accuracy: 0.5455

 Epoch 13 / 20
Training Accuracy: 0.5434

Training Loss: 1.019
Validation Loss: 1.152
Validation Accuracy: 0.5455

 Epoch 14 / 20
Training Accuracy: 0.5434

Training Loss: 1.015
Validation Loss: 1.140
Validation Accuracy: 0.5455

 Epoch 15 / 20
Training Accuracy: 0.5434

Training Loss: 0.999
Validation Loss: 1.123
Validation Accuracy: 0.5455

 Epoch 16 / 20
Training Accuracy: 0.5434

Training Loss: 1.008
Validation Loss: 1.123
Validation Accuracy: 0.5455

 Epoch 17 / 20
Training Accuracy: 0.5434

Training Loss: 0.989
Validation Loss: 1.111
Validation Accuracy: 0.5455

 Epoch 18 / 20
Training Accuracy: 0.5434

Training Loss: 0.963
Validation Loss: 1.101
Validation Accuracy: 0.5455

 Epoch 19 / 20
Training Accuracy: 0.5451

Training Loss: 0.950
Validation Loss: 1.094
Validation Accuracy: 0.5455

 Epoch 20 / 20
Training Accuracy: 0.5486

Training Loss: 0.947
Validation Loss: 1.076
Validation Accuracy: 0.5455


         == flag 1.601 distilbert result On test data ==
# called_model : distilbert
# Test Accuracy: 0.6679%
Precision: 0.4540
Recall: 0.6679
F1 Score: 0.5406
Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        45
           1       0.67      0.99      0.80       189
           2       0.00      0.00      0.00        46

    accuracy                           0.67       280
   macro avg       0.22      0.33      0.27       280
weighted avg       0.45      0.67      0.54       280

Confusion Matrix:
[[  0  45   0]
 [  2 187   0]
 [  0  46   0]]

flag 1.11  model:  finished  with:   distilbert





===================================================== 
flag 1.10  model:  started with ==>   electra
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.1022

Training Loss: 1.443
Validation Loss: 1.401
Validation Accuracy: 0.1515

 Epoch 2 / 20
Training Accuracy: 0.3884

Training Loss: 1.401
Validation Loss: 1.371
Validation Accuracy: 0.4091

 Epoch 3 / 20
Training Accuracy: 0.5451

Training Loss: 1.358
Validation Loss: 1.339
Validation Accuracy: 0.5758

 Epoch 4 / 20
Training Accuracy: 0.5366

Training Loss: 1.319
Validation Loss: 1.311
Validation Accuracy: 0.5606

 Epoch 5 / 20
Training Accuracy: 0.5451

Training Loss: 1.282
Validation Loss: 1.283
Validation Accuracy: 0.5455

 Epoch 6 / 20
Training Accuracy: 0.5434

Training Loss: 1.245
Validation Loss: 1.264
Validation Accuracy: 0.5455

 Epoch 7 / 20
Training Accuracy: 0.5434

Training Loss: 1.212
Validation Loss: 1.248
Validation Accuracy: 0.5455

 Epoch 8 / 20
Training Accuracy: 0.5434

Training Loss: 1.194
Validation Loss: 1.238
Validation Accuracy: 0.5455

 Epoch 9 / 20
Training Accuracy: 0.5434

Training Loss: 1.171
Validation Loss: 1.229
Validation Accuracy: 0.5455

 Epoch 10 / 20
Training Accuracy: 0.5434

Training Loss: 1.155
Validation Loss: 1.221
Validation Accuracy: 0.5455

 Epoch 11 / 20
Training Accuracy: 0.5434

Training Loss: 1.140
Validation Loss: 1.213
Validation Accuracy: 0.5455

 Epoch 12 / 20
Training Accuracy: 0.5434

Training Loss: 1.127
Validation Loss: 1.206
Validation Accuracy: 0.5455

 Epoch 13 / 20
Training Accuracy: 0.5434

Training Loss: 1.104
Validation Loss: 1.200
Validation Accuracy: 0.5455

 Epoch 14 / 20
Training Accuracy: 0.5434

Training Loss: 1.100
Validation Loss: 1.193
Validation Accuracy: 0.5455

 Epoch 15 / 20
Training Accuracy: 0.5434

Training Loss: 1.076
Validation Loss: 1.185
Validation Accuracy: 0.5455

 Epoch 16 / 20
Training Accuracy: 0.5434

Training Loss: 1.079
Validation Loss: 1.178
Validation Accuracy: 0.5455

 Epoch 17 / 20
Training Accuracy: 0.5434

Training Loss: 1.067
Validation Loss: 1.168
Validation Accuracy: 0.5455

 Epoch 18 / 20
Training Accuracy: 0.5434

Training Loss: 1.061
Validation Loss: 1.159
Validation Accuracy: 0.5455

 Epoch 19 / 20
Training Accuracy: 0.5434

Training Loss: 1.054
Validation Loss: 1.149
Validation Accuracy: 0.5455

 Epoch 20 / 20
Training Accuracy: 0.5434

Training Loss: 1.042
Validation Loss: 1.142
Validation Accuracy: 0.5455


         == flag 1.601 electra result On test data ==
# called_model : electra
# Test Accuracy: 0.6750%
Precision: 0.4556
Recall: 0.6750
F1 Score: 0.5440
Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        45
           1       0.68      1.00      0.81       189
           2       0.00      0.00      0.00        46

    accuracy                           0.68       280
   macro avg       0.23      0.33      0.27       280
weighted avg       0.46      0.68      0.54       280

Confusion Matrix:
[[  0  45   0]
 [  0 189   0]
 [  0  46   0]]

flag 1.11  model:  finished  with:   electra





===================================================== 
flag 1.10  model:  started with ==>   gpt2
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.3833

Training Loss: 1.312
Validation Loss: 1.115
Validation Accuracy: 0.3939

 Epoch 2 / 20
Training Accuracy: 0.5230

Training Loss: 1.250
Validation Loss: 1.111
Validation Accuracy: 0.4091

 Epoch 3 / 20
Training Accuracy: 0.5383

Training Loss: 1.273
Validation Loss: 1.114
Validation Accuracy: 0.5303

 Epoch 4 / 20
Training Accuracy: 0.5434

Training Loss: 1.208
Validation Loss: 1.118
Validation Accuracy: 0.5455

 Epoch 5 / 20
Training Accuracy: 0.5451

Training Loss: 1.175
Validation Loss: 1.125
Validation Accuracy: 0.5455

 Epoch 6 / 20
Training Accuracy: 0.5434

Training Loss: 1.155
Validation Loss: 1.131
Validation Accuracy: 0.5455

 Epoch 7 / 20
Training Accuracy: 0.5434

Training Loss: 1.130
Validation Loss: 1.141
Validation Accuracy: 0.5455

 Epoch 8 / 20
Training Accuracy: 0.5434

Training Loss: 1.185
Validation Loss: 1.148
Validation Accuracy: 0.5455

 Epoch 9 / 20
Training Accuracy: 0.5434

Training Loss: 1.089
Validation Loss: 1.156
Validation Accuracy: 0.5455

 Epoch 10 / 20
Training Accuracy: 0.5434

Training Loss: 1.099
Validation Loss: 1.158
Validation Accuracy: 0.5455

 Epoch 11 / 20
Training Accuracy: 0.5434

Training Loss: 1.106
Validation Loss: 1.165
Validation Accuracy: 0.5455

 Epoch 12 / 20
Training Accuracy: 0.5417

Training Loss: 1.104
Validation Loss: 1.157
Validation Accuracy: 0.5455

 Epoch 13 / 20
Training Accuracy: 0.5434

Training Loss: 1.065
Validation Loss: 1.158
Validation Accuracy: 0.5455

 Epoch 14 / 20
Training Accuracy: 0.5434

Training Loss: 1.061
Validation Loss: 1.157
Validation Accuracy: 0.5455

 Epoch 15 / 20
Training Accuracy: 0.5417

Training Loss: 1.088
Validation Loss: 1.153
Validation Accuracy: 0.5455

 Epoch 16 / 20
Training Accuracy: 0.5434

Training Loss: 1.047
Validation Loss: 1.153
Validation Accuracy: 0.5455

 Epoch 17 / 20
Training Accuracy: 0.5434

Training Loss: 1.035
Validation Loss: 1.149
Validation Accuracy: 0.5455

 Epoch 18 / 20
Training Accuracy: 0.5434

Training Loss: 1.066
Validation Loss: 1.155
Validation Accuracy: 0.5455

 Epoch 19 / 20
Training Accuracy: 0.5434

Training Loss: 1.030
Validation Loss: 1.152
Validation Accuracy: 0.5455

 Epoch 20 / 20
Training Accuracy: 0.5434

Training Loss: 1.063
Validation Loss: 1.146
Validation Accuracy: 0.5455


         == flag 1.601 gpt2 result On test data ==
# called_model : gpt2
# Test Accuracy: 0.5679%
Precision: 0.4820
Recall: 0.5679
F1 Score: 0.5213
Classification Report:
              precision    recall  f1-score   support

           0       0.19      0.24      0.21        45
           1       0.67      0.78      0.72       189
           2       0.00      0.00      0.00        46

    accuracy                           0.57       280
   macro avg       0.29      0.34      0.31       280
weighted avg       0.48      0.57      0.52       280

Confusion Matrix:
[[ 11  34   0]
 [ 41 148   0]
 [  7  39   0]]

flag 1.11  model:  finished  with:   gpt2





===================================================== 
flag 1.10  model:  started with ==>   longformer
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.4957

Training Loss: 1.388
Validation Loss: 1.395
Validation Accuracy: 0.5152

 Epoch 2 / 20
Training Accuracy: 0.5434

Training Loss: 1.373
Validation Loss: 1.383
Validation Accuracy: 0.5455

 Epoch 3 / 20
Training Accuracy: 0.5434

Training Loss: 1.352
Validation Loss: 1.371
Validation Accuracy: 0.5455

 Epoch 4 / 20
Training Accuracy: 0.5434

Training Loss: 1.330
Validation Loss: 1.355
Validation Accuracy: 0.5455

 Epoch 5 / 20
Training Accuracy: 0.5434

Training Loss: 1.301
Validation Loss: 1.335
Validation Accuracy: 0.5455

 Epoch 6 / 20
Training Accuracy: 0.5434

Training Loss: 1.270
Validation Loss: 1.305
Validation Accuracy: 0.5455

 Epoch 7 / 20
Training Accuracy: 0.5434

Training Loss: 1.219
Validation Loss: 1.266
Validation Accuracy: 0.5455

 Epoch 8 / 20
Training Accuracy: 0.5434

Training Loss: 1.144
Validation Loss: 1.238
Validation Accuracy: 0.5455

 Epoch 9 / 20
Training Accuracy: 0.5434

Training Loss: 1.093
Validation Loss: 1.218
Validation Accuracy: 0.5455

 Epoch 10 / 20
Training Accuracy: 0.5434

Training Loss: 1.064
Validation Loss: 1.197
Validation Accuracy: 0.5455

 Epoch 11 / 20
Training Accuracy: 0.5434

Training Loss: 1.052
Validation Loss: 1.173
Validation Accuracy: 0.5455

 Epoch 12 / 20
Training Accuracy: 0.5434

Training Loss: 1.014
Validation Loss: 1.148
Validation Accuracy: 0.5455

 Epoch 13 / 20
Training Accuracy: 0.5434

Training Loss: 1.002
Validation Loss: 1.122
Validation Accuracy: 0.5455

 Epoch 14 / 20
