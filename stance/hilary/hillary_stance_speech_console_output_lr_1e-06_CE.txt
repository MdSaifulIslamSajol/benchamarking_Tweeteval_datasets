learning rate  : 1e-06
epochs : 20
                                                text  label
0  If a man demanded staff to get him an ice tea ...      1
1  We're out here in G-town, and where are you  #...      0
2  If you're not watching @user speech right now ...      2
3    How can she live with herself? #Benghazi #SemST      1
4  Jimmy Fallon music playing. Thank you .... #Do...      0
                                                text
0  If a man demanded staff to get him an ice tea ...
1  We're out here in G-town, and where are you  #...
2  If you're not watching @user speech right now ...
3    How can she live with herself? #Benghazi #SemST
4  Jimmy Fallon music playing. Thank you .... #Do...
   label
0      1
1      0
2      2
3      1
4      0
                                                text  label
0  Fabulous @user ! You hit on every subject and ...      2
1  Make sure to make it to the Brew House in Pell...      1
2  It's what's best for business and presidential...      1
3  I suspect Hillary's Scooby Doo tour is being u...      1
4  @user @user 2 hours left, let's chip in $5, Ne...      1
                                                text
0  Fabulous @user ! You hit on every subject and ...
1  Make sure to make it to the Brew House in Pell...
2  It's what's best for business and presidential...
3  I suspect Hillary's Scooby Doo tour is being u...
4  @user @user 2 hours left, let's chip in $5, Ne...
   label
0      2
1      1
2      1
3      1
4      1
                                                text  label
0  #mtp @user How is deleting emails -part of the...      1
1  @user @user AndrewWhyDoYouCareAboutWhatIThink?...      1
2  The white male vote is solidly GOP. The black ...      1
3  @user big banker buds need to ratchet up their...      1
4  @user Why should I believe you on this? The GO...      1
                                                text
0  #mtp @user How is deleting emails -part of the...
1  @user @user AndrewWhyDoYouCareAboutWhatIThink?...
2  The white male vote is solidly GOP. The black ...
3  @user big banker buds need to ratchet up their...
4  @user Why should I believe you on this? The GO...
                                                text
0  #mtp @user How is deleting emails -part of the...
1  @user @user AndrewWhyDoYouCareAboutWhatIThink?...
2  The white male vote is solidly GOP. The black ...
3  @user big banker buds need to ratchet up their...
4  @user Why should I believe you on this? The GO...
len(train_labels) 620
len(test_labels) 295
len(val_labels) 69

Unique values count in train_labels:
label
1    354
0    160
2    106
Name: count, dtype: int64

Unique values count in val_labels:
label
1    39
0    18
2    12
Name: count, dtype: int64

Unique values count in test_labels:
label
1    172
0     78
2     45
Name: count, dtype: int64





===================================================== 
flag 1.10  model:  started with ==>   bert
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.5710

Training Loss: 1.352
Validation Loss: 1.325
Validation Accuracy: 0.5362

 Epoch 2 / 20
Training Accuracy: 0.5710

Training Loss: 1.299
Validation Loss: 1.282
Validation Accuracy: 0.5652

 Epoch 3 / 20
Training Accuracy: 0.5710

Training Loss: 1.258
Validation Loss: 1.245
Validation Accuracy: 0.5652

 Epoch 4 / 20
Training Accuracy: 0.5710

Training Loss: 1.231
Validation Loss: 1.214
Validation Accuracy: 0.5652

 Epoch 5 / 20
Training Accuracy: 0.5710

Training Loss: 1.200
Validation Loss: 1.185
Validation Accuracy: 0.5652

 Epoch 6 / 20
Training Accuracy: 0.5710

Training Loss: 1.178
Validation Loss: 1.160
Validation Accuracy: 0.5652

 Epoch 7 / 20
Training Accuracy: 0.5710

Training Loss: 1.147
Validation Loss: 1.138
Validation Accuracy: 0.5652

 Epoch 8 / 20
Training Accuracy: 0.5710

Training Loss: 1.131
Validation Loss: 1.120
Validation Accuracy: 0.5652

 Epoch 9 / 20
Training Accuracy: 0.5710

Training Loss: 1.108
Validation Loss: 1.105
Validation Accuracy: 0.5652

 Epoch 10 / 20
Training Accuracy: 0.5710

Training Loss: 1.102
Validation Loss: 1.091
Validation Accuracy: 0.5652

 Epoch 11 / 20
Training Accuracy: 0.5710

Training Loss: 1.080
Validation Loss: 1.078
Validation Accuracy: 0.5652

 Epoch 12 / 20
Training Accuracy: 0.5710

Training Loss: 1.062
Validation Loss: 1.068
Validation Accuracy: 0.5652

 Epoch 13 / 20
Training Accuracy: 0.5710

Training Loss: 1.050
Validation Loss: 1.060
Validation Accuracy: 0.5652

 Epoch 14 / 20
Training Accuracy: 0.5710

Training Loss: 1.045
Validation Loss: 1.052
Validation Accuracy: 0.5652

 Epoch 15 / 20
Training Accuracy: 0.5710

Training Loss: 1.022
Validation Loss: 1.044
Validation Accuracy: 0.5652

 Epoch 16 / 20
Training Accuracy: 0.5710

Training Loss: 1.011
Validation Loss: 1.040
Validation Accuracy: 0.5652

 Epoch 17 / 20
Training Accuracy: 0.5726

Training Loss: 0.991
Validation Loss: 1.035
Validation Accuracy: 0.5652

 Epoch 18 / 20
Training Accuracy: 0.5774

Training Loss: 0.987
Validation Loss: 1.029
Validation Accuracy: 0.5652

 Epoch 19 / 20
Training Accuracy: 0.5823

Training Loss: 0.981
Validation Loss: 1.023
Validation Accuracy: 0.5652

 Epoch 20 / 20
Training Accuracy: 0.5968

Training Loss: 0.963
Validation Loss: 1.018
Validation Accuracy: 0.5652


         == flag 1.601 bert result On test data ==
# called_model : bert
# Test Accuracy: 0.5831%
Precision: 0.3411
Recall: 0.5831
F1 Score: 0.4304
Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        78
           1       0.59      1.00      0.74       172
           2       0.00      0.00      0.00        45

    accuracy                           0.58       295
   macro avg       0.20      0.33      0.25       295
weighted avg       0.34      0.58      0.43       295

Confusion Matrix:
[[  0  78   0]
 [  0 172   0]
 [  1  44   0]]

flag 1.11  model:  finished  with:   bert





===================================================== 
flag 1.10  model:  started with ==>   roberta
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.0000

Training Loss: 1.406
Validation Loss: 1.399
Validation Accuracy: 0.0000

 Epoch 2 / 20
Training Accuracy: 0.4903

Training Loss: 1.388
Validation Loss: 1.382
Validation Accuracy: 0.3768

 Epoch 3 / 20
Training Accuracy: 0.5710

Training Loss: 1.369
Validation Loss: 1.363
Validation Accuracy: 0.5652

 Epoch 4 / 20
Training Accuracy: 0.5710

Training Loss: 1.344
Validation Loss: 1.338
Validation Accuracy: 0.5652

 Epoch 5 / 20
Training Accuracy: 0.5710

Training Loss: 1.315
Validation Loss: 1.298
Validation Accuracy: 0.5652

 Epoch 6 / 20
Training Accuracy: 0.5710

Training Loss: 1.258
Validation Loss: 1.217
Validation Accuracy: 0.5652

 Epoch 7 / 20
Training Accuracy: 0.5710

Training Loss: 1.168
Validation Loss: 1.122
Validation Accuracy: 0.5652

 Epoch 8 / 20
Training Accuracy: 0.5710

Training Loss: 1.114
Validation Loss: 1.078
Validation Accuracy: 0.5652

 Epoch 9 / 20
Training Accuracy: 0.5710

Training Loss: 1.080
Validation Loss: 1.054
Validation Accuracy: 0.5652

 Epoch 10 / 20
Training Accuracy: 0.5710

Training Loss: 1.061
Validation Loss: 1.035
Validation Accuracy: 0.5652

 Epoch 11 / 20
Training Accuracy: 0.5710

Training Loss: 1.039
Validation Loss: 1.020
Validation Accuracy: 0.5652

 Epoch 12 / 20
Training Accuracy: 0.5710

Training Loss: 1.027
Validation Loss: 1.006
Validation Accuracy: 0.5652

 Epoch 13 / 20
Training Accuracy: 0.5710

Training Loss: 1.011
Validation Loss: 0.991
Validation Accuracy: 0.5652

 Epoch 14 / 20
Training Accuracy: 0.5710

Training Loss: 0.993
Validation Loss: 0.977
Validation Accuracy: 0.5652

 Epoch 15 / 20
Training Accuracy: 0.5710

Training Loss: 0.983
Validation Loss: 0.964
Validation Accuracy: 0.5652

 Epoch 16 / 20
Training Accuracy: 0.5710

Training Loss: 0.964
Validation Loss: 0.955
Validation Accuracy: 0.5652

 Epoch 17 / 20
Training Accuracy: 0.5903

Training Loss: 0.946
Validation Loss: 0.945
Validation Accuracy: 0.5797

 Epoch 18 / 20
Training Accuracy: 0.6242

Training Loss: 0.915
Validation Loss: 0.936
Validation Accuracy: 0.5507

 Epoch 19 / 20
Training Accuracy: 0.6435

Training Loss: 0.912
Validation Loss: 0.932
Validation Accuracy: 0.5507

 Epoch 20 / 20
Training Accuracy: 0.6597

Training Loss: 0.903
Validation Loss: 0.932
Validation Accuracy: 0.5217


         == flag 1.601 roberta result On test data ==
# called_model : roberta
# Test Accuracy: 0.6407%
Precision: 0.5349
Recall: 0.6407
F1 Score: 0.5620
Classification Report:
              precision    recall  f1-score   support

           0       0.59      0.33      0.43        78
           1       0.65      0.95      0.77       172
           2       0.00      0.00      0.00        45

    accuracy                           0.64       295
   macro avg       0.41      0.43      0.40       295
weighted avg       0.53      0.64      0.56       295

Confusion Matrix:
[[ 26  52   0]
 [  9 163   0]
 [  9  36   0]]

flag 1.11  model:  finished  with:   roberta





===================================================== 
flag 1.10  model:  started with ==>   distilbert
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.4242

Training Loss: 1.356
Validation Loss: 1.336
Validation Accuracy: 0.3188

 Epoch 2 / 20
Training Accuracy: 0.5871

Training Loss: 1.318
Validation Loss: 1.298
Validation Accuracy: 0.5797

 Epoch 3 / 20
Training Accuracy: 0.5726

Training Loss: 1.277
Validation Loss: 1.255
Validation Accuracy: 0.5652

 Epoch 4 / 20
Training Accuracy: 0.5710

Training Loss: 1.231
Validation Loss: 1.203
Validation Accuracy: 0.5652

 Epoch 5 / 20
Training Accuracy: 0.5710

Training Loss: 1.172
Validation Loss: 1.144
Validation Accuracy: 0.5652

 Epoch 6 / 20
Training Accuracy: 0.5710

Training Loss: 1.129
Validation Loss: 1.097
Validation Accuracy: 0.5652

 Epoch 7 / 20
Training Accuracy: 0.5710

Training Loss: 1.084
Validation Loss: 1.067
Validation Accuracy: 0.5652

 Epoch 8 / 20
Training Accuracy: 0.5710

Training Loss: 1.058
Validation Loss: 1.049
Validation Accuracy: 0.5652

 Epoch 9 / 20
Training Accuracy: 0.5710

Training Loss: 1.043
Validation Loss: 1.036
Validation Accuracy: 0.5652

 Epoch 10 / 20
Training Accuracy: 0.5710

Training Loss: 1.023
Validation Loss: 1.026
Validation Accuracy: 0.5652

 Epoch 11 / 20
Training Accuracy: 0.5710

Training Loss: 1.010
Validation Loss: 1.018
Validation Accuracy: 0.5652

 Epoch 12 / 20
Training Accuracy: 0.5710

Training Loss: 1.006
Validation Loss: 1.011
Validation Accuracy: 0.5652

 Epoch 13 / 20
Training Accuracy: 0.5710

Training Loss: 0.998
Validation Loss: 1.005
Validation Accuracy: 0.5652

 Epoch 14 / 20
Training Accuracy: 0.5710

Training Loss: 0.994
Validation Loss: 0.999
Validation Accuracy: 0.5652

 Epoch 15 / 20
Training Accuracy: 0.5710

Training Loss: 0.988
Validation Loss: 0.993
Validation Accuracy: 0.5652

 Epoch 16 / 20
Training Accuracy: 0.5710

Training Loss: 0.980
Validation Loss: 0.986
Validation Accuracy: 0.5652

 Epoch 17 / 20
Training Accuracy: 0.5710

Training Loss: 0.974
Validation Loss: 0.980
Validation Accuracy: 0.5652

 Epoch 18 / 20
Training Accuracy: 0.5710

Training Loss: 0.970
Validation Loss: 0.974
Validation Accuracy: 0.5652

 Epoch 19 / 20
Training Accuracy: 0.5710

Training Loss: 0.955
Validation Loss: 0.966
Validation Accuracy: 0.5652

 Epoch 20 / 20
Training Accuracy: 0.5710

Training Loss: 0.947
Validation Loss: 0.959
Validation Accuracy: 0.5652


         == flag 1.601 distilbert result On test data ==
# called_model : distilbert
# Test Accuracy: 0.5831%
Precision: 0.3399
Recall: 0.5831
F1 Score: 0.4295
Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        78
           1       0.58      1.00      0.74       172
           2       0.00      0.00      0.00        45

    accuracy                           0.58       295
   macro avg       0.19      0.33      0.25       295
weighted avg       0.34      0.58      0.43       295

Confusion Matrix:
[[  0  78   0]
 [  0 172   0]
 [  0  45   0]]

flag 1.11  model:  finished  with:   distilbert





===================================================== 
flag 1.10  model:  started with ==>   electra
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.2290

Training Loss: 1.396
Validation Loss: 1.366
Validation Accuracy: 0.2754

 Epoch 2 / 20
Training Accuracy: 0.5484

Training Loss: 1.348
Validation Loss: 1.311
Validation Accuracy: 0.5362

 Epoch 3 / 20
Training Accuracy: 0.5742

Training Loss: 1.304
Validation Loss: 1.262
Validation Accuracy: 0.5362

 Epoch 4 / 20
Training Accuracy: 0.5710

Training Loss: 1.261
Validation Loss: 1.221
Validation Accuracy: 0.5362

 Epoch 5 / 20
Training Accuracy: 0.5710

Training Loss: 1.220
Validation Loss: 1.184
Validation Accuracy: 0.5652

 Epoch 6 / 20
Training Accuracy: 0.5710

Training Loss: 1.182
Validation Loss: 1.150
Validation Accuracy: 0.5652

 Epoch 7 / 20
Training Accuracy: 0.5710

Training Loss: 1.157
Validation Loss: 1.121
Validation Accuracy: 0.5652

 Epoch 8 / 20
Training Accuracy: 0.5710

Training Loss: 1.124
Validation Loss: 1.099
Validation Accuracy: 0.5652

 Epoch 9 / 20
Training Accuracy: 0.5710

Training Loss: 1.101
Validation Loss: 1.081
Validation Accuracy: 0.5652

 Epoch 10 / 20
Training Accuracy: 0.5710

Training Loss: 1.074
Validation Loss: 1.068
Validation Accuracy: 0.5652

 Epoch 11 / 20
Training Accuracy: 0.5710

Training Loss: 1.067
Validation Loss: 1.056
Validation Accuracy: 0.5652

 Epoch 12 / 20
Training Accuracy: 0.5710

Training Loss: 1.048
Validation Loss: 1.048
Validation Accuracy: 0.5652

 Epoch 13 / 20
Training Accuracy: 0.5710

Training Loss: 1.052
Validation Loss: 1.039
Validation Accuracy: 0.5652

 Epoch 14 / 20
Training Accuracy: 0.5710

Training Loss: 1.038
Validation Loss: 1.033
Validation Accuracy: 0.5652

 Epoch 15 / 20
Training Accuracy: 0.5710

Training Loss: 1.030
Validation Loss: 1.026
Validation Accuracy: 0.5652

 Epoch 16 / 20
Training Accuracy: 0.5710

Training Loss: 1.015
Validation Loss: 1.019
Validation Accuracy: 0.5652

 Epoch 17 / 20
Training Accuracy: 0.5710

Training Loss: 1.017
Validation Loss: 1.014
Validation Accuracy: 0.5652

 Epoch 18 / 20
Training Accuracy: 0.5710

Training Loss: 1.009
Validation Loss: 1.010
Validation Accuracy: 0.5652

 Epoch 19 / 20
Training Accuracy: 0.5710

Training Loss: 0.992
Validation Loss: 1.004
Validation Accuracy: 0.5652

 Epoch 20 / 20
Training Accuracy: 0.5710

Training Loss: 0.990
Validation Loss: 0.998
Validation Accuracy: 0.5652


         == flag 1.601 electra result On test data ==
# called_model : electra
# Test Accuracy: 0.5831%
Precision: 0.3399
Recall: 0.5831
F1 Score: 0.4295
Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        78
           1       0.58      1.00      0.74       172
           2       0.00      0.00      0.00        45

    accuracy                           0.58       295
   macro avg       0.19      0.33      0.25       295
weighted avg       0.34      0.58      0.43       295

Confusion Matrix:
[[  0  78   0]
 [  0 172   0]
 [  0  45   0]]

flag 1.11  model:  finished  with:   electra





===================================================== 
flag 1.10  model:  started with ==>   gpt2
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.2565

Training Loss: 3.317
Validation Loss: 3.425
Validation Accuracy: 0.2609

 Epoch 2 / 20
Training Accuracy: 0.3210

Training Loss: 2.527
Validation Loss: 2.365
Validation Accuracy: 0.3478

 Epoch 3 / 20
Training Accuracy: 0.4403

Training Loss: 2.020
Validation Loss: 1.693
Validation Accuracy: 0.4348

 Epoch 4 / 20
Training Accuracy: 0.5177

Training Loss: 1.577
Validation Loss: 1.383
Validation Accuracy: 0.4783

 Epoch 5 / 20
Training Accuracy: 0.5452

Training Loss: 1.419
Validation Loss: 1.232
Validation Accuracy: 0.5072

 Epoch 6 / 20
Training Accuracy: 0.5387

Training Loss: 1.376
Validation Loss: 1.181
Validation Accuracy: 0.5362

 Epoch 7 / 20
Training Accuracy: 0.5468

Training Loss: 1.359
Validation Loss: 1.170
Validation Accuracy: 0.5362

 Epoch 8 / 20
Training Accuracy: 0.5565

Training Loss: 1.274
Validation Loss: 1.150
Validation Accuracy: 0.5217

 Epoch 9 / 20
Training Accuracy: 0.5613

Training Loss: 1.263
Validation Loss: 1.140
Validation Accuracy: 0.5362

 Epoch 10 / 20
Training Accuracy: 0.5677

Training Loss: 1.234
Validation Loss: 1.133
Validation Accuracy: 0.5362

 Epoch 11 / 20
Training Accuracy: 0.5710

Training Loss: 1.214
Validation Loss: 1.125
Validation Accuracy: 0.5362

 Epoch 12 / 20
Training Accuracy: 0.5710

Training Loss: 1.174
Validation Loss: 1.117
Validation Accuracy: 0.5362

 Epoch 13 / 20
Training Accuracy: 0.5742

Training Loss: 1.165
Validation Loss: 1.104
Validation Accuracy: 0.5362

 Epoch 14 / 20
Training Accuracy: 0.5710

Training Loss: 1.138
Validation Loss: 1.083
Validation Accuracy: 0.5507

 Epoch 15 / 20
Training Accuracy: 0.5710

Training Loss: 1.165
Validation Loss: 1.074
Validation Accuracy: 0.5507

 Epoch 16 / 20
Training Accuracy: 0.5726

Training Loss: 1.159
Validation Loss: 1.069
Validation Accuracy: 0.5507

 Epoch 17 / 20
Training Accuracy: 0.5694

Training Loss: 1.171
Validation Loss: 1.064
Validation Accuracy: 0.5362

 Epoch 18 / 20
Training Accuracy: 0.5726

Training Loss: 1.145
Validation Loss: 1.063
Validation Accuracy: 0.5362

 Epoch 19 / 20
Training Accuracy: 0.5726

Training Loss: 1.157
Validation Loss: 1.077
Validation Accuracy: 0.5362

 Epoch 20 / 20
Training Accuracy: 0.5694

Training Loss: 1.137
Validation Loss: 1.060
Validation Accuracy: 0.5362


         == flag 1.601 gpt2 result On test data ==
# called_model : gpt2
# Test Accuracy: 0.5797%
Precision: 0.3391
Recall: 0.5797
F1 Score: 0.4279
Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        78
           1       0.58      0.99      0.73       172
           2       0.00      0.00      0.00        45

    accuracy                           0.58       295
   macro avg       0.19      0.33      0.24       295
weighted avg       0.34      0.58      0.43       295

Confusion Matrix:
[[  0  78   0]
 [  1 171   0]
 [  0  45   0]]

flag 1.11  model:  finished  with:   gpt2





===================================================== 
flag 1.10  model:  started with ==>   longformer
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.5710

Training Loss: 1.330
Validation Loss: 1.324
Validation Accuracy: 0.5652

 Epoch 2 / 20
Training Accuracy: 0.5710

Training Loss: 1.309
Validation Loss: 1.304
Validation Accuracy: 0.5652

 Epoch 3 / 20
Training Accuracy: 0.5710

Training Loss: 1.284
Validation Loss: 1.281
Validation Accuracy: 0.5652

 Epoch 4 / 20
Training Accuracy: 0.5710

Training Loss: 1.259
Validation Loss: 1.255
Validation Accuracy: 0.5652

 Epoch 5 / 20
Training Accuracy: 0.5710

Training Loss: 1.223
Validation Loss: 1.221
Validation Accuracy: 0.5652

 Epoch 6 / 20
Training Accuracy: 0.5710

Training Loss: 1.191
Validation Loss: 1.172
Validation Accuracy: 0.5652

 Epoch 7 / 20
Training Accuracy: 0.5710

Training Loss: 1.131
Validation Loss: 1.100
Validation Accuracy: 0.5652

 Epoch 8 / 20
