learning rate  : 1e-06
epochs : 20
                                                text  label
0  Why Is The Pope Upset?  via @user #UnzippedTru...      0
1  We support Australia's Climate Roundtable whic...      2
2  It's nights like this when I'm not so fond of ...      0
3  #Republican party will go down in history book...      0
4  RT @user @user We need degrowth - stop destroy...      2
                                                text
0  Why Is The Pope Upset?  via @user #UnzippedTru...
1  We support Australia's Climate Roundtable whic...
2  It's nights like this when I'm not so fond of ...
3  #Republican party will go down in history book...
4  RT @user @user We need degrowth - stop destroy...
   label
0      0
1      2
2      0
3      0
4      2
                                                text  label
0  #Mission:#Climate @ home > Simplify (by @user ...      2
1  Can @user use $866,615 of jet fuel on His #Ear...      0
2  .@whelan60 "While this debate goes on, yet mor...      0
3  Sir David Attenborough and @user  dissgussing ...      2
4  How did the #GreatBarrierReef look to you comp...      2
                                                text
0  #Mission:#Climate @ home > Simplify (by @user ...
1  Can @user use $866,615 of jet fuel on His #Ear...
2  .@whelan60 "While this debate goes on, yet mor...
3  Sir David Attenborough and @user  dissgussing ...
4  How did the #GreatBarrierReef look to you comp...
   label
0      2
1      0
2      0
3      2
4      2
                                                text  label
0  Closed door session begins. More after they de...      0
1  What is the #energiewende agenda? Why are they...      2
2  @user Stocker: Fish catch potential could drop...      2
3  ...a longer memory, and a sterner sense of jus...      0
4  Boni "Future Sea level rise will not be unifor...      2
                                                text
0  Closed door session begins. More after they de...
1  What is the #energiewende agenda? Why are they...
2  @user Stocker: Fish catch potential could drop...
3  ...a longer memory, and a sterner sense of jus...
4  Boni "Future Sea level rise will not be unifor...
                                                text
0  Closed door session begins. More after they de...
1  What is the #energiewende agenda? Why are they...
2  @user Stocker: Fish catch potential could drop...
3  ...a longer memory, and a sterner sense of jus...
4  Boni "Future Sea level rise will not be unifor...
len(train_labels) 355
len(test_labels) 169
len(val_labels) 40

Unique values count in train_labels:
label
2    191
0    151
1     13
Name: count, dtype: int64

Unique values count in val_labels:
label
2    21
0    17
1     2
Name: count, dtype: int64

Unique values count in test_labels:
label
2    123
0     35
1     11
Name: count, dtype: int64





===================================================== 
flag 1.10  model:  started with ==>   t5
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.4254

Training Loss: 1.316
Validation Loss: 1.274
Validation Accuracy: 0.4250

 Epoch 2 / 20
Training Accuracy: 0.4254

Training Loss: 1.332
Validation Loss: 1.269
Validation Accuracy: 0.4250

 Epoch 3 / 20
Training Accuracy: 0.4254

Training Loss: 1.317
Validation Loss: 1.265
Validation Accuracy: 0.4250

 Epoch 4 / 20
Training Accuracy: 0.4254

Training Loss: 1.312
Validation Loss: 1.261
Validation Accuracy: 0.4250

 Epoch 5 / 20
Training Accuracy: 0.4254

Training Loss: 1.300
Validation Loss: 1.257
Validation Accuracy: 0.4250

 Epoch 6 / 20
Training Accuracy: 0.4254

Training Loss: 1.312
Validation Loss: 1.252
Validation Accuracy: 0.4250

 Epoch 7 / 20
Training Accuracy: 0.4254

Training Loss: 1.303
Validation Loss: 1.249
Validation Accuracy: 0.4250

 Epoch 8 / 20
Training Accuracy: 0.4254

Training Loss: 1.309
Validation Loss: 1.245
Validation Accuracy: 0.4250

 Epoch 9 / 20
Training Accuracy: 0.4254

Training Loss: 1.294
Validation Loss: 1.241
Validation Accuracy: 0.4250

 Epoch 10 / 20
Training Accuracy: 0.4254

Training Loss: 1.282
Validation Loss: 1.237
Validation Accuracy: 0.4250

 Epoch 11 / 20
Training Accuracy: 0.4254

Training Loss: 1.290
Validation Loss: 1.233
Validation Accuracy: 0.4250

 Epoch 12 / 20
Training Accuracy: 0.4254

Training Loss: 1.286
Validation Loss: 1.229
Validation Accuracy: 0.4250

 Epoch 13 / 20
Training Accuracy: 0.4254

Training Loss: 1.301
Validation Loss: 1.226
Validation Accuracy: 0.4250

 Epoch 14 / 20
Training Accuracy: 0.4254

Training Loss: 1.275
Validation Loss: 1.222
Validation Accuracy: 0.4250

 Epoch 15 / 20
Training Accuracy: 0.4254

Training Loss: 1.263
Validation Loss: 1.218
Validation Accuracy: 0.4250

 Epoch 16 / 20
Training Accuracy: 0.4254

Training Loss: 1.272
Validation Loss: 1.214
Validation Accuracy: 0.4250

 Epoch 17 / 20
Training Accuracy: 0.4254

Training Loss: 1.258
Validation Loss: 1.211
Validation Accuracy: 0.4250

 Epoch 18 / 20
Training Accuracy: 0.4254

Training Loss: 1.257
Validation Loss: 1.207
Validation Accuracy: 0.4250

 Epoch 19 / 20
Training Accuracy: 0.4254

Training Loss: 1.252
Validation Loss: 1.203
Validation Accuracy: 0.4250

 Epoch 20 / 20
Training Accuracy: 0.4254

Training Loss: 1.249
Validation Loss: 1.199
Validation Accuracy: 0.4250


         == flag 1.601 t5 result On test data ==
# called_model : t5
# Test Accuracy: 0.2071%
Precision: 0.0429
Recall: 0.2071
F1 Score: 0.0711
Classification Report:
              precision    recall  f1-score   support

           0       0.21      1.00      0.34        35
           1       0.00      0.00      0.00        11
           2       0.00      0.00      0.00       123

    accuracy                           0.21       169
   macro avg       0.07      0.33      0.11       169
weighted avg       0.04      0.21      0.07       169

Confusion Matrix:
[[ 35   0   0]
 [ 11   0   0]
 [123   0   0]]

flag 1.11  model:  finished  with:   t5





===================================================== 
flag 1.10  model:  started with ==>   xlnet
===================================================== 

 Epoch 1 / 20
Training Accuracy: 0.1972

Training Loss: 1.866
Validation Loss: 1.568
Validation Accuracy: 0.1500

 Epoch 2 / 20
Training Accuracy: 0.4113

Training Loss: 1.473
Validation Loss: 1.324
Validation Accuracy: 0.4000

 Epoch 3 / 20
Training Accuracy: 0.4704

Training Loss: 1.272
Validation Loss: 1.154
Validation Accuracy: 0.5000

 Epoch 4 / 20
Training Accuracy: 0.5042

Training Loss: 1.143
Validation Loss: 1.037
Validation Accuracy: 0.5500

 Epoch 5 / 20
Training Accuracy: 0.5465

Training Loss: 1.034
Validation Loss: 0.949
Validation Accuracy: 0.6000

 Epoch 6 / 20
Training Accuracy: 0.5944

Training Loss: 0.956
Validation Loss: 0.890
Validation Accuracy: 0.5500

 Epoch 7 / 20
Training Accuracy: 0.6254

Training Loss: 0.877
Validation Loss: 0.853
Validation Accuracy: 0.5250

 Epoch 8 / 20
Training Accuracy: 0.6648

Training Loss: 0.829
Validation Loss: 0.838
Validation Accuracy: 0.6250

 Epoch 9 / 20
Training Accuracy: 0.6958

Training Loss: 0.819
Validation Loss: 0.824
Validation Accuracy: 0.6250

 Epoch 10 / 20
Training Accuracy: 0.7070

Training Loss: 0.796
Validation Loss: 0.810
Validation Accuracy: 0.6500

 Epoch 11 / 20
Training Accuracy: 0.7070

Training Loss: 0.797
Validation Loss: 0.794
Validation Accuracy: 0.6500

 Epoch 12 / 20
Training Accuracy: 0.7183

Training Loss: 0.734
Validation Loss: 0.789
Validation Accuracy: 0.6500

 Epoch 13 / 20
Training Accuracy: 0.7408

Training Loss: 0.780
Validation Loss: 0.787
Validation Accuracy: 0.6500

 Epoch 14 / 20
Training Accuracy: 0.7437

Training Loss: 0.754
Validation Loss: 0.753
Validation Accuracy: 0.6500

 Epoch 15 / 20
Training Accuracy: 0.7437

Training Loss: 0.693
Validation Loss: 0.746
Validation Accuracy: 0.6750

 Epoch 16 / 20
Training Accuracy: 0.7493

Training Loss: 0.732
Validation Loss: 0.738
Validation Accuracy: 0.7000

 Epoch 17 / 20
Training Accuracy: 0.7577

Training Loss: 0.653
Validation Loss: 0.721
Validation Accuracy: 0.7000

 Epoch 18 / 20
Training Accuracy: 0.7662

Training Loss: 0.643
Validation Loss: 0.717
Validation Accuracy: 0.7250

 Epoch 19 / 20
Training Accuracy: 0.7718

Training Loss: 0.662
Validation Loss: 0.710
Validation Accuracy: 0.7250

 Epoch 20 / 20
Training Accuracy: 0.7944

Training Loss: 0.641
Validation Loss: 0.676
Validation Accuracy: 0.7000


         == flag 1.601 xlnet result On test data ==
# called_model : xlnet
# Test Accuracy: 0.7633%
Precision: 0.7081
Recall: 0.7633
F1 Score: 0.7343
Classification Report:
              precision    recall  f1-score   support

           0       0.53      0.51      0.52        35
           1       0.00      0.00      0.00        11
           2       0.82      0.90      0.86       123

    accuracy                           0.76       169
   macro avg       0.45      0.47      0.46       169
weighted avg       0.71      0.76      0.73       169

Confusion Matrix:
[[ 18   0  17]
 [  4   0   7]
 [ 12   0 111]]

flag 1.11  model:  finished  with:   xlnet

Execution Finished
