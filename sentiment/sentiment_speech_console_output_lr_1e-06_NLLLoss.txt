learning rate  : 1e-06
epochs : 20
                                                text  label
0  "QT @user In the original draft of the 7th boo...      2
1  "Ben Smith / Smith (concussion) remains out of...      1
2  Sorry bout the stream last night I crashed out...      1
3  Chase Headley's RBI double in the 8th inning o...      1
4  @user Alciato: Bee will invest 150 million in ...      2
                                                text
0  "QT @user In the original draft of the 7th boo...
1  "Ben Smith / Smith (concussion) remains out of...
2  Sorry bout the stream last night I crashed out...
3  Chase Headley's RBI double in the 8th inning o...
4  @user Alciato: Bee will invest 150 million in ...
   label
0      2
1      1
2      1
3      1
4      2
                                                text  label
0  Dark Souls 3 April Launch Date Confirmed With ...      1
1  "National hot dog day, national tequila day, t...      2
2  When girls become bandwagon fans of the Packer...      0
3  @user I may or may not have searched it up on ...      1
4  Here's your starting TUESDAY MORNING Line up a...      1
                                                text
0  Dark Souls 3 April Launch Date Confirmed With ...
1  "National hot dog day, national tequila day, t...
2  When girls become bandwagon fans of the Packer...
3  @user I may or may not have searched it up on ...
4  Here's your starting TUESDAY MORNING Line up a...
   label
0      1
1      2
2      0
3      1
4      1
                                                text  label
0  @user @user what do these '1/2 naked pics' hav...      1
1  OH: “I had a blue penis while I was this” [pla...      1
2  @user @user That's coming, but I think the vic...      1
3  I think I may be finally in with the in crowd ...      2
4  @user Wow,first Hugo Chavez and now Fidel Cast...      0
                                                text
0  @user @user what do these '1/2 naked pics' hav...
1  OH: “I had a blue penis while I was this” [pla...
2  @user @user That's coming, but I think the vic...
3  I think I may be finally in with the in crowd ...
4  @user Wow,first Hugo Chavez and now Fidel Cast...
                                                text
0  @user @user what do these '1/2 naked pics' hav...
1  OH: “I had a blue penis while I was this” [pla...
2  @user @user That's coming, but I think the vic...
3  I think I may be finally in with the in crowd ...
4  @user Wow,first Hugo Chavez and now Fidel Cast...
len(train_labels) 45615
len(test_labels) 12284
len(val_labels) 2000

Unique values count in train_labels:
label
1    20673
2    17849
0     7093
Name: count, dtype: int64

Unique values count in val_labels:
label
1    869
2    819
0    312
Name: count, dtype: int64

Unique values count in test_labels:
label
1    5937
0    3972
2    2375
Name: count, dtype: int64





===================================================== 
flag 1.10  model:  started with ==>   bert
===================================================== 

 Epoch 1 / 20

Training Loss: 0.981
Validation Loss: 0.787
Validation Accuracy: 0.6660

 Epoch 2 / 20

Training Loss: 0.737
Validation Loss: 0.697
Validation Accuracy: 0.6915

 Epoch 3 / 20

Training Loss: 0.671
Validation Loss: 0.670
Validation Accuracy: 0.6955

 Epoch 4 / 20

Training Loss: 0.635
Validation Loss: 0.653
Validation Accuracy: 0.7070

 Epoch 5 / 20

Training Loss: 0.612
Validation Loss: 0.643
Validation Accuracy: 0.7135

 Epoch 6 / 20

Training Loss: 0.592
Validation Loss: 0.634
Validation Accuracy: 0.7165

 Epoch 7 / 20

Training Loss: 0.573
Validation Loss: 0.636
Validation Accuracy: 0.7265

 Epoch 8 / 20

Training Loss: 0.558
Validation Loss: 0.628
Validation Accuracy: 0.7345

 Epoch 9 / 20

Training Loss: 0.541
Validation Loss: 0.630
Validation Accuracy: 0.7280

 Epoch 10 / 20

Training Loss: 0.526
Validation Loss: 0.642
Validation Accuracy: 0.7215

 Epoch 11 / 20

Training Loss: 0.511
Validation Loss: 0.638
Validation Accuracy: 0.7285

 Epoch 12 / 20

Training Loss: 0.496
Validation Loss: 0.637
Validation Accuracy: 0.7340

 Epoch 13 / 20

Training Loss: 0.480
Validation Loss: 0.648
Validation Accuracy: 0.7305

 Epoch 14 / 20

Training Loss: 0.467
Validation Loss: 0.660
Validation Accuracy: 0.7220

 Epoch 15 / 20

Training Loss: 0.451
Validation Loss: 0.663
Validation Accuracy: 0.7360

 Epoch 16 / 20

Training Loss: 0.440
Validation Loss: 0.666
Validation Accuracy: 0.7280

 Epoch 17 / 20

Training Loss: 0.426
Validation Loss: 0.682
Validation Accuracy: 0.7255

 Epoch 18 / 20

Training Loss: 0.414
Validation Loss: 0.687
Validation Accuracy: 0.7305

 Epoch 19 / 20

Training Loss: 0.397
Validation Loss: 0.707
Validation Accuracy: 0.7295

 Epoch 20 / 20

Training Loss: 0.386
Validation Loss: 0.711
Validation Accuracy: 0.7325


         == flag 1.601 bert result On test data ==
# called_model : bert
# Test Accuracy: 0.7021%
Precision: 0.7036
Recall: 0.7021
F1 Score: 0.7022
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.67      0.70      3972
           1       0.70      0.72      0.71      5937
           2       0.66      0.71      0.68      2375

    accuracy                           0.70     12284
   macro avg       0.70      0.70      0.70     12284
weighted avg       0.70      0.70      0.70     12284

Confusion Matrix:
[[2667 1171  134]
 [ 927 4265  745]
 [  50  632 1693]]

flag 1.11  model:  finished  with:   bert





===================================================== 
flag 1.10  model:  started with ==>   roberta
===================================================== 

 Epoch 1 / 20

Training Loss: 0.933
Validation Loss: 0.720
Validation Accuracy: 0.6940

 Epoch 2 / 20

Training Loss: 0.686
Validation Loss: 0.665
Validation Accuracy: 0.7130

 Epoch 3 / 20

Training Loss: 0.634
Validation Loss: 0.638
Validation Accuracy: 0.7245

 Epoch 4 / 20

Training Loss: 0.604
Validation Loss: 0.619
Validation Accuracy: 0.7250

 Epoch 5 / 20

Training Loss: 0.580
Validation Loss: 0.621
Validation Accuracy: 0.7410

 Epoch 6 / 20

Training Loss: 0.566
Validation Loss: 0.614
Validation Accuracy: 0.7275

 Epoch 7 / 20

Training Loss: 0.553
Validation Loss: 0.614
Validation Accuracy: 0.7415

 Epoch 8 / 20

Training Loss: 0.541
Validation Loss: 0.608
Validation Accuracy: 0.7425

 Epoch 9 / 20

Training Loss: 0.526
Validation Loss: 0.611
Validation Accuracy: 0.7420

 Epoch 10 / 20

Training Loss: 0.516
Validation Loss: 0.623
Validation Accuracy: 0.7335

 Epoch 11 / 20

Training Loss: 0.505
Validation Loss: 0.619
Validation Accuracy: 0.7410

 Epoch 12 / 20

Training Loss: 0.494
Validation Loss: 0.638
Validation Accuracy: 0.7250

 Epoch 13 / 20

Training Loss: 0.482
Validation Loss: 0.661
Validation Accuracy: 0.7295

 Epoch 14 / 20

Training Loss: 0.471
Validation Loss: 0.629
Validation Accuracy: 0.7415

 Epoch 15 / 20

Training Loss: 0.459
Validation Loss: 0.643
Validation Accuracy: 0.7395

 Epoch 16 / 20

Training Loss: 0.451
Validation Loss: 0.663
Validation Accuracy: 0.7320

 Epoch 17 / 20

Training Loss: 0.438
Validation Loss: 0.660
Validation Accuracy: 0.7360

 Epoch 18 / 20

Training Loss: 0.429
Validation Loss: 0.665
Validation Accuracy: 0.7335

 Epoch 19 / 20

Training Loss: 0.417
Validation Loss: 0.657
Validation Accuracy: 0.7425

 Epoch 20 / 20

Training Loss: 0.405
Validation Loss: 0.685
Validation Accuracy: 0.7400


         == flag 1.601 roberta result On test data ==
# called_model : roberta
# Test Accuracy: 0.7193%
Precision: 0.7233
Recall: 0.7193
F1 Score: 0.7186
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.78      0.74      3972
           1       0.76      0.66      0.71      5937
           2       0.67      0.76      0.71      2375

    accuracy                           0.72     12284
   macro avg       0.71      0.73      0.72     12284
weighted avg       0.72      0.72      0.72     12284

Confusion Matrix:
[[3106  754  112]
 [1222 3926  789]
 [  59  512 1804]]

flag 1.11  model:  finished  with:   roberta





===================================================== 
flag 1.10  model:  started with ==>   distilbert
===================================================== 

 Epoch 1 / 20

Training Loss: 0.956
Validation Loss: 0.767
Validation Accuracy: 0.6575

 Epoch 2 / 20

Training Loss: 0.726
Validation Loss: 0.701
Validation Accuracy: 0.6865

 Epoch 3 / 20

Training Loss: 0.679
Validation Loss: 0.676
Validation Accuracy: 0.6975

 Epoch 4 / 20

Training Loss: 0.653
Validation Loss: 0.659
Validation Accuracy: 0.7085

 Epoch 5 / 20

Training Loss: 0.634
Validation Loss: 0.654
Validation Accuracy: 0.7070

 Epoch 6 / 20

Training Loss: 0.619
Validation Loss: 0.646
Validation Accuracy: 0.7120

 Epoch 7 / 20

Training Loss: 0.603
Validation Loss: 0.642
Validation Accuracy: 0.7175

 Epoch 8 / 20

Training Loss: 0.590
Validation Loss: 0.635
Validation Accuracy: 0.7215

 Epoch 9 / 20

Training Loss: 0.579
Validation Loss: 0.639
Validation Accuracy: 0.7240

 Epoch 10 / 20

Training Loss: 0.567
Validation Loss: 0.635
Validation Accuracy: 0.7290

 Epoch 11 / 20

Training Loss: 0.557
Validation Loss: 0.637
Validation Accuracy: 0.7205

 Epoch 12 / 20

Training Loss: 0.545
Validation Loss: 0.640
Validation Accuracy: 0.7225

 Epoch 13 / 20

Training Loss: 0.532
Validation Loss: 0.645
Validation Accuracy: 0.7230

 Epoch 14 / 20

Training Loss: 0.521
Validation Loss: 0.642
Validation Accuracy: 0.7310

 Epoch 15 / 20

Training Loss: 0.510
Validation Loss: 0.644
Validation Accuracy: 0.7310

 Epoch 16 / 20

Training Loss: 0.501
Validation Loss: 0.650
Validation Accuracy: 0.7280

 Epoch 17 / 20

Training Loss: 0.490
Validation Loss: 0.649
Validation Accuracy: 0.7310

 Epoch 18 / 20

Training Loss: 0.479
Validation Loss: 0.654
Validation Accuracy: 0.7360

 Epoch 19 / 20

Training Loss: 0.470
Validation Loss: 0.654
Validation Accuracy: 0.7330

 Epoch 20 / 20

Training Loss: 0.460
Validation Loss: 0.671
Validation Accuracy: 0.7265


         == flag 1.601 distilbert result On test data ==
# called_model : distilbert
# Test Accuracy: 0.6871%
Precision: 0.6895
Recall: 0.6871
F1 Score: 0.6871
Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.65      0.68      3972
           1       0.69      0.71      0.70      5937
           2       0.63      0.71      0.67      2375

    accuracy                           0.69     12284
   macro avg       0.68      0.69      0.68     12284
weighted avg       0.69      0.69      0.69     12284

Confusion Matrix:
[[2563 1241  168]
 [ 935 4191  811]
 [  57  632 1686]]

flag 1.11  model:  finished  with:   distilbert





===================================================== 
flag 1.10  model:  started with ==>   electra
===================================================== 

 Epoch 1 / 20

Training Loss: 0.949
Validation Loss: 0.725
Validation Accuracy: 0.6895

 Epoch 2 / 20

Training Loss: 0.699
Validation Loss: 0.665
Validation Accuracy: 0.7080

 Epoch 3 / 20

Training Loss: 0.639
Validation Loss: 0.644
Validation Accuracy: 0.7190

 Epoch 4 / 20

Training Loss: 0.608
Validation Loss: 0.635
Validation Accuracy: 0.7270

 Epoch 5 / 20

Training Loss: 0.585
Validation Loss: 0.629
Validation Accuracy: 0.7255

 Epoch 6 / 20

Training Loss: 0.567
Validation Loss: 0.631
Validation Accuracy: 0.7270

 Epoch 7 / 20

Training Loss: 0.553
Validation Loss: 0.638
Validation Accuracy: 0.7295

 Epoch 8 / 20

Training Loss: 0.538
Validation Loss: 0.622
Validation Accuracy: 0.7400

 Epoch 9 / 20

Training Loss: 0.529
Validation Loss: 0.627
Validation Accuracy: 0.7375

 Epoch 10 / 20

Training Loss: 0.512
Validation Loss: 0.630
Validation Accuracy: 0.7370

 Epoch 11 / 20

Training Loss: 0.502
Validation Loss: 0.627
Validation Accuracy: 0.7445

 Epoch 12 / 20

Training Loss: 0.489
Validation Loss: 0.645
Validation Accuracy: 0.7400

 Epoch 13 / 20

Training Loss: 0.480
Validation Loss: 0.641
Validation Accuracy: 0.7405

 Epoch 14 / 20

Training Loss: 0.469
Validation Loss: 0.657
Validation Accuracy: 0.7300

 Epoch 15 / 20

Training Loss: 0.458
Validation Loss: 0.659
Validation Accuracy: 0.7385

 Epoch 16 / 20

Training Loss: 0.447
Validation Loss: 0.655
Validation Accuracy: 0.7435

 Epoch 17 / 20

Training Loss: 0.435
Validation Loss: 0.666
Validation Accuracy: 0.7355

 Epoch 18 / 20

Training Loss: 0.425
Validation Loss: 0.673
Validation Accuracy: 0.7285

 Epoch 19 / 20

Training Loss: 0.413
Validation Loss: 0.686
Validation Accuracy: 0.7345

 Epoch 20 / 20

Training Loss: 0.404
Validation Loss: 0.696
Validation Accuracy: 0.7360


         == flag 1.601 electra result On test data ==
# called_model : electra
# Test Accuracy: 0.7171%
Precision: 0.7198
Recall: 0.7171
F1 Score: 0.7163
Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.79      0.75      3972
           1       0.75      0.67      0.70      5937
           2       0.67      0.72      0.70      2375

    accuracy                           0.72     12284
   macro avg       0.71      0.73      0.72     12284
weighted avg       0.72      0.72      0.72     12284

Confusion Matrix:
[[3139  734   99]
 [1257 3950  730]
 [  58  597 1720]]

flag 1.11  model:  finished  with:   electra





===================================================== 
flag 1.10  model:  started with ==>   gpt2
===================================================== 

 Epoch 1 / 20

Training Loss: 1.113
Validation Loss: 0.933
Validation Accuracy: 0.5445

 Epoch 2 / 20

Training Loss: 0.859
Validation Loss: 0.728
Validation Accuracy: 0.6670

 Epoch 3 / 20

Training Loss: 0.735
Validation Loss: 0.686
Validation Accuracy: 0.6900

 Epoch 4 / 20

Training Loss: 0.698
Validation Loss: 0.668
Validation Accuracy: 0.7025

 Epoch 5 / 20

Training Loss: 0.677
Validation Loss: 0.659
Validation Accuracy: 0.7065

 Epoch 6 / 20

Training Loss: 0.657
Validation Loss: 0.659
Validation Accuracy: 0.7080

 Epoch 7 / 20

Training Loss: 0.647
Validation Loss: 0.646
Validation Accuracy: 0.7145

 Epoch 8 / 20

Training Loss: 0.638
Validation Loss: 0.653
Validation Accuracy: 0.7125

 Epoch 9 / 20

Training Loss: 0.632
Validation Loss: 0.646
Validation Accuracy: 0.7190

 Epoch 10 / 20

Training Loss: 0.622
Validation Loss: 0.635
Validation Accuracy: 0.7245

 Epoch 11 / 20

Training Loss: 0.614
Validation Loss: 0.630
Validation Accuracy: 0.7235

 Epoch 12 / 20

Training Loss: 0.607
Validation Loss: 0.631
Validation Accuracy: 0.7265

 Epoch 13 / 20

Training Loss: 0.601
Validation Loss: 0.634
Validation Accuracy: 0.7255

 Epoch 14 / 20

Training Loss: 0.593
Validation Loss: 0.631
Validation Accuracy: 0.7275

 Epoch 15 / 20

Training Loss: 0.587
Validation Loss: 0.627
Validation Accuracy: 0.7280

 Epoch 16 / 20

Training Loss: 0.582
Validation Loss: 0.638
Validation Accuracy: 0.7205

 Epoch 17 / 20

Training Loss: 0.578
Validation Loss: 0.633
Validation Accuracy: 0.7215

 Epoch 18 / 20

Training Loss: 0.571
Validation Loss: 0.625
Validation Accuracy: 0.7285

 Epoch 19 / 20

Training Loss: 0.563
Validation Loss: 0.630
Validation Accuracy: 0.7245

 Epoch 20 / 20

Training Loss: 0.561
Validation Loss: 0.622
Validation Accuracy: 0.7295


         == flag 1.601 gpt2 result On test data ==
# called_model : gpt2
# Test Accuracy: 0.7092%
Precision: 0.7122
Recall: 0.7092
F1 Score: 0.7090
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.75      0.73      3972
           1       0.74      0.67      0.70      5937
           2       0.65      0.74      0.69      2375

    accuracy                           0.71     12284
   macro avg       0.70      0.72      0.71     12284
weighted avg       0.71      0.71      0.71     12284

Confusion Matrix:
[[2986  867  119]
 [1151 3957  829]
 [  69  537 1769]]

flag 1.11  model:  finished  with:   gpt2





===================================================== 
flag 1.10  model:  started with ==>   longformer
===================================================== 

 Epoch 1 / 20

Training Loss: 0.854
Validation Loss: 0.676
Validation Accuracy: 0.7055

 Epoch 2 / 20

Training Loss: 0.654
Validation Loss: 0.639
Validation Accuracy: 0.7215

 Epoch 3 / 20

Training Loss: 0.619
Validation Loss: 0.634
Validation Accuracy: 0.7250

 Epoch 4 / 20

Training Loss: 0.595
Validation Loss: 0.627
Validation Accuracy: 0.7295

 Epoch 5 / 20

Training Loss: 0.578
Validation Loss: 0.607
Validation Accuracy: 0.7215

 Epoch 6 / 20

Training Loss: 0.563
Validation Loss: 0.621
Validation Accuracy: 0.7270

 Epoch 7 / 20

Training Loss: 0.550
Validation Loss: 0.615
Validation Accuracy: 0.7240

 Epoch 8 / 20

Training Loss: 0.539
Validation Loss: 0.618
Validation Accuracy: 0.7270

 Epoch 9 / 20

Training Loss: 0.528
Validation Loss: 0.625
Validation Accuracy: 0.7250

 Epoch 10 / 20

Training Loss: 0.516
Validation Loss: 0.624
Validation Accuracy: 0.7320

 Epoch 11 / 20

Training Loss: 0.503
Validation Loss: 0.615
Validation Accuracy: 0.7340

 Epoch 12 / 20

Training Loss: 0.492
Validation Loss: 0.618
Validation Accuracy: 0.7355

 Epoch 13 / 20

Training Loss: 0.482
Validation Loss: 0.633
Validation Accuracy: 0.7300

 Epoch 14 / 20

Training Loss: 0.470
Validation Loss: 0.632
Validation Accuracy: 0.7350

 Epoch 15 / 20

Training Loss: 0.460
Validation Loss: 0.647
Validation Accuracy: 0.7260

 Epoch 16 / 20

Training Loss: 0.447
Validation Loss: 0.648
Validation Accuracy: 0.7405

 Epoch 17 / 20

Training Loss: 0.436
Validation Loss: 0.658
Validation Accuracy: 0.7365

 Epoch 18 / 20

Training Loss: 0.428
Validation Loss: 0.658
Validation Accuracy: 0.7350

 Epoch 19 / 20

Training Loss: 0.419
Validation Loss: 0.692
Validation Accuracy: 0.7215

 Epoch 20 / 20

Training Loss: 0.404
Validation Loss: 0.692
Validation Accuracy: 0.7220


         == flag 1.601 longformer result On test data ==
# called_model : longformer
# Test Accuracy: 0.7178%
Precision: 0.7214
Recall: 0.7178
F1 Score: 0.7171
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.78      0.74      3972
           1       0.75      0.66      0.70      5937
           2       0.67      0.76      0.71      2375

    accuracy                           0.72     12284
   macro avg       0.71      0.73      0.72     12284
weighted avg       0.72      0.72      0.72     12284

Confusion Matrix:
[[3083  776  113]
 [1226 3932  779]
 [  57  516 1802]]

flag 1.11  model:  finished  with:   longformer





===================================================== 
flag 1.10  model:  started with ==>   luke
===================================================== 

 Epoch 1 / 20

Training Loss: 0.848
Validation Loss: 0.696
Validation Accuracy: 0.6920

 Epoch 2 / 20

Training Loss: 0.650
Validation Loss: 0.646
Validation Accuracy: 0.7185

 Epoch 3 / 20

Training Loss: 0.615
Validation Loss: 0.636
Validation Accuracy: 0.7220

 Epoch 4 / 20

Training Loss: 0.592
Validation Loss: 0.633
Validation Accuracy: 0.7200

 Epoch 5 / 20

Training Loss: 0.574
Validation Loss: 0.620
Validation Accuracy: 0.7330

 Epoch 6 / 20

Training Loss: 0.560
Validation Loss: 0.620
Validation Accuracy: 0.7310

 Epoch 7 / 20

Training Loss: 0.548
Validation Loss: 0.625
Validation Accuracy: 0.7340

 Epoch 8 / 20

Training Loss: 0.536
Validation Loss: 0.621
Validation Accuracy: 0.7355

 Epoch 9 / 20

Training Loss: 0.525
Validation Loss: 0.630
Validation Accuracy: 0.7255

 Epoch 10 / 20

Training Loss: 0.511
Validation Loss: 0.631
Validation Accuracy: 0.7295

 Epoch 11 / 20

Training Loss: 0.500
Validation Loss: 0.639
Validation Accuracy: 0.7345

 Epoch 12 / 20

Training Loss: 0.489
Validation Loss: 0.639
Validation Accuracy: 0.7375

 Epoch 13 / 20

Training Loss: 0.477
Validation Loss: 0.661
Validation Accuracy: 0.7375

 Epoch 14 / 20

Training Loss: 0.467
Validation Loss: 0.666
Validation Accuracy: 0.7345

 Epoch 15 / 20

Training Loss: 0.453
Validation Loss: 0.679
Validation Accuracy: 0.7305

 Epoch 16 / 20

Training Loss: 0.444
Validation Loss: 0.690
Validation Accuracy: 0.7245

 Epoch 17 / 20

Training Loss: 0.432
Validation Loss: 0.679
Validation Accuracy: 0.7350

 Epoch 18 / 20

Training Loss: 0.420
Validation Loss: 0.693
Validation Accuracy: 0.7340

 Epoch 19 / 20

Training Loss: 0.407
Validation Loss: 0.693
Validation Accuracy: 0.7315

 Epoch 20 / 20

Training Loss: 0.395
Validation Loss: 0.721
Validation Accuracy: 0.7225


         == flag 1.601 luke result On test data ==
# called_model : luke
# Test Accuracy: 0.7085%
Precision: 0.7136
Recall: 0.7085
F1 Score: 0.7074
Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.78      0.73      3972
           1       0.75      0.64      0.69      5937
           2       0.66      0.75      0.70      2375

    accuracy                           0.71     12284
   macro avg       0.70      0.73      0.71     12284
weighted avg       0.71      0.71      0.71     12284

Confusion Matrix:
[[3112  735  125]
 [1335 3806  796]
 [  63  527 1785]]

flag 1.11  model:  finished  with:   luke





===================================================== 
flag 1.10  model:  started with ==>   t5
===================================================== 

 Epoch 1 / 20

Training Loss: 1.228
Validation Loss: 1.081
Validation Accuracy: 0.4340

 Epoch 2 / 20

Training Loss: 1.077
Validation Loss: 1.040
Validation Accuracy: 0.4345

 Epoch 3 / 20

Training Loss: 1.047
Validation Loss: 1.029
Validation Accuracy: 0.4345

 Epoch 4 / 20

Training Loss: 1.034
Validation Loss: 1.021
Validation Accuracy: 0.4345

 Epoch 5 / 20

Training Loss: 1.027
Validation Loss: 1.012
Validation Accuracy: 0.4730

 Epoch 6 / 20

Training Loss: 1.014
Validation Loss: 0.990
Validation Accuracy: 0.5430

 Epoch 7 / 20

Training Loss: 0.985
Validation Loss: 0.929
Validation Accuracy: 0.6020

 Epoch 8 / 20

Training Loss: 0.927
Validation Loss: 0.841
Validation Accuracy: 0.6235

 Epoch 9 / 20

Training Loss: 0.851
Validation Loss: 0.762
Validation Accuracy: 0.6565

 Epoch 10 / 20

Training Loss: 0.781
Validation Loss: 0.712
Validation Accuracy: 0.6875

 Epoch 11 / 20

Training Loss: 0.734
Validation Loss: 0.689
Validation Accuracy: 0.6950

 Epoch 12 / 20

Training Loss: 0.707
Validation Loss: 0.680
Validation Accuracy: 0.6955

 Epoch 13 / 20

Training Loss: 0.689
Validation Loss: 0.679
Validation Accuracy: 0.6920

 Epoch 14 / 20

Training Loss: 0.677
Validation Loss: 0.678
Validation Accuracy: 0.6910

 Epoch 15 / 20

Training Loss: 0.670
Validation Loss: 0.677
Validation Accuracy: 0.6915

 Epoch 16 / 20

Training Loss: 0.663
Validation Loss: 0.673
Validation Accuracy: 0.6925

 Epoch 17 / 20

Training Loss: 0.657
Validation Loss: 0.670
Validation Accuracy: 0.6950

 Epoch 18 / 20

Training Loss: 0.650
Validation Loss: 0.668
Validation Accuracy: 0.6955

 Epoch 19 / 20

Training Loss: 0.648
Validation Loss: 0.665
Validation Accuracy: 0.7020

 Epoch 20 / 20

Training Loss: 0.643
Validation Loss: 0.662
Validation Accuracy: 0.7040


         == flag 1.601 t5 result On test data ==
# called_model : t5
# Test Accuracy: 0.7000%
Precision: 0.7042
Recall: 0.7000
F1 Score: 0.6994
Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.77      0.72      3972
           1       0.74      0.65      0.69      5937
           2       0.65      0.72      0.68      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.71      0.70     12284
weighted avg       0.70      0.70      0.70     12284

Confusion Matrix:
[[3065  754  153]
 [1350 3834  753]
 [  86  589 1700]]

flag 1.11  model:  finished  with:   t5





===================================================== 
flag 1.10  model:  started with ==>   xlnet
===================================================== 

 Epoch 1 / 20

Training Loss: 0.861
Validation Loss: 0.691
Validation Accuracy: 0.6845

 Epoch 2 / 20

Training Loss: 0.696
Validation Loss: 0.672
Validation Accuracy: 0.7120

 Epoch 3 / 20

Training Loss: 0.658
Validation Loss: 0.642
Validation Accuracy: 0.7325

 Epoch 4 / 20

Training Loss: 0.633
Validation Loss: 0.636
Validation Accuracy: 0.7380

 Epoch 5 / 20

Training Loss: 0.613
Validation Loss: 0.623
Validation Accuracy: 0.7410

 Epoch 6 / 20

Training Loss: 0.597
Validation Loss: 0.637
Validation Accuracy: 0.7310

 Epoch 7 / 20

Training Loss: 0.582
Validation Loss: 0.625
Validation Accuracy: 0.7330

 Epoch 8 / 20

Training Loss: 0.565
Validation Loss: 0.625
Validation Accuracy: 0.7310

 Epoch 9 / 20

Training Loss: 0.554
Validation Loss: 0.630
Validation Accuracy: 0.7290

 Epoch 10 / 20

Training Loss: 0.543
Validation Loss: 0.621
Validation Accuracy: 0.7315

 Epoch 11 / 20

Training Loss: 0.530
Validation Loss: 0.621
Validation Accuracy: 0.7275

 Epoch 12 / 20

Training Loss: 0.517
Validation Loss: 0.633
Validation Accuracy: 0.7335

 Epoch 13 / 20

Training Loss: 0.505
Validation Loss: 0.633
Validation Accuracy: 0.7325

 Epoch 14 / 20

Training Loss: 0.494
Validation Loss: 0.649
Validation Accuracy: 0.7230

 Epoch 15 / 20

Training Loss: 0.483
Validation Loss: 0.655
Validation Accuracy: 0.7350

 Epoch 16 / 20

Training Loss: 0.472
Validation Loss: 0.669
Validation Accuracy: 0.7340

 Epoch 17 / 20

Training Loss: 0.461
Validation Loss: 0.661
Validation Accuracy: 0.7380

 Epoch 18 / 20

Training Loss: 0.448
Validation Loss: 0.669
Validation Accuracy: 0.7295

 Epoch 19 / 20

Training Loss: 0.441
Validation Loss: 0.679
Validation Accuracy: 0.7295

 Epoch 20 / 20

Training Loss: 0.428
Validation Loss: 0.690
Validation Accuracy: 0.7350


         == flag 1.601 xlnet result On test data ==
# called_model : xlnet
# Test Accuracy: 0.7025%
Precision: 0.7079
Recall: 0.7025
F1 Score: 0.7022
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.74      0.73      3972
           1       0.74      0.65      0.69      5937
           2       0.63      0.77      0.69      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.72      0.70     12284
weighted avg       0.71      0.70      0.70     12284

Confusion Matrix:
[[2956  853  163]
 [1162 3856  919]
 [  61  497 1817]]

flag 1.11  model:  finished  with:   xlnet

Execution Finished
