learning rate  : 1e-05
epochs : 20
                                                text  label
0  "QT @user In the original draft of the 7th boo...      2
1  "Ben Smith / Smith (concussion) remains out of...      1
2  Sorry bout the stream last night I crashed out...      1
3  Chase Headley's RBI double in the 8th inning o...      1
4  @user Alciato: Bee will invest 150 million in ...      2
                                                text
0  "QT @user In the original draft of the 7th boo...
1  "Ben Smith / Smith (concussion) remains out of...
2  Sorry bout the stream last night I crashed out...
3  Chase Headley's RBI double in the 8th inning o...
4  @user Alciato: Bee will invest 150 million in ...
   label
0      2
1      1
2      1
3      1
4      2
                                                text  label
0  Dark Souls 3 April Launch Date Confirmed With ...      1
1  "National hot dog day, national tequila day, t...      2
2  When girls become bandwagon fans of the Packer...      0
3  @user I may or may not have searched it up on ...      1
4  Here's your starting TUESDAY MORNING Line up a...      1
                                                text
0  Dark Souls 3 April Launch Date Confirmed With ...
1  "National hot dog day, national tequila day, t...
2  When girls become bandwagon fans of the Packer...
3  @user I may or may not have searched it up on ...
4  Here's your starting TUESDAY MORNING Line up a...
   label
0      1
1      2
2      0
3      1
4      1
                                                text  label
0  @user @user what do these '1/2 naked pics' hav...      1
1  OH: “I had a blue penis while I was this” [pla...      1
2  @user @user That's coming, but I think the vic...      1
3  I think I may be finally in with the in crowd ...      2
4  @user Wow,first Hugo Chavez and now Fidel Cast...      0
                                                text
0  @user @user what do these '1/2 naked pics' hav...
1  OH: “I had a blue penis while I was this” [pla...
2  @user @user That's coming, but I think the vic...
3  I think I may be finally in with the in crowd ...
4  @user Wow,first Hugo Chavez and now Fidel Cast...
                                                text
0  @user @user what do these '1/2 naked pics' hav...
1  OH: “I had a blue penis while I was this” [pla...
2  @user @user That's coming, but I think the vic...
3  I think I may be finally in with the in crowd ...
4  @user Wow,first Hugo Chavez and now Fidel Cast...
len(train_labels) 45615
len(test_labels) 12284
len(val_labels) 2000

Unique values count in train_labels:
label
1    20673
2    17849
0     7093
Name: count, dtype: int64

Unique values count in val_labels:
label
1    869
2    819
0    312
Name: count, dtype: int64

Unique values count in test_labels:
label
1    5937
0    3972
2    2375
Name: count, dtype: int64





===================================================== 
flag 1.10  model:  started with ==>   bert
===================================================== 

 Epoch 1 / 20

Training Loss: 0.703
Validation Loss: 0.614
Validation Accuracy: 0.7360

 Epoch 2 / 20

Training Loss: 0.541
Validation Loss: 0.617
Validation Accuracy: 0.7335

 Epoch 3 / 20

Training Loss: 0.432
Validation Loss: 0.630
Validation Accuracy: 0.7485

 Epoch 4 / 20

Training Loss: 0.324
Validation Loss: 0.754
Validation Accuracy: 0.7350

 Epoch 5 / 20

Training Loss: 0.236
Validation Loss: 0.869
Validation Accuracy: 0.7325

 Epoch 6 / 20

Training Loss: 0.176
Validation Loss: 1.007
Validation Accuracy: 0.7280

 Epoch 7 / 20

Training Loss: 0.139
Validation Loss: 1.141
Validation Accuracy: 0.7260

 Epoch 8 / 20

Training Loss: 0.115
Validation Loss: 1.291
Validation Accuracy: 0.7265

 Epoch 9 / 20

Training Loss: 0.099
Validation Loss: 1.381
Validation Accuracy: 0.7220

 Epoch 10 / 20

Training Loss: 0.088
Validation Loss: 1.432
Validation Accuracy: 0.7295

 Epoch 11 / 20

Training Loss: 0.078
Validation Loss: 1.743
Validation Accuracy: 0.7180

 Epoch 12 / 20

Training Loss: 0.070
Validation Loss: 1.638
Validation Accuracy: 0.7280

 Epoch 13 / 20

Training Loss: 0.063
Validation Loss: 1.794
Validation Accuracy: 0.7160

 Epoch 14 / 20

Training Loss: 0.060
Validation Loss: 1.917
Validation Accuracy: 0.7240

 Epoch 15 / 20

Training Loss: 0.053
Validation Loss: 1.921
Validation Accuracy: 0.7250

 Epoch 16 / 20

Training Loss: 0.052
Validation Loss: 1.875
Validation Accuracy: 0.7285

 Epoch 17 / 20

Training Loss: 0.044
Validation Loss: 1.863
Validation Accuracy: 0.7180

 Epoch 18 / 20

Training Loss: 0.039
Validation Loss: 1.956
Validation Accuracy: 0.7170

 Epoch 19 / 20

Training Loss: 0.039
Validation Loss: 2.099
Validation Accuracy: 0.7155

 Epoch 20 / 20

Training Loss: 0.036
Validation Loss: 2.088
Validation Accuracy: 0.7175


         == flag 1.601 bert result On test data ==
# called_model : bert
# Test Accuracy: 0.7012%
Precision: 0.7047
Recall: 0.7012
F1 Score: 0.7015
Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.67      0.70      3972
           1       0.71      0.71      0.71      5937
           2       0.63      0.74      0.68      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.71      0.70     12284
weighted avg       0.70      0.70      0.70     12284

Confusion Matrix:
[[2645 1158  169]
 [ 875 4207  855]
 [  60  554 1761]]

flag 1.11  model:  finished  with:   bert





===================================================== 
flag 1.10  model:  started with ==>   roberta
===================================================== 

 Epoch 1 / 20

Training Loss: 0.684
Validation Loss: 0.597
Validation Accuracy: 0.7455

 Epoch 2 / 20

Training Loss: 0.547
Validation Loss: 0.597
Validation Accuracy: 0.7440

 Epoch 3 / 20

Training Loss: 0.475
Validation Loss: 0.645
Validation Accuracy: 0.7300

 Epoch 4 / 20

Training Loss: 0.399
Validation Loss: 0.647
Validation Accuracy: 0.7415

 Epoch 5 / 20

Training Loss: 0.329
Validation Loss: 0.730
Validation Accuracy: 0.7330

 Epoch 6 / 20

Training Loss: 0.269
Validation Loss: 0.839
Validation Accuracy: 0.7295

 Epoch 7 / 20

Training Loss: 0.219
Validation Loss: 0.882
Validation Accuracy: 0.7390

 Epoch 8 / 20

Training Loss: 0.181
Validation Loss: 0.971
Validation Accuracy: 0.7255

 Epoch 9 / 20

Training Loss: 0.151
Validation Loss: 1.081
Validation Accuracy: 0.7250

 Epoch 10 / 20

Training Loss: 0.131
Validation Loss: 1.287
Validation Accuracy: 0.7295

 Epoch 11 / 20

Training Loss: 0.121
Validation Loss: 1.242
Validation Accuracy: 0.7255

 Epoch 12 / 20

Training Loss: 0.112
Validation Loss: 1.284
Validation Accuracy: 0.7265

 Epoch 13 / 20

Training Loss: 0.103
Validation Loss: 1.355
Validation Accuracy: 0.7230

 Epoch 14 / 20

Training Loss: 0.096
Validation Loss: 1.645
Validation Accuracy: 0.7255

 Epoch 15 / 20

Training Loss: 0.095
Validation Loss: 1.494
Validation Accuracy: 0.7375

 Epoch 16 / 20

Training Loss: 0.090
Validation Loss: 1.683
Validation Accuracy: 0.7215

 Epoch 17 / 20

Training Loss: 0.082
Validation Loss: 1.792
Validation Accuracy: 0.7245

 Epoch 18 / 20

Training Loss: 0.075
Validation Loss: 1.889
Validation Accuracy: 0.7170

 Epoch 19 / 20

Training Loss: 0.071
Validation Loss: 1.992
Validation Accuracy: 0.7290

 Epoch 20 / 20

Training Loss: 0.071
Validation Loss: 1.910
Validation Accuracy: 0.7270


         == flag 1.601 roberta result On test data ==
# called_model : roberta
# Test Accuracy: 0.7161%
Precision: 0.7191
Recall: 0.7161
F1 Score: 0.7165
Classification Report:
              precision    recall  f1-score   support

           0       0.75      0.70      0.72      3972
           1       0.73      0.72      0.72      5937
           2       0.65      0.75      0.70      2375

    accuracy                           0.72     12284
   macro avg       0.71      0.72      0.71     12284
weighted avg       0.72      0.72      0.72     12284

Confusion Matrix:
[[2764 1047  161]
 [ 886 4246  805]
 [  36  552 1787]]

flag 1.11  model:  finished  with:   roberta





===================================================== 
flag 1.10  model:  started with ==>   distilbert
===================================================== 

 Epoch 1 / 20

Training Loss: 0.713
Validation Loss: 0.636
Validation Accuracy: 0.7260

 Epoch 2 / 20

Training Loss: 0.574
Validation Loss: 0.614
Validation Accuracy: 0.7350

 Epoch 3 / 20

Training Loss: 0.492
Validation Loss: 0.632
Validation Accuracy: 0.7380

 Epoch 4 / 20

Training Loss: 0.403
Validation Loss: 0.715
Validation Accuracy: 0.7210

 Epoch 5 / 20

Training Loss: 0.323
Validation Loss: 0.723
Validation Accuracy: 0.7380

 Epoch 6 / 20

Training Loss: 0.245
Validation Loss: 0.880
Validation Accuracy: 0.7240

 Epoch 7 / 20

Training Loss: 0.194
Validation Loss: 0.948
Validation Accuracy: 0.7225

 Epoch 8 / 20

Training Loss: 0.153
Validation Loss: 1.072
Validation Accuracy: 0.7200

 Epoch 9 / 20

Training Loss: 0.123
Validation Loss: 1.244
Validation Accuracy: 0.7085

 Epoch 10 / 20

Training Loss: 0.104
Validation Loss: 1.313
Validation Accuracy: 0.7160

 Epoch 11 / 20

Training Loss: 0.094
Validation Loss: 1.496
Validation Accuracy: 0.7165

 Epoch 12 / 20

Training Loss: 0.083
Validation Loss: 1.606
Validation Accuracy: 0.7125

 Epoch 13 / 20

Training Loss: 0.077
Validation Loss: 1.715
Validation Accuracy: 0.7130

 Epoch 14 / 20

Training Loss: 0.068
Validation Loss: 1.674
Validation Accuracy: 0.7095

 Epoch 15 / 20

Training Loss: 0.059
Validation Loss: 1.900
Validation Accuracy: 0.7215

 Epoch 16 / 20

Training Loss: 0.058
Validation Loss: 1.896
Validation Accuracy: 0.7195

 Epoch 17 / 20

Training Loss: 0.051
Validation Loss: 1.932
Validation Accuracy: 0.7135

 Epoch 18 / 20

Training Loss: 0.048
Validation Loss: 2.011
Validation Accuracy: 0.7105

 Epoch 19 / 20

Training Loss: 0.046
Validation Loss: 2.057
Validation Accuracy: 0.7145

 Epoch 20 / 20

Training Loss: 0.039
Validation Loss: 2.142
Validation Accuracy: 0.7245


         == flag 1.601 distilbert result On test data ==
# called_model : distilbert
# Test Accuracy: 0.6907%
Precision: 0.6934
Recall: 0.6907
F1 Score: 0.6910
Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.66      0.69      3972
           1       0.70      0.70      0.70      5937
           2       0.63      0.72      0.67      2375

    accuracy                           0.69     12284
   macro avg       0.68      0.69      0.69     12284
weighted avg       0.69      0.69      0.69     12284

Confusion Matrix:
[[2630 1153  189]
 [ 960 4142  835]
 [  63  599 1713]]

flag 1.11  model:  finished  with:   distilbert





===================================================== 
flag 1.10  model:  started with ==>   electra
===================================================== 

 Epoch 1 / 20

Training Loss: 0.683
Validation Loss: 0.631
Validation Accuracy: 0.7220

 Epoch 2 / 20

Training Loss: 0.531
Validation Loss: 0.635
Validation Accuracy: 0.7375

 Epoch 3 / 20

Training Loss: 0.451
Validation Loss: 0.646
Validation Accuracy: 0.7335

 Epoch 4 / 20

Training Loss: 0.372
Validation Loss: 0.719
Validation Accuracy: 0.7400

 Epoch 5 / 20

Training Loss: 0.300
Validation Loss: 0.849
Validation Accuracy: 0.7320

 Epoch 6 / 20

Training Loss: 0.236
Validation Loss: 0.888
Validation Accuracy: 0.7430

 Epoch 7 / 20

Training Loss: 0.192
Validation Loss: 1.034
Validation Accuracy: 0.7305

 Epoch 8 / 20

Training Loss: 0.158
Validation Loss: 1.109
Validation Accuracy: 0.7170

 Epoch 9 / 20

Training Loss: 0.135
Validation Loss: 1.189
Validation Accuracy: 0.7290

 Epoch 10 / 20

Training Loss: 0.118
Validation Loss: 1.303
Validation Accuracy: 0.7200

 Epoch 11 / 20

Training Loss: 0.104
Validation Loss: 1.371
Validation Accuracy: 0.7110

 Epoch 12 / 20

Training Loss: 0.092
Validation Loss: 1.429
Validation Accuracy: 0.7210

 Epoch 13 / 20

Training Loss: 0.086
Validation Loss: 1.664
Validation Accuracy: 0.7130

 Epoch 14 / 20

Training Loss: 0.081
Validation Loss: 1.516
Validation Accuracy: 0.7235

 Epoch 15 / 20

Training Loss: 0.074
Validation Loss: 1.700
Validation Accuracy: 0.7270

 Epoch 16 / 20

Training Loss: 0.068
Validation Loss: 1.825
Validation Accuracy: 0.7210

 Epoch 17 / 20

Training Loss: 0.062
Validation Loss: 1.880
Validation Accuracy: 0.7140

 Epoch 18 / 20

Training Loss: 0.060
Validation Loss: 1.781
Validation Accuracy: 0.7210

 Epoch 19 / 20

Training Loss: 0.054
Validation Loss: 1.927
Validation Accuracy: 0.7275

 Epoch 20 / 20

Training Loss: 0.051
Validation Loss: 2.049
Validation Accuracy: 0.7200


         == flag 1.601 electra result On test data ==
# called_model : electra
# Test Accuracy: 0.7060%
Precision: 0.7202
Recall: 0.7060
F1 Score: 0.7025
Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.85      0.75      3972
           1       0.78      0.59      0.67      5937
           2       0.64      0.76      0.69      2375

    accuracy                           0.71     12284
   macro avg       0.70      0.73      0.71     12284
weighted avg       0.72      0.71      0.70     12284

Confusion Matrix:
[[3362  471  139]
 [1537 3505  895]
 [  69  500 1806]]

flag 1.11  model:  finished  with:   electra





===================================================== 
flag 1.10  model:  started with ==>   gpt2
===================================================== 

 Epoch 1 / 20

Training Loss: 0.776
Validation Loss: 0.649
Validation Accuracy: 0.7085

 Epoch 2 / 20

Training Loss: 0.624
Validation Loss: 0.621
Validation Accuracy: 0.7365

 Epoch 3 / 20

Training Loss: 0.574
Validation Loss: 0.623
Validation Accuracy: 0.7310

 Epoch 4 / 20

Training Loss: 0.532
Validation Loss: 0.615
Validation Accuracy: 0.7320

 Epoch 5 / 20

Training Loss: 0.488
Validation Loss: 0.634
Validation Accuracy: 0.7380

 Epoch 6 / 20

Training Loss: 0.449
Validation Loss: 0.691
Validation Accuracy: 0.7225

 Epoch 7 / 20

Training Loss: 0.407
Validation Loss: 0.689
Validation Accuracy: 0.7290

 Epoch 8 / 20

Training Loss: 0.370
Validation Loss: 0.762
Validation Accuracy: 0.7210

 Epoch 9 / 20

Training Loss: 0.330
Validation Loss: 0.797
Validation Accuracy: 0.7360

 Epoch 10 / 20

Training Loss: 0.293
Validation Loss: 0.872
Validation Accuracy: 0.7115

 Epoch 11 / 20

Training Loss: 0.264
Validation Loss: 0.969
Validation Accuracy: 0.7215

 Epoch 12 / 20

Training Loss: 0.231
Validation Loss: 0.979
Validation Accuracy: 0.7280

 Epoch 13 / 20

Training Loss: 0.202
Validation Loss: 1.094
Validation Accuracy: 0.7190

 Epoch 14 / 20

Training Loss: 0.181
Validation Loss: 1.110
Validation Accuracy: 0.7235

 Epoch 15 / 20

Training Loss: 0.160
Validation Loss: 1.146
Validation Accuracy: 0.7215

 Epoch 16 / 20

Training Loss: 0.142
Validation Loss: 1.331
Validation Accuracy: 0.7155

 Epoch 17 / 20

Training Loss: 0.130
Validation Loss: 1.387
Validation Accuracy: 0.7215

 Epoch 18 / 20

Training Loss: 0.116
Validation Loss: 1.536
Validation Accuracy: 0.7125

 Epoch 19 / 20

Training Loss: 0.107
Validation Loss: 1.570
Validation Accuracy: 0.7220

 Epoch 20 / 20

Training Loss: 0.097
Validation Loss: 1.668
Validation Accuracy: 0.7150


         == flag 1.601 gpt2 result On test data ==
# called_model : gpt2
# Test Accuracy: 0.7060%
Precision: 0.7071
Recall: 0.7060
F1 Score: 0.7056
Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.76      0.72      3972
           1       0.73      0.68      0.70      5937
           2       0.68      0.70      0.69      2375

    accuracy                           0.71     12284
   macro avg       0.70      0.71      0.70     12284
weighted avg       0.71      0.71      0.71     12284

Confusion Matrix:
[[3006  883   83]
 [1242 4013  682]
 [  87  635 1653]]

flag 1.11  model:  finished  with:   gpt2





===================================================== 
flag 1.10  model:  started with ==>   longformer
===================================================== 

 Epoch 1 / 20

Training Loss: 0.680
Validation Loss: 0.617
Validation Accuracy: 0.7200

 Epoch 2 / 20

Training Loss: 0.555
Validation Loss: 0.603
Validation Accuracy: 0.7380

 Epoch 3 / 20

Training Loss: 0.481
Validation Loss: 0.632
Validation Accuracy: 0.7400

 Epoch 4 / 20

Training Loss: 0.410
Validation Loss: 0.702
Validation Accuracy: 0.7300

 Epoch 5 / 20

Training Loss: 0.341
Validation Loss: 0.754
Validation Accuracy: 0.7260

 Epoch 6 / 20

Training Loss: 0.279
Validation Loss: 0.833
Validation Accuracy: 0.7325

 Epoch 7 / 20

Training Loss: 0.225
Validation Loss: 0.959
Validation Accuracy: 0.7180

 Epoch 8 / 20

Training Loss: 0.191
Validation Loss: 0.949
Validation Accuracy: 0.7235

 Epoch 9 / 20

Training Loss: 0.158
Validation Loss: 1.133
Validation Accuracy: 0.7315

 Epoch 10 / 20

Training Loss: 0.134
Validation Loss: 1.260
Validation Accuracy: 0.7215

 Epoch 11 / 20

Training Loss: 0.126
Validation Loss: 1.268
Validation Accuracy: 0.7270

 Epoch 12 / 20

Training Loss: 0.112
Validation Loss: 1.376
Validation Accuracy: 0.7190

 Epoch 13 / 20

Training Loss: 0.103
Validation Loss: 1.476
Validation Accuracy: 0.7180

 Epoch 14 / 20

Training Loss: 0.099
Validation Loss: 1.663
Validation Accuracy: 0.7175

 Epoch 15 / 20

Training Loss: 0.091
Validation Loss: 1.641
Validation Accuracy: 0.7230

 Epoch 16 / 20

Training Loss: 0.087
Validation Loss: 1.789
Validation Accuracy: 0.7215

 Epoch 17 / 20

Training Loss: 0.078
Validation Loss: 1.820
Validation Accuracy: 0.7210

 Epoch 18 / 20

Training Loss: 0.080
Validation Loss: 1.809
Validation Accuracy: 0.7215

 Epoch 19 / 20

Training Loss: 0.074
Validation Loss: 2.025
Validation Accuracy: 0.7205

 Epoch 20 / 20

Training Loss: 0.070
Validation Loss: 2.051
Validation Accuracy: 0.7235


         == flag 1.601 longformer result On test data ==
# called_model : longformer
# Test Accuracy: 0.7267%
Precision: 0.7269
Recall: 0.7267
F1 Score: 0.7267
Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.72      0.73      3972
           1       0.72      0.74      0.73      5937
           2       0.71      0.71      0.71      2375

    accuracy                           0.73     12284
   macro avg       0.73      0.72      0.72     12284
weighted avg       0.73      0.73      0.73     12284

Confusion Matrix:
[[2847 1043   82]
 [ 941 4393  603]
 [  56  632 1687]]

flag 1.11  model:  finished  with:   longformer





===================================================== 
flag 1.10  model:  started with ==>   luke
===================================================== 

 Epoch 1 / 20

Training Loss: 0.666
Validation Loss: 0.655
Validation Accuracy: 0.7180

 Epoch 2 / 20

Training Loss: 0.544
Validation Loss: 0.607
Validation Accuracy: 0.7305

 Epoch 3 / 20

Training Loss: 0.469
Validation Loss: 0.643
Validation Accuracy: 0.7390

 Epoch 4 / 20

Training Loss: 0.397
Validation Loss: 0.684
Validation Accuracy: 0.7285

 Epoch 5 / 20

Training Loss: 0.329
Validation Loss: 0.756
Validation Accuracy: 0.7290

 Epoch 6 / 20

Training Loss: 0.269
Validation Loss: 0.827
Validation Accuracy: 0.7345

 Epoch 7 / 20

Training Loss: 0.214
Validation Loss: 0.894
Validation Accuracy: 0.7430

 Epoch 8 / 20

Training Loss: 0.178
Validation Loss: 0.974
Validation Accuracy: 0.7350

 Epoch 9 / 20

Training Loss: 0.151
Validation Loss: 1.192
Validation Accuracy: 0.7160

 Epoch 10 / 20

Training Loss: 0.132
Validation Loss: 1.160
Validation Accuracy: 0.7305

 Epoch 11 / 20

Training Loss: 0.118
Validation Loss: 1.418
Validation Accuracy: 0.7205

 Epoch 12 / 20

Training Loss: 0.112
Validation Loss: 1.422
Validation Accuracy: 0.7160

 Epoch 13 / 20

Training Loss: 0.099
Validation Loss: 1.625
Validation Accuracy: 0.7255

 Epoch 14 / 20

Training Loss: 0.095
Validation Loss: 1.553
Validation Accuracy: 0.7245

 Epoch 15 / 20

Training Loss: 0.086
Validation Loss: 1.685
Validation Accuracy: 0.7295

 Epoch 16 / 20

Training Loss: 0.084
Validation Loss: 1.853
Validation Accuracy: 0.7155

 Epoch 17 / 20

Training Loss: 0.077
Validation Loss: 1.914
Validation Accuracy: 0.7300

 Epoch 18 / 20

Training Loss: 0.078
Validation Loss: 1.935
Validation Accuracy: 0.7180

 Epoch 19 / 20

Training Loss: 0.069
Validation Loss: 2.122
Validation Accuracy: 0.7200

 Epoch 20 / 20

Training Loss: 0.068
Validation Loss: 2.023
Validation Accuracy: 0.7240


         == flag 1.601 luke result On test data ==
# called_model : luke
# Test Accuracy: 0.7231%
Precision: 0.7240
Recall: 0.7231
F1 Score: 0.7228
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.78      0.74      3972
           1       0.74      0.70      0.72      5937
           2       0.72      0.70      0.71      2375

    accuracy                           0.72     12284
   macro avg       0.72      0.72      0.72     12284
weighted avg       0.72      0.72      0.72     12284

Confusion Matrix:
[[3082  808   82]
 [1224 4149  564]
 [  55  668 1652]]

flag 1.11  model:  finished  with:   luke





===================================================== 
flag 1.10  model:  started with ==>   t5
===================================================== 

 Epoch 1 / 20

Training Loss: 0.961
Validation Loss: 0.680
Validation Accuracy: 0.6930

 Epoch 2 / 20

Training Loss: 0.659
Validation Loss: 0.645
Validation Accuracy: 0.7060

 Epoch 3 / 20

Training Loss: 0.617
Validation Loss: 0.629
Validation Accuracy: 0.7200

 Epoch 4 / 20

Training Loss: 0.591
Validation Loss: 0.626
Validation Accuracy: 0.7280

 Epoch 5 / 20

Training Loss: 0.569
Validation Loss: 0.620
Validation Accuracy: 0.7390

 Epoch 6 / 20

Training Loss: 0.549
Validation Loss: 0.621
Validation Accuracy: 0.7395

 Epoch 7 / 20

Training Loss: 0.531
Validation Loss: 0.618
Validation Accuracy: 0.7390

 Epoch 8 / 20

Training Loss: 0.515
Validation Loss: 0.640
Validation Accuracy: 0.7425

 Epoch 9 / 20

Training Loss: 0.496
Validation Loss: 0.644
Validation Accuracy: 0.7420

 Epoch 10 / 20

Training Loss: 0.481
Validation Loss: 0.651
Validation Accuracy: 0.7370

 Epoch 11 / 20

Training Loss: 0.462
Validation Loss: 0.672
Validation Accuracy: 0.7440

 Epoch 12 / 20

Training Loss: 0.448
Validation Loss: 0.690
Validation Accuracy: 0.7395

 Epoch 13 / 20

Training Loss: 0.432
Validation Loss: 0.696
Validation Accuracy: 0.7405

 Epoch 14 / 20

Training Loss: 0.414
Validation Loss: 0.711
Validation Accuracy: 0.7420

 Epoch 15 / 20

Training Loss: 0.400
Validation Loss: 0.730
Validation Accuracy: 0.7355

 Epoch 16 / 20

Training Loss: 0.381
Validation Loss: 0.755
Validation Accuracy: 0.7405

 Epoch 17 / 20

Training Loss: 0.367
Validation Loss: 0.764
Validation Accuracy: 0.7410

 Epoch 18 / 20

Training Loss: 0.353
Validation Loss: 0.793
Validation Accuracy: 0.7335

 Epoch 19 / 20

Training Loss: 0.341
Validation Loss: 0.801
Validation Accuracy: 0.7345

 Epoch 20 / 20

Training Loss: 0.325
Validation Loss: 0.856
Validation Accuracy: 0.7345


         == flag 1.601 t5 result On test data ==
# called_model : t5
# Test Accuracy: 0.7089%
Precision: 0.7111
Recall: 0.7089
F1 Score: 0.7086
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.75      0.73      3972
           1       0.73      0.67      0.70      5937
           2       0.66      0.74      0.70      2375

    accuracy                           0.71     12284
   macro avg       0.70      0.72      0.71     12284
weighted avg       0.71      0.71      0.71     12284

Confusion Matrix:
[[2991  876  105]
 [1191 3959  787]
 [  59  558 1758]]

flag 1.11  model:  finished  with:   t5





===================================================== 
flag 1.10  model:  started with ==>   xlnet
===================================================== 

 Epoch 1 / 20

Training Loss: 0.702
Validation Loss: 0.620
Validation Accuracy: 0.7330

 Epoch 2 / 20

Training Loss: 0.572
Validation Loss: 0.659
Validation Accuracy: 0.7010

 Epoch 3 / 20

Training Loss: 0.490
Validation Loss: 0.646
Validation Accuracy: 0.7195

 Epoch 4 / 20

Training Loss: 0.408
Validation Loss: 0.792
Validation Accuracy: 0.7315

 Epoch 5 / 20

Training Loss: 0.335
Validation Loss: 0.818
Validation Accuracy: 0.7340

 Epoch 6 / 20

Training Loss: 0.265
Validation Loss: 0.937
Validation Accuracy: 0.7230

 Epoch 7 / 20

Training Loss: 0.208
Validation Loss: 1.058
Validation Accuracy: 0.7215

 Epoch 8 / 20

Training Loss: 0.172
Validation Loss: 1.114
Validation Accuracy: 0.7290

 Epoch 9 / 20

Training Loss: 0.143
Validation Loss: 1.366
Validation Accuracy: 0.7245

 Epoch 10 / 20

Training Loss: 0.122
Validation Loss: 1.393
Validation Accuracy: 0.7170

 Epoch 11 / 20

Training Loss: 0.110
Validation Loss: 1.590
Validation Accuracy: 0.7320

 Epoch 12 / 20

Training Loss: 0.099
Validation Loss: 1.599
Validation Accuracy: 0.7235

 Epoch 13 / 20

Training Loss: 0.090
Validation Loss: 1.854
Validation Accuracy: 0.7255

 Epoch 14 / 20

Training Loss: 0.084
Validation Loss: 1.716
Validation Accuracy: 0.7340

 Epoch 15 / 20

Training Loss: 0.079
Validation Loss: 2.177
Validation Accuracy: 0.7175

 Epoch 16 / 20

Training Loss: 0.075
Validation Loss: 2.122
Validation Accuracy: 0.7195

 Epoch 17 / 20

Training Loss: 0.068
Validation Loss: 2.152
Validation Accuracy: 0.7240

 Epoch 18 / 20

Training Loss: 0.067
Validation Loss: 1.964
Validation Accuracy: 0.7270

 Epoch 19 / 20

Training Loss: 0.060
Validation Loss: 2.088
Validation Accuracy: 0.7215

 Epoch 20 / 20

Training Loss: 0.060
Validation Loss: 1.985
Validation Accuracy: 0.7260


         == flag 1.601 xlnet result On test data ==
# called_model : xlnet
# Test Accuracy: 0.6998%
Precision: 0.7037
Recall: 0.6998
F1 Score: 0.6996
Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.75      0.72      3972
           1       0.74      0.65      0.69      5937
           2       0.63      0.73      0.68      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.71      0.70     12284
weighted avg       0.70      0.70      0.70     12284

Confusion Matrix:
[[2968  828  176]
 [1224 3887  826]
 [  67  567 1741]]

flag 1.11  model:  finished  with:   xlnet

Execution Finished
