learning rate  : 1e-06
epochs : 20
                                                text  label
0  "QT @user In the original draft of the 7th boo...      2
1  "Ben Smith / Smith (concussion) remains out of...      1
2  Sorry bout the stream last night I crashed out...      1
3  Chase Headley's RBI double in the 8th inning o...      1
4  @user Alciato: Bee will invest 150 million in ...      2
                                                text
0  "QT @user In the original draft of the 7th boo...
1  "Ben Smith / Smith (concussion) remains out of...
2  Sorry bout the stream last night I crashed out...
3  Chase Headley's RBI double in the 8th inning o...
4  @user Alciato: Bee will invest 150 million in ...
   label
0      2
1      1
2      1
3      1
4      2
                                                text  label
0  Dark Souls 3 April Launch Date Confirmed With ...      1
1  "National hot dog day, national tequila day, t...      2
2  When girls become bandwagon fans of the Packer...      0
3  @user I may or may not have searched it up on ...      1
4  Here's your starting TUESDAY MORNING Line up a...      1
                                                text
0  Dark Souls 3 April Launch Date Confirmed With ...
1  "National hot dog day, national tequila day, t...
2  When girls become bandwagon fans of the Packer...
3  @user I may or may not have searched it up on ...
4  Here's your starting TUESDAY MORNING Line up a...
   label
0      1
1      2
2      0
3      1
4      1
                                                text  label
0  @user @user what do these '1/2 naked pics' hav...      1
1  OH: “I had a blue penis while I was this” [pla...      1
2  @user @user That's coming, but I think the vic...      1
3  I think I may be finally in with the in crowd ...      2
4  @user Wow,first Hugo Chavez and now Fidel Cast...      0
                                                text
0  @user @user what do these '1/2 naked pics' hav...
1  OH: “I had a blue penis while I was this” [pla...
2  @user @user That's coming, but I think the vic...
3  I think I may be finally in with the in crowd ...
4  @user Wow,first Hugo Chavez and now Fidel Cast...
                                                text
0  @user @user what do these '1/2 naked pics' hav...
1  OH: “I had a blue penis while I was this” [pla...
2  @user @user That's coming, but I think the vic...
3  I think I may be finally in with the in crowd ...
4  @user Wow,first Hugo Chavez and now Fidel Cast...
len(train_labels) 45615
len(test_labels) 12284
len(val_labels) 2000

Unique values count in train_labels:
label
1    20673
2    17849
0     7093
Name: count, dtype: int64

Unique values count in val_labels:
label
1    869
2    819
0    312
Name: count, dtype: int64

Unique values count in test_labels:
label
1    5937
0    3972
2    2375
Name: count, dtype: int64





===================================================== 
flag 1.10  model:  started with ==>   bert
===================================================== 

 Epoch 1 / 20

Training Loss: 0.996
Validation Loss: 0.784
Validation Accuracy: 0.6500

 Epoch 2 / 20

Training Loss: 0.733
Validation Loss: 0.689
Validation Accuracy: 0.6905

 Epoch 3 / 20

Training Loss: 0.665
Validation Loss: 0.659
Validation Accuracy: 0.7105

 Epoch 4 / 20

Training Loss: 0.634
Validation Loss: 0.642
Validation Accuracy: 0.7145

 Epoch 5 / 20

Training Loss: 0.607
Validation Loss: 0.636
Validation Accuracy: 0.7170

 Epoch 6 / 20

Training Loss: 0.588
Validation Loss: 0.636
Validation Accuracy: 0.7165

 Epoch 7 / 20

Training Loss: 0.568
Validation Loss: 0.625
Validation Accuracy: 0.7215

 Epoch 8 / 20

Training Loss: 0.554
Validation Loss: 0.634
Validation Accuracy: 0.7245

 Epoch 9 / 20

Training Loss: 0.538
Validation Loss: 0.628
Validation Accuracy: 0.7335

 Epoch 10 / 20

Training Loss: 0.522
Validation Loss: 0.627
Validation Accuracy: 0.7290

 Epoch 11 / 20

Training Loss: 0.508
Validation Loss: 0.631
Validation Accuracy: 0.7340

 Epoch 12 / 20

Training Loss: 0.493
Validation Loss: 0.630
Validation Accuracy: 0.7330

 Epoch 13 / 20

Training Loss: 0.477
Validation Loss: 0.648
Validation Accuracy: 0.7300

 Epoch 14 / 20

Training Loss: 0.461
Validation Loss: 0.643
Validation Accuracy: 0.7370

 Epoch 15 / 20

Training Loss: 0.448
Validation Loss: 0.652
Validation Accuracy: 0.7395

 Epoch 16 / 20

Training Loss: 0.437
Validation Loss: 0.662
Validation Accuracy: 0.7405

 Epoch 17 / 20

Training Loss: 0.422
Validation Loss: 0.668
Validation Accuracy: 0.7480

 Epoch 18 / 20

Training Loss: 0.408
Validation Loss: 0.682
Validation Accuracy: 0.7385

 Epoch 19 / 20

Training Loss: 0.393
Validation Loss: 0.695
Validation Accuracy: 0.7405

 Epoch 20 / 20

Training Loss: 0.380
Validation Loss: 0.696
Validation Accuracy: 0.7370


         == flag 1.601 bert result On test data ==
# called_model : bert
# Test Accuracy: 0.6988%
Precision: 0.7015
Recall: 0.6988
F1 Score: 0.6985
Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.74      0.72      3972
           1       0.73      0.66      0.69      5937
           2       0.65      0.73      0.69      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.71      0.70     12284
weighted avg       0.70      0.70      0.70     12284

Confusion Matrix:
[[2954  889  129]
 [1228 3892  817]
 [  67  570 1738]]

flag 1.11  model:  finished  with:   bert





===================================================== 
flag 1.10  model:  started with ==>   roberta
===================================================== 

 Epoch 1 / 20

Training Loss: 0.914
Validation Loss: 0.715
Validation Accuracy: 0.7115

 Epoch 2 / 20

Training Loss: 0.685
Validation Loss: 0.652
Validation Accuracy: 0.7270

 Epoch 3 / 20

Training Loss: 0.631
Validation Loss: 0.637
Validation Accuracy: 0.7310

 Epoch 4 / 20

Training Loss: 0.604
Validation Loss: 0.622
Validation Accuracy: 0.7295

 Epoch 5 / 20

Training Loss: 0.581
Validation Loss: 0.613
Validation Accuracy: 0.7455

 Epoch 6 / 20

Training Loss: 0.565
Validation Loss: 0.622
Validation Accuracy: 0.7335

 Epoch 7 / 20

Training Loss: 0.553
Validation Loss: 0.613
Validation Accuracy: 0.7440

 Epoch 8 / 20

Training Loss: 0.539
Validation Loss: 0.611
Validation Accuracy: 0.7395

 Epoch 9 / 20

Training Loss: 0.526
Validation Loss: 0.608
Validation Accuracy: 0.7460

 Epoch 10 / 20

Training Loss: 0.515
Validation Loss: 0.616
Validation Accuracy: 0.7415

 Epoch 11 / 20

Training Loss: 0.503
Validation Loss: 0.606
Validation Accuracy: 0.7465

 Epoch 12 / 20

Training Loss: 0.492
Validation Loss: 0.622
Validation Accuracy: 0.7420

 Epoch 13 / 20

Training Loss: 0.479
Validation Loss: 0.628
Validation Accuracy: 0.7375

 Epoch 14 / 20

Training Loss: 0.470
Validation Loss: 0.634
Validation Accuracy: 0.7440

 Epoch 15 / 20

Training Loss: 0.459
Validation Loss: 0.647
Validation Accuracy: 0.7415

 Epoch 16 / 20

Training Loss: 0.447
Validation Loss: 0.641
Validation Accuracy: 0.7450

 Epoch 17 / 20

Training Loss: 0.435
Validation Loss: 0.655
Validation Accuracy: 0.7485

 Epoch 18 / 20

Training Loss: 0.427
Validation Loss: 0.672
Validation Accuracy: 0.7405

 Epoch 19 / 20

Training Loss: 0.417
Validation Loss: 0.667
Validation Accuracy: 0.7430

 Epoch 20 / 20

Training Loss: 0.404
Validation Loss: 0.672
Validation Accuracy: 0.7435


         == flag 1.601 roberta result On test data ==
# called_model : roberta
# Test Accuracy: 0.7107%
Precision: 0.7162
Recall: 0.7107
F1 Score: 0.7099
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.77      0.74      3972
           1       0.75      0.64      0.69      5937
           2       0.64      0.77      0.70      2375

    accuracy                           0.71     12284
   macro avg       0.70      0.73      0.71     12284
weighted avg       0.72      0.71      0.71     12284

Confusion Matrix:
[[3073  778  121]
 [1214 3827  896]
 [  58  487 1830]]

flag 1.11  model:  finished  with:   roberta





===================================================== 
flag 1.10  model:  started with ==>   distilbert
===================================================== 

 Epoch 1 / 20

Training Loss: 0.937
Validation Loss: 0.754
Validation Accuracy: 0.6660

 Epoch 2 / 20

Training Loss: 0.718
Validation Loss: 0.694
Validation Accuracy: 0.6915

 Epoch 3 / 20

Training Loss: 0.677
Validation Loss: 0.674
Validation Accuracy: 0.6985

 Epoch 4 / 20

Training Loss: 0.653
Validation Loss: 0.663
Validation Accuracy: 0.7095

 Epoch 5 / 20

Training Loss: 0.633
Validation Loss: 0.654
Validation Accuracy: 0.7165

 Epoch 6 / 20

Training Loss: 0.616
Validation Loss: 0.650
Validation Accuracy: 0.7155

 Epoch 7 / 20

Training Loss: 0.603
Validation Loss: 0.645
Validation Accuracy: 0.7255

 Epoch 8 / 20

Training Loss: 0.591
Validation Loss: 0.645
Validation Accuracy: 0.7190

 Epoch 9 / 20

Training Loss: 0.579
Validation Loss: 0.641
Validation Accuracy: 0.7180

 Epoch 10 / 20

Training Loss: 0.566
Validation Loss: 0.641
Validation Accuracy: 0.7225

 Epoch 11 / 20

Training Loss: 0.555
Validation Loss: 0.642
Validation Accuracy: 0.7250

 Epoch 12 / 20

Training Loss: 0.542
Validation Loss: 0.642
Validation Accuracy: 0.7225

 Epoch 13 / 20

Training Loss: 0.532
Validation Loss: 0.642
Validation Accuracy: 0.7230

 Epoch 14 / 20

Training Loss: 0.520
Validation Loss: 0.642
Validation Accuracy: 0.7220

 Epoch 15 / 20

Training Loss: 0.510
Validation Loss: 0.643
Validation Accuracy: 0.7330

 Epoch 16 / 20

Training Loss: 0.499
Validation Loss: 0.649
Validation Accuracy: 0.7290

 Epoch 17 / 20

Training Loss: 0.488
Validation Loss: 0.650
Validation Accuracy: 0.7310

 Epoch 18 / 20

Training Loss: 0.478
Validation Loss: 0.656
Validation Accuracy: 0.7305

 Epoch 19 / 20

Training Loss: 0.468
Validation Loss: 0.662
Validation Accuracy: 0.7295

 Epoch 20 / 20

Training Loss: 0.459
Validation Loss: 0.663
Validation Accuracy: 0.7310


         == flag 1.601 distilbert result On test data ==
# called_model : distilbert
# Test Accuracy: 0.6880%
Precision: 0.6903
Recall: 0.6880
F1 Score: 0.6882
Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.71      0.70      3972
           1       0.71      0.66      0.69      5937
           2       0.63      0.71      0.67      2375

    accuracy                           0.69     12284
   macro avg       0.68      0.70      0.69     12284
weighted avg       0.69      0.69      0.69     12284

Confusion Matrix:
[[2806 1004  162]
 [1153 3948  836]
 [  77  600 1698]]

flag 1.11  model:  finished  with:   distilbert





===================================================== 
flag 1.10  model:  started with ==>   electra
===================================================== 

 Epoch 1 / 20

Training Loss: 0.953
Validation Loss: 0.743
Validation Accuracy: 0.6815

 Epoch 2 / 20

Training Loss: 0.712
Validation Loss: 0.671
Validation Accuracy: 0.7100

 Epoch 3 / 20

Training Loss: 0.648
Validation Loss: 0.650
Validation Accuracy: 0.7220

 Epoch 4 / 20

Training Loss: 0.613
Validation Loss: 0.639
Validation Accuracy: 0.7255

 Epoch 5 / 20

Training Loss: 0.589
Validation Loss: 0.627
Validation Accuracy: 0.7330

 Epoch 6 / 20

Training Loss: 0.572
Validation Loss: 0.624
Validation Accuracy: 0.7335

 Epoch 7 / 20

Training Loss: 0.553
Validation Loss: 0.621
Validation Accuracy: 0.7340

 Epoch 8 / 20

Training Loss: 0.542
Validation Loss: 0.630
Validation Accuracy: 0.7320

 Epoch 9 / 20

Training Loss: 0.531
Validation Loss: 0.622
Validation Accuracy: 0.7325

 Epoch 10 / 20

Training Loss: 0.515
Validation Loss: 0.631
Validation Accuracy: 0.7370

 Epoch 11 / 20

Training Loss: 0.505
Validation Loss: 0.638
Validation Accuracy: 0.7395

 Epoch 12 / 20

Training Loss: 0.492
Validation Loss: 0.633
Validation Accuracy: 0.7320

 Epoch 13 / 20

Training Loss: 0.481
Validation Loss: 0.642
Validation Accuracy: 0.7295

 Epoch 14 / 20

Training Loss: 0.469
Validation Loss: 0.664
Validation Accuracy: 0.7275

 Epoch 15 / 20

Training Loss: 0.457
Validation Loss: 0.655
Validation Accuracy: 0.7270

 Epoch 16 / 20

Training Loss: 0.447
Validation Loss: 0.666
Validation Accuracy: 0.7335

 Epoch 17 / 20

Training Loss: 0.433
Validation Loss: 0.667
Validation Accuracy: 0.7335

 Epoch 18 / 20

Training Loss: 0.422
Validation Loss: 0.690
Validation Accuracy: 0.7295

 Epoch 19 / 20

Training Loss: 0.413
Validation Loss: 0.687
Validation Accuracy: 0.7285

 Epoch 20 / 20

Training Loss: 0.401
Validation Loss: 0.700
Validation Accuracy: 0.7265


         == flag 1.601 electra result On test data ==
# called_model : electra
# Test Accuracy: 0.7159%
Precision: 0.7180
Recall: 0.7159
F1 Score: 0.7151
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.79      0.75      3972
           1       0.74      0.67      0.70      5937
           2       0.67      0.71      0.69      2375

    accuracy                           0.72     12284
   macro avg       0.71      0.72      0.71     12284
weighted avg       0.72      0.72      0.72     12284

Confusion Matrix:
[[3136  753   83]
 [1236 3966  735]
 [  63  620 1692]]

flag 1.11  model:  finished  with:   electra





===================================================== 
flag 1.10  model:  started with ==>   gpt2
===================================================== 

 Epoch 1 / 20

Training Loss: 1.305
Validation Loss: 1.012
Validation Accuracy: 0.4665

 Epoch 2 / 20

Training Loss: 0.954
Validation Loss: 0.861
Validation Accuracy: 0.5840

 Epoch 3 / 20

Training Loss: 0.826
Validation Loss: 0.741
Validation Accuracy: 0.6635

 Epoch 4 / 20

Training Loss: 0.735
Validation Loss: 0.699
Validation Accuracy: 0.6865

 Epoch 5 / 20

Training Loss: 0.701
Validation Loss: 0.682
Validation Accuracy: 0.6945

 Epoch 6 / 20

Training Loss: 0.681
Validation Loss: 0.674
Validation Accuracy: 0.6895

 Epoch 7 / 20

Training Loss: 0.666
Validation Loss: 0.660
Validation Accuracy: 0.7035

 Epoch 8 / 20

Training Loss: 0.652
Validation Loss: 0.650
Validation Accuracy: 0.7155

 Epoch 9 / 20

Training Loss: 0.641
Validation Loss: 0.648
Validation Accuracy: 0.7150

 Epoch 10 / 20

Training Loss: 0.633
Validation Loss: 0.646
Validation Accuracy: 0.7140

 Epoch 11 / 20

Training Loss: 0.624
Validation Loss: 0.643
Validation Accuracy: 0.7180

 Epoch 12 / 20

Training Loss: 0.617
Validation Loss: 0.639
Validation Accuracy: 0.7165

 Epoch 13 / 20

Training Loss: 0.611
Validation Loss: 0.632
Validation Accuracy: 0.7170

 Epoch 14 / 20

Training Loss: 0.602
Validation Loss: 0.636
Validation Accuracy: 0.7165

 Epoch 15 / 20

Training Loss: 0.597
Validation Loss: 0.632
Validation Accuracy: 0.7205

 Epoch 16 / 20

Training Loss: 0.590
Validation Loss: 0.630
Validation Accuracy: 0.7200

 Epoch 17 / 20

Training Loss: 0.584
Validation Loss: 0.635
Validation Accuracy: 0.7170

 Epoch 18 / 20

Training Loss: 0.579
Validation Loss: 0.628
Validation Accuracy: 0.7175

 Epoch 19 / 20

Training Loss: 0.573
Validation Loss: 0.630
Validation Accuracy: 0.7225

 Epoch 20 / 20

Training Loss: 0.568
Validation Loss: 0.633
Validation Accuracy: 0.7260


         == flag 1.601 gpt2 result On test data ==
# called_model : gpt2
# Test Accuracy: 0.6997%
Precision: 0.7059
Recall: 0.6997
F1 Score: 0.6987
Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.77      0.73      3972
           1       0.75      0.63      0.68      5937
           2       0.64      0.75      0.69      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.72      0.70     12284
weighted avg       0.71      0.70      0.70     12284

Confusion Matrix:
[[3066  769  137]
 [1308 3739  890]
 [  78  507 1790]]

flag 1.11  model:  finished  with:   gpt2





===================================================== 
flag 1.10  model:  started with ==>   longformer
===================================================== 

 Epoch 1 / 20

Training Loss: 0.869
Validation Loss: 0.693
Validation Accuracy: 0.6885

 Epoch 2 / 20

Training Loss: 0.660
Validation Loss: 0.659
Validation Accuracy: 0.7050

 Epoch 3 / 20

Training Loss: 0.624
Validation Loss: 0.642
Validation Accuracy: 0.7185

 Epoch 4 / 20

Training Loss: 0.599
Validation Loss: 0.627
Validation Accuracy: 0.7255

 Epoch 5 / 20

Training Loss: 0.583
Validation Loss: 0.622
Validation Accuracy: 0.7290

 Epoch 6 / 20

Training Loss: 0.567
Validation Loss: 0.622
Validation Accuracy: 0.7345

 Epoch 7 / 20

Training Loss: 0.554
Validation Loss: 0.608
Validation Accuracy: 0.7355

 Epoch 8 / 20

Training Loss: 0.542
Validation Loss: 0.627
Validation Accuracy: 0.7310

 Epoch 9 / 20

Training Loss: 0.532
Validation Loss: 0.621
Validation Accuracy: 0.7355

 Epoch 10 / 20

Training Loss: 0.519
Validation Loss: 0.633
Validation Accuracy: 0.7305

 Epoch 11 / 20

Training Loss: 0.509
Validation Loss: 0.622
Validation Accuracy: 0.7330

 Epoch 12 / 20

Training Loss: 0.497
Validation Loss: 0.651
Validation Accuracy: 0.7270

 Epoch 13 / 20

Training Loss: 0.487
Validation Loss: 0.630
Validation Accuracy: 0.7340

 Epoch 14 / 20

Training Loss: 0.474
Validation Loss: 0.660
Validation Accuracy: 0.7225

 Epoch 15 / 20

Training Loss: 0.464
Validation Loss: 0.645
Validation Accuracy: 0.7345

 Epoch 16 / 20

Training Loss: 0.458
Validation Loss: 0.658
Validation Accuracy: 0.7295

 Epoch 17 / 20

Training Loss: 0.444
Validation Loss: 0.660
Validation Accuracy: 0.7325

 Epoch 18 / 20

Training Loss: 0.433
Validation Loss: 0.663
Validation Accuracy: 0.7305

 Epoch 19 / 20

Training Loss: 0.424
Validation Loss: 0.680
Validation Accuracy: 0.7325

 Epoch 20 / 20

Training Loss: 0.410
Validation Loss: 0.711
Validation Accuracy: 0.7255


         == flag 1.601 longformer result On test data ==
# called_model : longformer
# Test Accuracy: 0.7191%
Precision: 0.7208
Recall: 0.7191
F1 Score: 0.7193
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.73      0.73      3972
           1       0.73      0.70      0.72      5937
           2       0.67      0.75      0.71      2375

    accuracy                           0.72     12284
   macro avg       0.71      0.73      0.72     12284
weighted avg       0.72      0.72      0.72     12284

Confusion Matrix:
[[2905  957  110]
 [1013 4142  782]
 [  47  541 1787]]

flag 1.11  model:  finished  with:   longformer





===================================================== 
flag 1.10  model:  started with ==>   luke
===================================================== 

 Epoch 1 / 20

Training Loss: 0.836
Validation Loss: 0.677
Validation Accuracy: 0.7000

 Epoch 2 / 20

Training Loss: 0.650
Validation Loss: 0.645
Validation Accuracy: 0.7225

 Epoch 3 / 20

Training Loss: 0.613
Validation Loss: 0.634
Validation Accuracy: 0.7295

 Epoch 4 / 20

Training Loss: 0.592
Validation Loss: 0.620
Validation Accuracy: 0.7345

 Epoch 5 / 20

Training Loss: 0.576
Validation Loss: 0.611
Validation Accuracy: 0.7410

 Epoch 6 / 20

Training Loss: 0.561
Validation Loss: 0.615
Validation Accuracy: 0.7280

 Epoch 7 / 20

Training Loss: 0.549
Validation Loss: 0.604
Validation Accuracy: 0.7445

 Epoch 8 / 20

Training Loss: 0.536
Validation Loss: 0.612
Validation Accuracy: 0.7370

 Epoch 9 / 20

Training Loss: 0.523
Validation Loss: 0.628
Validation Accuracy: 0.7330

 Epoch 10 / 20

Training Loss: 0.514
Validation Loss: 0.618
Validation Accuracy: 0.7405

 Epoch 11 / 20

Training Loss: 0.501
Validation Loss: 0.618
Validation Accuracy: 0.7430

 Epoch 12 / 20

Training Loss: 0.488
Validation Loss: 0.623
Validation Accuracy: 0.7420

 Epoch 13 / 20

Training Loss: 0.477
Validation Loss: 0.633
Validation Accuracy: 0.7415

 Epoch 14 / 20

Training Loss: 0.467
Validation Loss: 0.642
Validation Accuracy: 0.7400

 Epoch 15 / 20

Training Loss: 0.455
Validation Loss: 0.644
Validation Accuracy: 0.7415

 Epoch 16 / 20

Training Loss: 0.446
Validation Loss: 0.677
Validation Accuracy: 0.7295

 Epoch 17 / 20

Training Loss: 0.434
Validation Loss: 0.661
Validation Accuracy: 0.7370

 Epoch 18 / 20

Training Loss: 0.422
Validation Loss: 0.678
Validation Accuracy: 0.7325

 Epoch 19 / 20

Training Loss: 0.411
Validation Loss: 0.689
Validation Accuracy: 0.7355

 Epoch 20 / 20

Training Loss: 0.399
Validation Loss: 0.689
Validation Accuracy: 0.7335


         == flag 1.601 luke result On test data ==
# called_model : luke
# Test Accuracy: 0.7148%
Precision: 0.7180
Recall: 0.7148
F1 Score: 0.7149
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.73      0.73      3972
           1       0.74      0.68      0.71      5937
           2       0.65      0.77      0.71      2375

    accuracy                           0.71     12284
   macro avg       0.71      0.73      0.71     12284
weighted avg       0.72      0.71      0.71     12284

Confusion Matrix:
[[2892  955  125]
 [1020 4052  865]
 [  44  494 1837]]

flag 1.11  model:  finished  with:   luke





===================================================== 
flag 1.10  model:  started with ==>   t5
===================================================== 

 Epoch 1 / 20

Training Loss: 1.358
Validation Loss: 1.202
Validation Accuracy: 0.4475

 Epoch 2 / 20

Training Loss: 1.126
Validation Loss: 1.039
Validation Accuracy: 0.5250

 Epoch 3 / 20

Training Loss: 1.037
Validation Loss: 0.990
Validation Accuracy: 0.5585

 Epoch 4 / 20

Training Loss: 0.983
Validation Loss: 0.919
Validation Accuracy: 0.5950

 Epoch 5 / 20

Training Loss: 0.910
Validation Loss: 0.829
Validation Accuracy: 0.6220

 Epoch 6 / 20

Training Loss: 0.835
Validation Loss: 0.770
Validation Accuracy: 0.6360

 Epoch 7 / 20

Training Loss: 0.781
Validation Loss: 0.731
Validation Accuracy: 0.6715

 Epoch 8 / 20

Training Loss: 0.743
Validation Loss: 0.705
Validation Accuracy: 0.7000

 Epoch 9 / 20

Training Loss: 0.720
Validation Loss: 0.693
Validation Accuracy: 0.6880

 Epoch 10 / 20

Training Loss: 0.699
Validation Loss: 0.687
Validation Accuracy: 0.6880

 Epoch 11 / 20

Training Loss: 0.686
Validation Loss: 0.682
Validation Accuracy: 0.6940

 Epoch 12 / 20

Training Loss: 0.675
Validation Loss: 0.677
Validation Accuracy: 0.6935

 Epoch 13 / 20

Training Loss: 0.667
Validation Loss: 0.671
Validation Accuracy: 0.6970

 Epoch 14 / 20

Training Loss: 0.659
Validation Loss: 0.668
Validation Accuracy: 0.6995

 Epoch 15 / 20

Training Loss: 0.651
Validation Loss: 0.666
Validation Accuracy: 0.7015

 Epoch 16 / 20

Training Loss: 0.645
Validation Loss: 0.666
Validation Accuracy: 0.7020

 Epoch 17 / 20

Training Loss: 0.640
Validation Loss: 0.664
Validation Accuracy: 0.7025

 Epoch 18 / 20

Training Loss: 0.635
Validation Loss: 0.664
Validation Accuracy: 0.7060

 Epoch 19 / 20

Training Loss: 0.635
Validation Loss: 0.657
Validation Accuracy: 0.7035

 Epoch 20 / 20

Training Loss: 0.629
Validation Loss: 0.654
Validation Accuracy: 0.7060


         == flag 1.601 t5 result On test data ==
# called_model : t5
# Test Accuracy: 0.7016%
Precision: 0.7086
Recall: 0.7016
F1 Score: 0.7008
Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.77      0.73      3972
           1       0.75      0.63      0.69      5937
           2       0.63      0.76      0.69      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.72      0.70     12284
weighted avg       0.71      0.70      0.70     12284

Confusion Matrix:
[[3063  743  166]
 [1293 3753  891]
 [  71  501 1803]]

flag 1.11  model:  finished  with:   t5





===================================================== 
flag 1.10  model:  started with ==>   xlnet
===================================================== 

 Epoch 1 / 20

Training Loss: 0.881
Validation Loss: 0.705
Validation Accuracy: 0.6780

 Epoch 2 / 20

Training Loss: 0.706
Validation Loss: 0.669
Validation Accuracy: 0.7070

 Epoch 3 / 20

Training Loss: 0.663
Validation Loss: 0.651
Validation Accuracy: 0.7210

 Epoch 4 / 20

Training Loss: 0.638
Validation Loss: 0.633
Validation Accuracy: 0.7265

 Epoch 5 / 20

Training Loss: 0.616
Validation Loss: 0.634
Validation Accuracy: 0.7215

 Epoch 6 / 20

Training Loss: 0.600
Validation Loss: 0.639
Validation Accuracy: 0.7240

 Epoch 7 / 20

Training Loss: 0.583
Validation Loss: 0.630
Validation Accuracy: 0.7340

 Epoch 8 / 20

Training Loss: 0.570
Validation Loss: 0.630
Validation Accuracy: 0.7360

 Epoch 9 / 20

Training Loss: 0.557
Validation Loss: 0.622
Validation Accuracy: 0.7340

 Epoch 10 / 20

Training Loss: 0.545
Validation Loss: 0.629
Validation Accuracy: 0.7285

 Epoch 11 / 20

Training Loss: 0.531
Validation Loss: 0.643
Validation Accuracy: 0.7220

 Epoch 12 / 20

Training Loss: 0.520
Validation Loss: 0.636
Validation Accuracy: 0.7330

 Epoch 13 / 20

Training Loss: 0.508
Validation Loss: 0.635
Validation Accuracy: 0.7315

 Epoch 14 / 20

Training Loss: 0.496
Validation Loss: 0.642
Validation Accuracy: 0.7340

 Epoch 15 / 20

Training Loss: 0.485
Validation Loss: 0.645
Validation Accuracy: 0.7265

 Epoch 16 / 20

Training Loss: 0.472
Validation Loss: 0.658
Validation Accuracy: 0.7290

 Epoch 17 / 20

Training Loss: 0.461
Validation Loss: 0.661
Validation Accuracy: 0.7300

 Epoch 18 / 20

Training Loss: 0.452
Validation Loss: 0.646
Validation Accuracy: 0.7320

 Epoch 19 / 20

Training Loss: 0.437
Validation Loss: 0.683
Validation Accuracy: 0.7325

 Epoch 20 / 20

Training Loss: 0.428
Validation Loss: 0.675
Validation Accuracy: 0.7265


         == flag 1.601 xlnet result On test data ==
# called_model : xlnet
# Test Accuracy: 0.6993%
Precision: 0.7041
Recall: 0.6993
F1 Score: 0.6997
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.70      0.72      3972
           1       0.72      0.67      0.70      5937
           2       0.62      0.76      0.68      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.71      0.70     12284
weighted avg       0.70      0.70      0.70     12284

Confusion Matrix:
[[2794 1010  168]
 [1003 3980  954]
 [  45  514 1816]]

flag 1.11  model:  finished  with:   xlnet

Execution Finished
