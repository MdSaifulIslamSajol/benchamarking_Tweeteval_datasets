learning rate  : 1e-05
epochs : 20
                                                text  label
0  "QT @user In the original draft of the 7th boo...      2
1  "Ben Smith / Smith (concussion) remains out of...      1
2  Sorry bout the stream last night I crashed out...      1
3  Chase Headley's RBI double in the 8th inning o...      1
4  @user Alciato: Bee will invest 150 million in ...      2
                                                text
0  "QT @user In the original draft of the 7th boo...
1  "Ben Smith / Smith (concussion) remains out of...
2  Sorry bout the stream last night I crashed out...
3  Chase Headley's RBI double in the 8th inning o...
4  @user Alciato: Bee will invest 150 million in ...
   label
0      2
1      1
2      1
3      1
4      2
                                                text  label
0  Dark Souls 3 April Launch Date Confirmed With ...      1
1  "National hot dog day, national tequila day, t...      2
2  When girls become bandwagon fans of the Packer...      0
3  @user I may or may not have searched it up on ...      1
4  Here's your starting TUESDAY MORNING Line up a...      1
                                                text
0  Dark Souls 3 April Launch Date Confirmed With ...
1  "National hot dog day, national tequila day, t...
2  When girls become bandwagon fans of the Packer...
3  @user I may or may not have searched it up on ...
4  Here's your starting TUESDAY MORNING Line up a...
   label
0      1
1      2
2      0
3      1
4      1
                                                text  label
0  @user @user what do these '1/2 naked pics' hav...      1
1  OH: “I had a blue penis while I was this” [pla...      1
2  @user @user That's coming, but I think the vic...      1
3  I think I may be finally in with the in crowd ...      2
4  @user Wow,first Hugo Chavez and now Fidel Cast...      0
                                                text
0  @user @user what do these '1/2 naked pics' hav...
1  OH: “I had a blue penis while I was this” [pla...
2  @user @user That's coming, but I think the vic...
3  I think I may be finally in with the in crowd ...
4  @user Wow,first Hugo Chavez and now Fidel Cast...
                                                text
0  @user @user what do these '1/2 naked pics' hav...
1  OH: “I had a blue penis while I was this” [pla...
2  @user @user That's coming, but I think the vic...
3  I think I may be finally in with the in crowd ...
4  @user Wow,first Hugo Chavez and now Fidel Cast...
len(train_labels) 45615
len(test_labels) 12284
len(val_labels) 2000

Unique values count in train_labels:
label
1    20673
2    17849
0     7093
Name: count, dtype: int64

Unique values count in val_labels:
label
1    869
2    819
0    312
Name: count, dtype: int64

Unique values count in test_labels:
label
1    5937
0    3972
2    2375
Name: count, dtype: int64





===================================================== 
flag 1.10  model:  started with ==>   bert
===================================================== 

 Epoch 1 / 20

Training Loss: 0.712
Validation Loss: 0.611
Validation Accuracy: 0.7325

 Epoch 2 / 20

Training Loss: 0.542
Validation Loss: 0.608
Validation Accuracy: 0.7455

 Epoch 3 / 20

Training Loss: 0.437
Validation Loss: 0.634
Validation Accuracy: 0.7380

 Epoch 4 / 20

Training Loss: 0.328
Validation Loss: 0.776
Validation Accuracy: 0.7285

 Epoch 5 / 20

Training Loss: 0.237
Validation Loss: 0.863
Validation Accuracy: 0.7240

 Epoch 6 / 20

Training Loss: 0.176
Validation Loss: 1.018
Validation Accuracy: 0.7290

 Epoch 7 / 20

Training Loss: 0.136
Validation Loss: 1.225
Validation Accuracy: 0.7190

 Epoch 8 / 20

Training Loss: 0.118
Validation Loss: 1.280
Validation Accuracy: 0.7230

 Epoch 9 / 20

Training Loss: 0.099
Validation Loss: 1.484
Validation Accuracy: 0.7185

 Epoch 10 / 20

Training Loss: 0.087
Validation Loss: 1.465
Validation Accuracy: 0.7345

 Epoch 11 / 20

Training Loss: 0.082
Validation Loss: 1.745
Validation Accuracy: 0.7200

 Epoch 12 / 20

Training Loss: 0.075
Validation Loss: 1.715
Validation Accuracy: 0.7175

 Epoch 13 / 20

Training Loss: 0.070
Validation Loss: 1.574
Validation Accuracy: 0.7250

 Epoch 14 / 20

Training Loss: 0.059
Validation Loss: 1.790
Validation Accuracy: 0.7160

 Epoch 15 / 20

Training Loss: 0.060
Validation Loss: 1.765
Validation Accuracy: 0.7250

 Epoch 16 / 20

Training Loss: 0.051
Validation Loss: 1.993
Validation Accuracy: 0.7215

 Epoch 17 / 20

Training Loss: 0.050
Validation Loss: 1.935
Validation Accuracy: 0.7140

 Epoch 18 / 20

Training Loss: 0.044
Validation Loss: 2.087
Validation Accuracy: 0.7280

 Epoch 19 / 20

Training Loss: 0.041
Validation Loss: 2.030
Validation Accuracy: 0.7205

 Epoch 20 / 20

Training Loss: 0.038
Validation Loss: 2.132
Validation Accuracy: 0.7275


         == flag 1.601 bert result On test data ==
# called_model : bert
# Test Accuracy: 0.6977%
Precision: 0.7019
Recall: 0.6977
F1 Score: 0.6983
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.69      0.71      3972
           1       0.71      0.69      0.70      5937
           2       0.62      0.74      0.68      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.71      0.70     12284
weighted avg       0.70      0.70      0.70     12284

Confusion Matrix:
[[2736 1064  172]
 [ 950 4070  917]
 [  42  568 1765]]

flag 1.11  model:  finished  with:   bert





===================================================== 
flag 1.10  model:  started with ==>   roberta
===================================================== 

 Epoch 1 / 20

Training Loss: 0.684
Validation Loss: 0.597
Validation Accuracy: 0.7345

 Epoch 2 / 20

Training Loss: 0.548
Validation Loss: 0.622
Validation Accuracy: 0.7370

 Epoch 3 / 20

Training Loss: 0.471
Validation Loss: 0.594
Validation Accuracy: 0.7485

 Epoch 4 / 20

Training Loss: 0.403
Validation Loss: 0.629
Validation Accuracy: 0.7540

 Epoch 5 / 20

Training Loss: 0.334
Validation Loss: 0.719
Validation Accuracy: 0.7415

 Epoch 6 / 20

Training Loss: 0.267
Validation Loss: 0.813
Validation Accuracy: 0.7315

 Epoch 7 / 20

Training Loss: 0.222
Validation Loss: 0.882
Validation Accuracy: 0.7260

 Epoch 8 / 20

Training Loss: 0.182
Validation Loss: 0.944
Validation Accuracy: 0.7315

 Epoch 9 / 20

Training Loss: 0.154
Validation Loss: 1.127
Validation Accuracy: 0.7190

 Epoch 10 / 20

Training Loss: 0.137
Validation Loss: 1.177
Validation Accuracy: 0.7275

 Epoch 11 / 20

Training Loss: 0.125
Validation Loss: 1.266
Validation Accuracy: 0.7280

 Epoch 12 / 20

Training Loss: 0.111
Validation Loss: 1.405
Validation Accuracy: 0.7290

 Epoch 13 / 20

Training Loss: 0.104
Validation Loss: 1.446
Validation Accuracy: 0.7265

 Epoch 14 / 20

Training Loss: 0.101
Validation Loss: 1.534
Validation Accuracy: 0.7370

 Epoch 15 / 20

Training Loss: 0.093
Validation Loss: 1.620
Validation Accuracy: 0.7315

 Epoch 16 / 20

Training Loss: 0.086
Validation Loss: 1.655
Validation Accuracy: 0.7150

 Epoch 17 / 20

Training Loss: 0.078
Validation Loss: 1.927
Validation Accuracy: 0.7190

 Epoch 18 / 20

Training Loss: 0.079
Validation Loss: 1.843
Validation Accuracy: 0.7345

 Epoch 19 / 20

Training Loss: 0.077
Validation Loss: 1.743
Validation Accuracy: 0.7225

 Epoch 20 / 20

Training Loss: 0.067
Validation Loss: 2.083
Validation Accuracy: 0.7180


         == flag 1.601 roberta result On test data ==
# called_model : roberta
# Test Accuracy: 0.7176%
Precision: 0.7179
Recall: 0.7176
F1 Score: 0.7177
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.73      0.73      3972
           1       0.72      0.71      0.72      5937
           2       0.69      0.72      0.70      2375

    accuracy                           0.72     12284
   macro avg       0.71      0.72      0.72     12284
weighted avg       0.72      0.72      0.72     12284

Confusion Matrix:
[[2884 1010   78]
 [1026 4221  690]
 [  53  612 1710]]

flag 1.11  model:  finished  with:   roberta





===================================================== 
flag 1.10  model:  started with ==>   distilbert
===================================================== 

 Epoch 1 / 20

Training Loss: 0.709
Validation Loss: 0.661
Validation Accuracy: 0.6975

 Epoch 2 / 20

Training Loss: 0.576
Validation Loss: 0.620
Validation Accuracy: 0.7235

 Epoch 3 / 20

Training Loss: 0.490
Validation Loss: 0.636
Validation Accuracy: 0.7305

 Epoch 4 / 20

Training Loss: 0.407
Validation Loss: 0.685
Validation Accuracy: 0.7300

 Epoch 5 / 20

Training Loss: 0.322
Validation Loss: 0.737
Validation Accuracy: 0.7310

 Epoch 6 / 20

Training Loss: 0.251
Validation Loss: 0.859
Validation Accuracy: 0.7240

 Epoch 7 / 20

Training Loss: 0.193
Validation Loss: 0.958
Validation Accuracy: 0.7200

 Epoch 8 / 20

Training Loss: 0.147
Validation Loss: 1.068
Validation Accuracy: 0.7265

 Epoch 9 / 20

Training Loss: 0.122
Validation Loss: 1.268
Validation Accuracy: 0.7145

 Epoch 10 / 20

Training Loss: 0.107
Validation Loss: 1.335
Validation Accuracy: 0.7125

 Epoch 11 / 20

Training Loss: 0.092
Validation Loss: 1.468
Validation Accuracy: 0.7105

 Epoch 12 / 20

Training Loss: 0.082
Validation Loss: 1.541
Validation Accuracy: 0.7205

 Epoch 13 / 20

Training Loss: 0.076
Validation Loss: 1.661
Validation Accuracy: 0.7150

 Epoch 14 / 20

Training Loss: 0.069
Validation Loss: 1.709
Validation Accuracy: 0.7170

 Epoch 15 / 20

Training Loss: 0.063
Validation Loss: 1.846
Validation Accuracy: 0.7210

 Epoch 16 / 20

Training Loss: 0.054
Validation Loss: 1.902
Validation Accuracy: 0.7115

 Epoch 17 / 20

Training Loss: 0.050
Validation Loss: 1.897
Validation Accuracy: 0.7275

 Epoch 18 / 20

Training Loss: 0.048
Validation Loss: 2.139
Validation Accuracy: 0.7020

 Epoch 19 / 20

Training Loss: 0.047
Validation Loss: 2.069
Validation Accuracy: 0.7215

 Epoch 20 / 20

Training Loss: 0.043
Validation Loss: 2.109
Validation Accuracy: 0.7200


         == flag 1.601 distilbert result On test data ==
# called_model : distilbert
# Test Accuracy: 0.6984%
Precision: 0.6987
Recall: 0.6984
F1 Score: 0.6982
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.67      0.69      3972
           1       0.69      0.72      0.71      5937
           2       0.69      0.68      0.68      2375

    accuracy                           0.70     12284
   macro avg       0.70      0.69      0.69     12284
weighted avg       0.70      0.70      0.70     12284

Confusion Matrix:
[[2670 1201  101]
 [1025 4302  610]
 [  59  709 1607]]

flag 1.11  model:  finished  with:   distilbert





===================================================== 
flag 1.10  model:  started with ==>   electra
===================================================== 

 Epoch 1 / 20

Training Loss: 0.680
Validation Loss: 0.630
Validation Accuracy: 0.7310

 Epoch 2 / 20

Training Loss: 0.539
Validation Loss: 0.622
Validation Accuracy: 0.7380

 Epoch 3 / 20

Training Loss: 0.455
Validation Loss: 0.672
Validation Accuracy: 0.7340

 Epoch 4 / 20

Training Loss: 0.375
Validation Loss: 0.714
Validation Accuracy: 0.7445

 Epoch 5 / 20

Training Loss: 0.301
Validation Loss: 0.821
Validation Accuracy: 0.7375

 Epoch 6 / 20

Training Loss: 0.240
Validation Loss: 0.847
Validation Accuracy: 0.7375

 Epoch 7 / 20

Training Loss: 0.191
Validation Loss: 0.985
Validation Accuracy: 0.7255

 Epoch 8 / 20

Training Loss: 0.155
Validation Loss: 1.084
Validation Accuracy: 0.7190

 Epoch 9 / 20

Training Loss: 0.137
Validation Loss: 1.184
Validation Accuracy: 0.7185

 Epoch 10 / 20

Training Loss: 0.116
Validation Loss: 1.284
Validation Accuracy: 0.7255

 Epoch 11 / 20

Training Loss: 0.106
Validation Loss: 1.315
Validation Accuracy: 0.7305

 Epoch 12 / 20

Training Loss: 0.096
Validation Loss: 1.459
Validation Accuracy: 0.7350

 Epoch 13 / 20

Training Loss: 0.084
Validation Loss: 1.611
Validation Accuracy: 0.7220

 Epoch 14 / 20

Training Loss: 0.082
Validation Loss: 1.605
Validation Accuracy: 0.7180

 Epoch 15 / 20

Training Loss: 0.071
Validation Loss: 1.770
Validation Accuracy: 0.7200

 Epoch 16 / 20

Training Loss: 0.068
Validation Loss: 1.827
Validation Accuracy: 0.7175

 Epoch 17 / 20

Training Loss: 0.065
Validation Loss: 1.780
Validation Accuracy: 0.7195

 Epoch 18 / 20

Training Loss: 0.059
Validation Loss: 1.923
Validation Accuracy: 0.7255

 Epoch 19 / 20

Training Loss: 0.055
Validation Loss: 1.945
Validation Accuracy: 0.7210

 Epoch 20 / 20

Training Loss: 0.053
Validation Loss: 1.995
Validation Accuracy: 0.7170


         == flag 1.601 electra result On test data ==
# called_model : electra
# Test Accuracy: 0.6991%
Precision: 0.7153
Recall: 0.6991
F1 Score: 0.6961
Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.80      0.75      3972
           1       0.77      0.58      0.66      5937
           2       0.60      0.82      0.69      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.73      0.70     12284
weighted avg       0.72      0.70      0.70     12284

Confusion Matrix:
[[3192  643  137]
 [1305 3447 1185]
 [  51  375 1949]]

flag 1.11  model:  finished  with:   electra





===================================================== 
flag 1.10  model:  started with ==>   gpt2
===================================================== 

 Epoch 1 / 20

Training Loss: 0.780
Validation Loss: 0.655
Validation Accuracy: 0.7085

 Epoch 2 / 20

Training Loss: 0.625
Validation Loss: 0.615
Validation Accuracy: 0.7340

 Epoch 3 / 20

Training Loss: 0.573
Validation Loss: 0.623
Validation Accuracy: 0.7295

 Epoch 4 / 20

Training Loss: 0.531
Validation Loss: 0.620
Validation Accuracy: 0.7390

 Epoch 5 / 20

Training Loss: 0.490
Validation Loss: 0.629
Validation Accuracy: 0.7390

 Epoch 6 / 20

Training Loss: 0.452
Validation Loss: 0.654
Validation Accuracy: 0.7280

 Epoch 7 / 20

Training Loss: 0.409
Validation Loss: 0.686
Validation Accuracy: 0.7405

 Epoch 8 / 20

Training Loss: 0.368
Validation Loss: 0.751
Validation Accuracy: 0.7345

 Epoch 9 / 20

Training Loss: 0.332
Validation Loss: 0.801
Validation Accuracy: 0.7285

 Epoch 10 / 20

Training Loss: 0.295
Validation Loss: 0.858
Validation Accuracy: 0.7300

 Epoch 11 / 20

Training Loss: 0.264
Validation Loss: 0.924
Validation Accuracy: 0.7205

 Epoch 12 / 20

Training Loss: 0.229
Validation Loss: 0.998
Validation Accuracy: 0.7280

 Epoch 13 / 20

Training Loss: 0.202
Validation Loss: 1.080
Validation Accuracy: 0.7285

 Epoch 14 / 20

Training Loss: 0.181
Validation Loss: 1.146
Validation Accuracy: 0.7190

 Epoch 15 / 20

Training Loss: 0.157
Validation Loss: 1.209
Validation Accuracy: 0.7350

 Epoch 16 / 20

Training Loss: 0.140
Validation Loss: 1.299
Validation Accuracy: 0.7290

 Epoch 17 / 20

Training Loss: 0.126
Validation Loss: 1.387
Validation Accuracy: 0.7270

 Epoch 18 / 20

Training Loss: 0.114
Validation Loss: 1.480
Validation Accuracy: 0.7220

 Epoch 19 / 20

Training Loss: 0.103
Validation Loss: 1.568
Validation Accuracy: 0.7170

 Epoch 20 / 20

Training Loss: 0.094
Validation Loss: 1.675
Validation Accuracy: 0.7235


         == flag 1.601 gpt2 result On test data ==
# called_model : gpt2
# Test Accuracy: 0.7005%
Precision: 0.7088
Recall: 0.7005
F1 Score: 0.6995
Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.77      0.73      3972
           1       0.75      0.62      0.68      5937
           2       0.62      0.77      0.69      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.72      0.70     12284
weighted avg       0.71      0.70      0.70     12284

Confusion Matrix:
[[3065  750  157]
 [1263 3701  973]
 [  68  468 1839]]

flag 1.11  model:  finished  with:   gpt2





===================================================== 
flag 1.10  model:  started with ==>   longformer
===================================================== 

 Epoch 1 / 20

Training Loss: 0.672
Validation Loss: 0.608
Validation Accuracy: 0.7365

 Epoch 2 / 20

Training Loss: 0.550
Validation Loss: 0.592
Validation Accuracy: 0.7440

 Epoch 3 / 20

Training Loss: 0.476
Validation Loss: 0.643
Validation Accuracy: 0.7395

 Epoch 4 / 20

Training Loss: 0.407
Validation Loss: 0.714
Validation Accuracy: 0.7260

 Epoch 5 / 20

Training Loss: 0.338
Validation Loss: 0.792
Validation Accuracy: 0.7315

 Epoch 6 / 20

Training Loss: 0.276
Validation Loss: 0.782
Validation Accuracy: 0.7360

 Epoch 7 / 20

Training Loss: 0.223
Validation Loss: 0.920
Validation Accuracy: 0.7345

 Epoch 8 / 20

Training Loss: 0.187
Validation Loss: 0.975
Validation Accuracy: 0.7325

 Epoch 9 / 20

Training Loss: 0.156
Validation Loss: 1.054
Validation Accuracy: 0.7315

 Epoch 10 / 20

Training Loss: 0.135
Validation Loss: 1.140
Validation Accuracy: 0.7345

 Epoch 11 / 20

Training Loss: 0.122
Validation Loss: 1.240
Validation Accuracy: 0.7300

 Epoch 12 / 20

Training Loss: 0.107
Validation Loss: 1.328
Validation Accuracy: 0.7165

 Epoch 13 / 20

Training Loss: 0.104
Validation Loss: 1.589
Validation Accuracy: 0.7140

 Epoch 14 / 20

Training Loss: 0.099
Validation Loss: 1.471
Validation Accuracy: 0.7340

 Epoch 15 / 20

Training Loss: 0.093
Validation Loss: 1.524
Validation Accuracy: 0.7340

 Epoch 16 / 20

Training Loss: 0.086
Validation Loss: 1.779
Validation Accuracy: 0.7290

 Epoch 17 / 20

Training Loss: 0.085
Validation Loss: 1.795
Validation Accuracy: 0.7210

 Epoch 18 / 20

Training Loss: 0.079
Validation Loss: 1.838
Validation Accuracy: 0.7270

 Epoch 19 / 20

Training Loss: 0.077
Validation Loss: 1.651
Validation Accuracy: 0.7300

 Epoch 20 / 20

Training Loss: 0.069
Validation Loss: 1.845
Validation Accuracy: 0.7165


         == flag 1.601 longformer result On test data ==
# called_model : longformer
# Test Accuracy: 0.7167%
Precision: 0.7210
Recall: 0.7167
F1 Score: 0.7162
Classification Report:
              precision    recall  f1-score   support

           0       0.72      0.77      0.74      3972
           1       0.75      0.66      0.70      5937
           2       0.65      0.77      0.71      2375

    accuracy                           0.72     12284
   macro avg       0.71      0.73      0.72     12284
weighted avg       0.72      0.72      0.72     12284

Confusion Matrix:
[[3052  813  107]
 [1154 3917  866]
 [  58  482 1835]]

flag 1.11  model:  finished  with:   longformer





===================================================== 
flag 1.10  model:  started with ==>   luke
===================================================== 

 Epoch 1 / 20

Training Loss: 0.676
Validation Loss: 0.632
Validation Accuracy: 0.7340

 Epoch 2 / 20

Training Loss: 0.554
Validation Loss: 0.607
Validation Accuracy: 0.7340

 Epoch 3 / 20

Training Loss: 0.473
Validation Loss: 0.653
Validation Accuracy: 0.7400

 Epoch 4 / 20

Training Loss: 0.406
Validation Loss: 0.678
Validation Accuracy: 0.7340

 Epoch 5 / 20

Training Loss: 0.332
Validation Loss: 0.751
Validation Accuracy: 0.7325

 Epoch 6 / 20

Training Loss: 0.270
Validation Loss: 0.826
Validation Accuracy: 0.7365

 Epoch 7 / 20

Training Loss: 0.221
Validation Loss: 0.996
Validation Accuracy: 0.7140

 Epoch 8 / 20

Training Loss: 0.183
Validation Loss: 1.033
Validation Accuracy: 0.7265

 Epoch 9 / 20

Training Loss: 0.150
Validation Loss: 1.147
Validation Accuracy: 0.7100

 Epoch 10 / 20

Training Loss: 0.133
Validation Loss: 1.222
Validation Accuracy: 0.7215

 Epoch 11 / 20

Training Loss: 0.120
Validation Loss: 1.351
Validation Accuracy: 0.7215

 Epoch 12 / 20

Training Loss: 0.108
Validation Loss: 1.421
Validation Accuracy: 0.7240

 Epoch 13 / 20

Training Loss: 0.100
Validation Loss: 1.693
Validation Accuracy: 0.7075

 Epoch 14 / 20

Training Loss: 0.099
Validation Loss: 1.532
Validation Accuracy: 0.7310

 Epoch 15 / 20

Training Loss: 0.088
Validation Loss: 1.828
Validation Accuracy: 0.7170

 Epoch 16 / 20

Training Loss: 0.087
Validation Loss: 1.736
Validation Accuracy: 0.7260

 Epoch 17 / 20

Training Loss: 0.080
Validation Loss: 1.760
Validation Accuracy: 0.7300

 Epoch 18 / 20

Training Loss: 0.076
Validation Loss: 1.883
Validation Accuracy: 0.7225

 Epoch 19 / 20

Training Loss: 0.072
Validation Loss: 1.857
Validation Accuracy: 0.7220

 Epoch 20 / 20

Training Loss: 0.065
Validation Loss: 1.966
Validation Accuracy: 0.7280


         == flag 1.601 luke result On test data ==
# called_model : luke
# Test Accuracy: 0.6968%
Precision: 0.7171
Recall: 0.6968
F1 Score: 0.6912
Classification Report:
              precision    recall  f1-score   support

           0       0.66      0.85      0.75      3972
           1       0.79      0.55      0.65      5937
           2       0.62      0.79      0.70      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.73      0.70     12284
weighted avg       0.72      0.70      0.69     12284

Confusion Matrix:
[[3388  458  126]
 [1635 3286 1016]
 [  72  417 1886]]

flag 1.11  model:  finished  with:   luke





===================================================== 
flag 1.10  model:  started with ==>   t5
===================================================== 

 Epoch 1 / 20

Training Loss: 0.952
Validation Loss: 0.696
Validation Accuracy: 0.6820

 Epoch 2 / 20

Training Loss: 0.665
Validation Loss: 0.645
Validation Accuracy: 0.7165

 Epoch 3 / 20

Training Loss: 0.621
Validation Loss: 0.645
Validation Accuracy: 0.7250

 Epoch 4 / 20

Training Loss: 0.598
Validation Loss: 0.625
Validation Accuracy: 0.7280

 Epoch 5 / 20

Training Loss: 0.573
Validation Loss: 0.625
Validation Accuracy: 0.7235

 Epoch 6 / 20

Training Loss: 0.554
Validation Loss: 0.619
Validation Accuracy: 0.7320

 Epoch 7 / 20

Training Loss: 0.534
Validation Loss: 0.624
Validation Accuracy: 0.7280

 Epoch 8 / 20

Training Loss: 0.522
Validation Loss: 0.624
Validation Accuracy: 0.7325

 Epoch 9 / 20

Training Loss: 0.503
Validation Loss: 0.626
Validation Accuracy: 0.7385

 Epoch 10 / 20

Training Loss: 0.488
Validation Loss: 0.638
Validation Accuracy: 0.7410

 Epoch 11 / 20

Training Loss: 0.471
Validation Loss: 0.657
Validation Accuracy: 0.7340

 Epoch 12 / 20

Training Loss: 0.454
Validation Loss: 0.664
Validation Accuracy: 0.7360

 Epoch 13 / 20

Training Loss: 0.440
Validation Loss: 0.671
Validation Accuracy: 0.7425

 Epoch 14 / 20

Training Loss: 0.425
Validation Loss: 0.689
Validation Accuracy: 0.7380

 Epoch 15 / 20

Training Loss: 0.409
Validation Loss: 0.694
Validation Accuracy: 0.7380

 Epoch 16 / 20

Training Loss: 0.393
Validation Loss: 0.705
Validation Accuracy: 0.7405

 Epoch 17 / 20

Training Loss: 0.380
Validation Loss: 0.739
Validation Accuracy: 0.7435

 Epoch 18 / 20

Training Loss: 0.366
Validation Loss: 0.743
Validation Accuracy: 0.7410

 Epoch 19 / 20

Training Loss: 0.350
Validation Loss: 0.777
Validation Accuracy: 0.7365

 Epoch 20 / 20

Training Loss: 0.336
Validation Loss: 0.791
Validation Accuracy: 0.7255


         == flag 1.601 t5 result On test data ==
# called_model : t5
# Test Accuracy: 0.7038%
Precision: 0.7119
Recall: 0.7038
F1 Score: 0.7021
Classification Report:
              precision    recall  f1-score   support

           0       0.69      0.79      0.74      3972
           1       0.76      0.62      0.68      5937
           2       0.64      0.77      0.70      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.73      0.70     12284
weighted avg       0.71      0.70      0.70     12284

Confusion Matrix:
[[3148  695  129]
 [1366 3674  897]
 [  74  478 1823]]

flag 1.11  model:  finished  with:   t5





===================================================== 
flag 1.10  model:  started with ==>   xlnet
===================================================== 

 Epoch 1 / 20

Training Loss: 0.695
Validation Loss: 0.637
Validation Accuracy: 0.7100

 Epoch 2 / 20

Training Loss: 0.568
Validation Loss: 0.610
Validation Accuracy: 0.7325

 Epoch 3 / 20

Training Loss: 0.484
Validation Loss: 0.689
Validation Accuracy: 0.7350

 Epoch 4 / 20

Training Loss: 0.403
Validation Loss: 0.750
Validation Accuracy: 0.7290

 Epoch 5 / 20

Training Loss: 0.326
Validation Loss: 0.754
Validation Accuracy: 0.7355

 Epoch 6 / 20

Training Loss: 0.261
Validation Loss: 1.014
Validation Accuracy: 0.7270

 Epoch 7 / 20

Training Loss: 0.210
Validation Loss: 0.935
Validation Accuracy: 0.7245

 Epoch 8 / 20

Training Loss: 0.166
Validation Loss: 1.183
Validation Accuracy: 0.7180

 Epoch 9 / 20

Training Loss: 0.139
Validation Loss: 1.193
Validation Accuracy: 0.7250

 Epoch 10 / 20

Training Loss: 0.123
Validation Loss: 1.444
Validation Accuracy: 0.7225

 Epoch 11 / 20

Training Loss: 0.105
Validation Loss: 1.509
Validation Accuracy: 0.7305

 Epoch 12 / 20

Training Loss: 0.097
Validation Loss: 1.705
Validation Accuracy: 0.7185

 Epoch 13 / 20

Training Loss: 0.089
Validation Loss: 1.749
Validation Accuracy: 0.7260

 Epoch 14 / 20

Training Loss: 0.086
Validation Loss: 1.943
Validation Accuracy: 0.7240

 Epoch 15 / 20

Training Loss: 0.077
Validation Loss: 2.147
Validation Accuracy: 0.7115

 Epoch 16 / 20

Training Loss: 0.075
Validation Loss: 2.051
Validation Accuracy: 0.7225

 Epoch 17 / 20

Training Loss: 0.070
Validation Loss: 2.080
Validation Accuracy: 0.7295

 Epoch 18 / 20

Training Loss: 0.064
Validation Loss: 1.896
Validation Accuracy: 0.7320

 Epoch 19 / 20

Training Loss: 0.062
Validation Loss: 1.986
Validation Accuracy: 0.7355

 Epoch 20 / 20

Training Loss: 0.057
Validation Loss: 2.349
Validation Accuracy: 0.7320


         == flag 1.601 xlnet result On test data ==
# called_model : xlnet
# Test Accuracy: 0.7007%
Precision: 0.7058
Recall: 0.7007
F1 Score: 0.7005
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.74      0.73      3972
           1       0.74      0.65      0.69      5937
           2       0.63      0.76      0.69      2375

    accuracy                           0.70     12284
   macro avg       0.69      0.72      0.70     12284
weighted avg       0.71      0.70      0.70     12284

Confusion Matrix:
[[2954  883  135]
 [1146 3843  948]
 [  64  500 1811]]

flag 1.11  model:  finished  with:   xlnet

Execution Finished
