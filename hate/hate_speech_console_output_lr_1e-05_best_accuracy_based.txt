learning rate  : 1e-05
epochs : 30
                                                text  label
0  @user nice new signage. Are you not concerned ...      0
1  A woman who you fucked multiple times saying y...      1
2  @user @user real talk do you have eyes or were...      1
3  your girlfriend lookin at me like a groupie in...      1
4                        Hysterical woman like @user      0
                                                text
0  @user nice new signage. Are you not concerned ...
1  A woman who you fucked multiple times saying y...
2  @user @user real talk do you have eyes or were...
3  your girlfriend lookin at me like a groupie in...
4                        Hysterical woman like @user
   label
0      0
1      1
2      1
3      1
4      0
                                                text  label
0  @user @user If book Claire wanted to "stay in ...      0
1  After arriving in the EU refugees make protest...      0
2                                                 ðŸ˜³ðŸ‘‡      0
3  @user Worst thing is if they are that stupid t...      1
4  @user Say's the HYSTERICAL woman. It is woman ...      0
                                                text
0  @user @user If book Claire wanted to "stay in ...
1  After arriving in the EU refugees make protest...
2                                                 ðŸ˜³ðŸ‘‡
3  @user Worst thing is if they are that stupid t...
4  @user Say's the HYSTERICAL woman. It is woman ...
   label
0      0
1      0
2      0
3      1
4      0
                                                text  label
0  @user , you are correct that Reid certainly is...      0
1             Whoever just unfollowed me you a bitch      1
2  @user @user Those People Invaded Us!!! They DO...      1
3  stop JUDGING bitches by there cover, jus cuz s...      1
4  how about i knock heads off and send them gift...      1
                                                text
0  @user , you are correct that Reid certainly is...
1             Whoever just unfollowed me you a bitch
2  @user @user Those People Invaded Us!!! They DO...
3  stop JUDGING bitches by there cover, jus cuz s...
4  how about i knock heads off and send them gift...
                                                text
0  @user , you are correct that Reid certainly is...
1             Whoever just unfollowed me you a bitch
2  @user @user Those People Invaded Us!!! They DO...
3  stop JUDGING bitches by there cover, jus cuz s...
4  how about i knock heads off and send them gift...
len(train_labels) 9000
len(test_labels) 2970
len(val_labels) 1000

Unique values count in train_labels:
label
0    5217
1    3783
Name: count, dtype: int64

Unique values count in val_labels:
label
0    573
1    427
Name: count, dtype: int64

Unique values count in test_labels:
label
0    1718
1    1252
Name: count, dtype: int64





===================================================== 
flag 1.10  model:  started with ==>   bert
===================================================== 

 Epoch 1 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.8508

Evaluating...

Training Loss: 0.650
Validation Loss: 0.498
Validation Accuracy: 0.7820

 Epoch 2 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9090

Evaluating...

Training Loss: 0.373
Validation Loss: 0.481
Validation Accuracy: 0.7640

 Epoch 3 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9451

Evaluating...

Training Loss: 0.287
Validation Loss: 0.510
Validation Accuracy: 0.7730

 Epoch 4 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9802

Evaluating...

Training Loss: 0.203
Validation Loss: 0.578
Validation Accuracy: 0.7750

 Epoch 5 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9841

Evaluating...

Training Loss: 0.138
Validation Loss: 0.718
Validation Accuracy: 0.7810

 Epoch 6 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9947

Evaluating...

Training Loss: 0.091
Validation Loss: 0.819
Validation Accuracy: 0.7690

 Epoch 7 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9963

Evaluating...

Training Loss: 0.070
Validation Loss: 0.998
Validation Accuracy: 0.7630

 Epoch 8 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9957

Evaluating...

Training Loss: 0.054
Validation Loss: 1.063
Validation Accuracy: 0.7730

 Epoch 9 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9977

Evaluating...

Training Loss: 0.043
Validation Loss: 1.158
Validation Accuracy: 0.7760

 Epoch 10 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9976

Evaluating...

Training Loss: 0.035
Validation Loss: 1.208
Validation Accuracy: 0.7810

 Epoch 11 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9977

Evaluating...

Training Loss: 0.029
Validation Loss: 1.224
Validation Accuracy: 0.7880

 Epoch 12 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9984

Evaluating...

Training Loss: 0.027
Validation Loss: 1.315
Validation Accuracy: 0.7780

 Epoch 13 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9972

Evaluating...

Training Loss: 0.025
Validation Loss: 1.432
Validation Accuracy: 0.7670

 Epoch 14 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9970

Evaluating...

Training Loss: 0.026
Validation Loss: 1.395
Validation Accuracy: 0.7760

 Epoch 15 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9987

Evaluating...

Training Loss: 0.029
Validation Loss: 1.361
Validation Accuracy: 0.7670

 Epoch 16 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9996

Evaluating...

Training Loss: 0.015
Validation Loss: 1.314
Validation Accuracy: 0.7800

 Epoch 17 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9993

Evaluating...

Training Loss: 0.016
Validation Loss: 1.652
Validation Accuracy: 0.7640

 Epoch 18 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9997

Evaluating...

Training Loss: 0.017
Validation Loss: 1.632
Validation Accuracy: 0.7660

 Epoch 19 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9994

Evaluating...

Training Loss: 0.024
Validation Loss: 1.612
Validation Accuracy: 0.7750

 Epoch 20 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9996

Evaluating...

Training Loss: 0.022
Validation Loss: 1.518
Validation Accuracy: 0.7860

 Epoch 21 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9992

Evaluating...

Training Loss: 0.013
Validation Loss: 1.541
Validation Accuracy: 0.7860

 Epoch 22 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9994

Evaluating...

Training Loss: 0.012
Validation Loss: 1.658
Validation Accuracy: 0.7800

 Epoch 23 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9980

Evaluating...

Training Loss: 0.018
Validation Loss: 1.870
Validation Accuracy: 0.7530

 Epoch 24 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9992

Evaluating...

Training Loss: 0.018
Validation Loss: 1.580
Validation Accuracy: 0.7790

 Epoch 25 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9997

Evaluating...

Training Loss: 0.015
Validation Loss: 1.816
Validation Accuracy: 0.7700

 Epoch 26 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9994

Evaluating...

Training Loss: 0.019
Validation Loss: 1.544
Validation Accuracy: 0.7900

 Epoch 27 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9992

Evaluating...

Training Loss: 0.011
Validation Loss: 1.551
Validation Accuracy: 0.7820

 Epoch 28 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9997

Evaluating...

Training Loss: 0.014
Validation Loss: 1.524
Validation Accuracy: 0.7890

 Epoch 29 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9997

Evaluating...

Training Loss: 0.013
Validation Loss: 1.584
Validation Accuracy: 0.7790

 Epoch 30 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9997

Evaluating...

Training Loss: 0.009
Validation Loss: 1.730
Validation Accuracy: 0.7840


         == flag 1.601 bert result On test data ==
# called_model : bert
# Test Accuracy: 0.5455%
Precision: 0.7089
Recall: 0.5455
F1 Score: 0.4938
Classification Report:
              precision    recall  f1-score   support

           0       0.88      0.25      0.39      1718
           1       0.48      0.95      0.64      1252

    accuracy                           0.55      2970
   macro avg       0.68      0.60      0.51      2970
weighted avg       0.71      0.55      0.49      2970

Confusion Matrix:
[[ 429 1289]
 [  61 1191]]

flag 1.11  model:  finished  with:   bert





===================================================== 
flag 1.10  model:  started with ==>   roberta
===================================================== 

 Epoch 1 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.8247

Evaluating...

Training Loss: 0.625
Validation Loss: 0.564
Validation Accuracy: 0.7100

 Epoch 2 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.8647

Evaluating...

Training Loss: 0.398
Validation Loss: 0.546
Validation Accuracy: 0.7320

 Epoch 3 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9144

Evaluating...

Training Loss: 0.331
Validation Loss: 0.484
Validation Accuracy: 0.7870

 Epoch 4 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9520

Evaluating...

Training Loss: 0.270
Validation Loss: 0.512
Validation Accuracy: 0.8010

 Epoch 5 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9660

Evaluating...

Training Loss: 0.217
Validation Loss: 0.572
Validation Accuracy: 0.7930

 Epoch 6 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9400

Evaluating...

Training Loss: 0.167
Validation Loss: 0.680
Validation Accuracy: 0.7860

 Epoch 7 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9734

Evaluating...

Training Loss: 0.147
Validation Loss: 0.891
Validation Accuracy: 0.7620

 Epoch 8 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9897

Evaluating...

Training Loss: 0.122
Validation Loss: 0.902
Validation Accuracy: 0.7900

 Epoch 9 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9922

Evaluating...

Training Loss: 0.110
Validation Loss: 0.953
Validation Accuracy: 0.7900

 Epoch 10 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9794

Evaluating...

Training Loss: 0.091
Validation Loss: 1.165
Validation Accuracy: 0.7360

 Epoch 11 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9957

Evaluating...

Training Loss: 0.080
Validation Loss: 1.069
Validation Accuracy: 0.7740

 Epoch 12 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9963

Evaluating...

Training Loss: 0.076
Validation Loss: 1.091
Validation Accuracy: 0.7920

 Epoch 13 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9950

Evaluating...

Training Loss: 0.067
Validation Loss: 1.218
Validation Accuracy: 0.7740

 Epoch 14 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9976

Evaluating...

Training Loss: 0.059
Validation Loss: 1.185
Validation Accuracy: 0.7990

 Epoch 15 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9977

Evaluating...

Training Loss: 0.055
Validation Loss: 1.117
Validation Accuracy: 0.7900

 Epoch 16 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9984

Evaluating...

Training Loss: 0.043
Validation Loss: 1.297
Validation Accuracy: 0.8030

 Epoch 17 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9989

Evaluating...

Training Loss: 0.047
Validation Loss: 1.326
Validation Accuracy: 0.7870

 Epoch 18 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9988

Evaluating...

Training Loss: 0.048
Validation Loss: 1.402
Validation Accuracy: 0.7800

 Epoch 19 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9981

Evaluating...

Training Loss: 0.044
Validation Loss: 1.387
Validation Accuracy: 0.7960

 Epoch 20 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9976

Evaluating...

Training Loss: 0.036
Validation Loss: 1.504
Validation Accuracy: 0.7860

 Epoch 21 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9992

Evaluating...

Training Loss: 0.027
Validation Loss: 1.584
Validation Accuracy: 0.7930

 Epoch 22 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9986

Evaluating...

Training Loss: 0.032
Validation Loss: 1.594
Validation Accuracy: 0.7690

 Epoch 23 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9993

Evaluating...

Training Loss: 0.043
Validation Loss: 1.483
Validation Accuracy: 0.7860

 Epoch 24 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9994

Evaluating...

Training Loss: 0.029
Validation Loss: 1.478
Validation Accuracy: 0.7740

 Epoch 25 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9992

Evaluating...

Training Loss: 0.028
Validation Loss: 1.689
Validation Accuracy: 0.7660

 Epoch 26 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9998

Evaluating...

Training Loss: 0.024
Validation Loss: 1.569
Validation Accuracy: 0.7810

 Epoch 27 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9991

Evaluating...

Training Loss: 0.028
Validation Loss: 1.658
Validation Accuracy: 0.7880

 Epoch 28 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9994

Evaluating...

Training Loss: 0.024
Validation Loss: 1.620
Validation Accuracy: 0.7930

 Epoch 29 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9971

Evaluating...

Training Loss: 0.030
Validation Loss: 1.889
Validation Accuracy: 0.7660

 Epoch 30 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9993

Evaluating...

Training Loss: 0.026
Validation Loss: 1.651
Validation Accuracy: 0.7790


         == flag 1.601 roberta result On test data ==
# called_model : roberta
# Test Accuracy: 0.5290%
Precision: 0.6979
Recall: 0.5290
F1 Score: 0.4689
Classification Report:
              precision    recall  f1-score   support

           0       0.86      0.22      0.35      1718
           1       0.47      0.95      0.63      1252

    accuracy                           0.53      2970
   macro avg       0.67      0.59      0.49      2970
weighted avg       0.70      0.53      0.47      2970

Confusion Matrix:
[[ 379 1339]
 [  60 1192]]

flag 1.11  model:  finished  with:   roberta





===================================================== 
flag 1.10  model:  started with ==>   distilbert
===================================================== 

 Epoch 1 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.8099

Evaluating...

Training Loss: 0.614
Validation Loss: 0.537
Validation Accuracy: 0.7220

 Epoch 2 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.8658

Evaluating...

Training Loss: 0.421
Validation Loss: 0.526
Validation Accuracy: 0.7360

 Epoch 3 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9052

Evaluating...

Training Loss: 0.345
Validation Loss: 0.510
Validation Accuracy: 0.7490

 Epoch 4 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9339

Evaluating...

Training Loss: 0.276
Validation Loss: 0.601
Validation Accuracy: 0.7580

 Epoch 5 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9618

Evaluating...

Training Loss: 0.208
Validation Loss: 0.697
Validation Accuracy: 0.7470

 Epoch 6 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9828

Evaluating...

Training Loss: 0.156
Validation Loss: 0.723
Validation Accuracy: 0.7640

 Epoch 7 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9832

Evaluating...

Training Loss: 0.120
Validation Loss: 0.888
Validation Accuracy: 0.7450

 Epoch 8 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9934

Evaluating...

Training Loss: 0.095
Validation Loss: 0.962
Validation Accuracy: 0.7520

 Epoch 9 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9949

Evaluating...

Training Loss: 0.072
Validation Loss: 1.046
Validation Accuracy: 0.7400

 Epoch 10 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9941

Evaluating...

Training Loss: 0.056
Validation Loss: 1.287
Validation Accuracy: 0.7510

 Epoch 11 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9966

Evaluating...

Training Loss: 0.042
Validation Loss: 1.371
Validation Accuracy: 0.7530

 Epoch 12 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9978

Evaluating...

Training Loss: 0.041
Validation Loss: 1.363
Validation Accuracy: 0.7690

 Epoch 13 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9966

Evaluating...

Training Loss: 0.032
Validation Loss: 1.503
Validation Accuracy: 0.7620

 Epoch 14 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9978

Evaluating...

Training Loss: 0.029
Validation Loss: 1.632
Validation Accuracy: 0.7600

 Epoch 15 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9990

Evaluating...

Training Loss: 0.027
Validation Loss: 1.637
Validation Accuracy: 0.7590

 Epoch 16 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9994

Evaluating...

Training Loss: 0.019
Validation Loss: 1.723
Validation Accuracy: 0.7580

 Epoch 17 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9993

Evaluating...

Training Loss: 0.015
Validation Loss: 1.862
Validation Accuracy: 0.7590

 Epoch 18 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9993

Evaluating...

Training Loss: 0.023
Validation Loss: 1.812
Validation Accuracy: 0.7540

 Epoch 19 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9991

Evaluating...

Training Loss: 0.018
Validation Loss: 1.860
Validation Accuracy: 0.7690

 Epoch 20 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9996

Evaluating...

Training Loss: 0.018
Validation Loss: 1.806
Validation Accuracy: 0.7580

 Epoch 21 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9992

Evaluating...

Training Loss: 0.013
Validation Loss: 1.798
Validation Accuracy: 0.7570

 Epoch 22 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9997

Evaluating...

Training Loss: 0.021
Validation Loss: 1.818
Validation Accuracy: 0.7580

 Epoch 23 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9990

Evaluating...

Training Loss: 0.017
Validation Loss: 1.915
Validation Accuracy: 0.7570

 Epoch 24 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9994

Evaluating...

Training Loss: 0.010
Validation Loss: 1.976
Validation Accuracy: 0.7640

 Epoch 25 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9997

Evaluating...

Training Loss: 0.015
Validation Loss: 2.064
Validation Accuracy: 0.7580

 Epoch 26 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9996

Evaluating...

Training Loss: 0.017
Validation Loss: 1.880
Validation Accuracy: 0.7700

 Epoch 27 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9996

Evaluating...

Training Loss: 0.014
Validation Loss: 2.050
Validation Accuracy: 0.7500

 Epoch 28 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9996

Evaluating...

Training Loss: 0.017
Validation Loss: 2.020
Validation Accuracy: 0.7550

 Epoch 29 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9983

Evaluating...

Training Loss: 0.012
Validation Loss: 2.416
Validation Accuracy: 0.7380

 Epoch 30 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9997

Evaluating...

Training Loss: 0.014
Validation Loss: 2.103
Validation Accuracy: 0.7590


         == flag 1.601 distilbert result On test data ==
# called_model : distilbert
# Test Accuracy: 0.5330%
Precision: 0.7019
Recall: 0.5330
F1 Score: 0.4748
Classification Report:
              precision    recall  f1-score   support

           0       0.87      0.23      0.36      1718
           1       0.47      0.95      0.63      1252

    accuracy                           0.53      2970
   macro avg       0.67      0.59      0.50      2970
weighted avg       0.70      0.53      0.47      2970

Confusion Matrix:
[[ 390 1328]
 [  59 1193]]

flag 1.11  model:  finished  with:   distilbert





===================================================== 
flag 1.10  model:  started with ==>   electra
===================================================== 

 Epoch 1 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.8338

Evaluating...

Training Loss: 0.646
Validation Loss: 0.509
Validation Accuracy: 0.7480

 Epoch 2 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.8461

Evaluating...

Training Loss: 0.416
Validation Loss: 0.498
Validation Accuracy: 0.7610

 Epoch 3 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9098

Evaluating...

Training Loss: 0.344
Validation Loss: 0.488
Validation Accuracy: 0.7780

 Epoch 4 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9229

Evaluating...

Training Loss: 0.273
Validation Loss: 0.647
Validation Accuracy: 0.7530

 Epoch 5 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9524

Evaluating...

Training Loss: 0.217
Validation Loss: 0.621
Validation Accuracy: 0.7630

 Epoch 6 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9777

Evaluating...

Training Loss: 0.166
Validation Loss: 0.670
Validation Accuracy: 0.7610

 Epoch 7 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9861

Evaluating...

Training Loss: 0.133
Validation Loss: 0.701
Validation Accuracy: 0.7590

 Epoch 8 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9858

Evaluating...

Training Loss: 0.105
Validation Loss: 0.906
Validation Accuracy: 0.7680

 Epoch 9 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9850

Evaluating...

Training Loss: 0.093
Validation Loss: 0.916
Validation Accuracy: 0.7770

 Epoch 10 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9932

Evaluating...

Training Loss: 0.080
Validation Loss: 0.970
Validation Accuracy: 0.7900

 Epoch 11 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9940

Evaluating...

Training Loss: 0.070
Validation Loss: 1.011
Validation Accuracy: 0.7960

 Epoch 12 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9957

Evaluating...

Training Loss: 0.061
Validation Loss: 1.089
Validation Accuracy: 0.7770

 Epoch 13 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9937

Evaluating...

Training Loss: 0.060
Validation Loss: 1.204
Validation Accuracy: 0.7890

 Epoch 14 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9987

Evaluating...

Training Loss: 0.048
Validation Loss: 1.187
Validation Accuracy: 0.7840

 Epoch 15 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9980

Evaluating...

Training Loss: 0.041
Validation Loss: 1.183
Validation Accuracy: 0.7970

 Epoch 16 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9981

Evaluating...

Training Loss: 0.041
Validation Loss: 1.361
Validation Accuracy: 0.7790

 Epoch 17 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9989

Evaluating...

Training Loss: 0.025
Validation Loss: 1.392
Validation Accuracy: 0.7870

 Epoch 18 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9988

Evaluating...

Training Loss: 0.027
Validation Loss: 1.524
Validation Accuracy: 0.7740

 Epoch 19 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9989

Evaluating...

Training Loss: 0.038
Validation Loss: 1.507
Validation Accuracy: 0.7680

 Epoch 20 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9996

Evaluating...

Training Loss: 0.035
Validation Loss: 1.390
Validation Accuracy: 0.7950

 Epoch 21 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9982

Evaluating...

Training Loss: 0.026
Validation Loss: 1.721
Validation Accuracy: 0.7750

 Epoch 22 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9983

Evaluating...

Training Loss: 0.033
Validation Loss: 1.533
Validation Accuracy: 0.7760

 Epoch 23 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9996

Evaluating...

Training Loss: 0.027
Validation Loss: 1.510
Validation Accuracy: 0.7750

 Epoch 24 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9993

Evaluating...

Training Loss: 0.017
Validation Loss: 1.637
Validation Accuracy: 0.7860

 Epoch 25 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9974

Evaluating...

Training Loss: 0.020
Validation Loss: 1.769
Validation Accuracy: 0.7630

 Epoch 26 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9991

Evaluating...

Training Loss: 0.025
Validation Loss: 1.637
Validation Accuracy: 0.7830

 Epoch 27 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9992

Evaluating...

Training Loss: 0.020
Validation Loss: 1.570
Validation Accuracy: 0.7810

 Epoch 28 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9994

Evaluating...

Training Loss: 0.019
Validation Loss: 1.546
Validation Accuracy: 0.7940

 Epoch 29 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9992

Evaluating...

Training Loss: 0.017
Validation Loss: 1.589
Validation Accuracy: 0.7780

 Epoch 30 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9989

Evaluating...

Training Loss: 0.030
Validation Loss: 1.596
Validation Accuracy: 0.7810


         == flag 1.601 electra result On test data ==
# called_model : electra
# Test Accuracy: 0.5296%
Precision: 0.6892
Recall: 0.5296
F1 Score: 0.4726
Classification Report:
              precision    recall  f1-score   support

           0       0.85      0.23      0.36      1718
           1       0.47      0.94      0.63      1252

    accuracy                           0.53      2970
   macro avg       0.66      0.59      0.49      2970
weighted avg       0.69      0.53      0.47      2970

Confusion Matrix:
[[ 391 1327]
 [  70 1182]]

flag 1.11  model:  finished  with:   electra





===================================================== 
flag 1.10  model:  started with ==>   gpt2
===================================================== 

 Epoch 1 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.7800

Evaluating...

Training Loss: 0.682
Validation Loss: 0.564
Validation Accuracy: 0.7250

 Epoch 2 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.8267

Evaluating...

Training Loss: 0.466
Validation Loss: 0.495
Validation Accuracy: 0.7430

 Epoch 3 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.8447

Evaluating...

Training Loss: 0.413
Validation Loss: 0.524
Validation Accuracy: 0.7420

 Epoch 4 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.8766

Evaluating...

Training Loss: 0.372
Validation Loss: 0.476
Validation Accuracy: 0.7790

 Epoch 5 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.8940

Evaluating...

Training Loss: 0.333
Validation Loss: 0.521
Validation Accuracy: 0.7520

 Epoch 6 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9154

Evaluating...

Training Loss: 0.302
Validation Loss: 0.549
Validation Accuracy: 0.7620

 Epoch 7 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9440

Evaluating...

Training Loss: 0.266
Validation Loss: 0.536
Validation Accuracy: 0.7730

 Epoch 8 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9576

Evaluating...

Training Loss: 0.237
Validation Loss: 0.560
Validation Accuracy: 0.7720

 Epoch 9 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9690

Evaluating...

Training Loss: 0.204
Validation Loss: 0.627
Validation Accuracy: 0.7670

 Epoch 10 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9768

Evaluating...

Training Loss: 0.175
Validation Loss: 0.665
Validation Accuracy: 0.7880

 Epoch 11 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9843

Evaluating...

Training Loss: 0.150
Validation Loss: 0.693
Validation Accuracy: 0.7800

 Epoch 12 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9883

Evaluating...

Training Loss: 0.128
Validation Loss: 0.824
Validation Accuracy: 0.7860

 Epoch 13 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9919

Evaluating...

Training Loss: 0.110
Validation Loss: 0.927
Validation Accuracy: 0.7840

 Epoch 14 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9898

Evaluating...

Training Loss: 0.098
Validation Loss: 0.996
Validation Accuracy: 0.7760

 Epoch 15 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9943

Evaluating...

Training Loss: 0.084
Validation Loss: 1.168
Validation Accuracy: 0.7780

 Epoch 16 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9967

Evaluating...

Training Loss: 0.074
Validation Loss: 1.273
Validation Accuracy: 0.7640

 Epoch 17 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9950

Evaluating...

Training Loss: 0.062
Validation Loss: 1.387
Validation Accuracy: 0.7660

 Epoch 18 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9971

Evaluating...

Training Loss: 0.062
Validation Loss: 1.368
Validation Accuracy: 0.7770

 Epoch 19 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9980

Evaluating...

Training Loss: 0.046
Validation Loss: 1.547
Validation Accuracy: 0.7720

 Epoch 20 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9992

Evaluating...

Training Loss: 0.046
Validation Loss: 1.546
Validation Accuracy: 0.7820

 Epoch 21 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9980

Evaluating...

Training Loss: 0.039
Validation Loss: 1.644
Validation Accuracy: 0.7910

 Epoch 22 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9990

Evaluating...

Training Loss: 0.041
Validation Loss: 1.790
Validation Accuracy: 0.7820

 Epoch 23 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9941

Evaluating...

Training Loss: 0.039
Validation Loss: 1.932
Validation Accuracy: 0.7600

 Epoch 24 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9994

Evaluating...

Training Loss: 0.043
Validation Loss: 1.862
Validation Accuracy: 0.7760

 Epoch 25 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9996

Evaluating...

Training Loss: 0.033
Validation Loss: 1.877
Validation Accuracy: 0.7780

 Epoch 26 / 30
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.

Evaluating...
  Batch    50  of    282.
  Batch   100  of    282.
  Batch   150  of    282.
  Batch   200  of    282.
  Batch   250  of    282.
Training Accuracy: 0.9997

Evaluating...

Training Loss: 0.025
Validation Loss: 2.017
Validation Accuracy: 0.7870

 Epoch 27 / 30
